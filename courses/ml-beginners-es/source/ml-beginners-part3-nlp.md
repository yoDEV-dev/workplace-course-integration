# ML para Principiantes ü§ñ
## Parte 3: Procesamiento de Lenguaje Natural
**NLP y An√°lisis de Texto**

---


# Procesamiento de Lenguaje Natural

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1eb379dc2d0c9940b320732d16083778",
  "translation_date": "2025-09-04T00:33:20+00:00",
  "source_file": "6-NLP/README.md",
  "language_code": "es"
}
-->
# Comenzando con el procesamiento de lenguaje natural

El procesamiento de lenguaje natural (NLP, por sus siglas en ingl√©s) es la capacidad de un programa de computadora para entender el lenguaje humano tal como se habla y se escribe, conocido como lenguaje natural. Es un componente de la inteligencia artificial (IA). El NLP ha existido por m√°s de 50 a√±os y tiene ra√≠ces en el campo de la ling√º√≠stica. Todo el campo est√° dirigido a ayudar a las m√°quinas a entender y procesar el lenguaje humano. Esto puede ser utilizado para realizar tareas como la correcci√≥n ortogr√°fica o la traducci√≥n autom√°tica. Tiene una variedad de aplicaciones en el mundo real en varios campos, incluyendo la investigaci√≥n m√©dica, los motores de b√∫squeda y la inteligencia empresarial.

## Tema regional: Idiomas y literatura europeas y hoteles rom√°nticos de Europa ‚ù§Ô∏è

En esta secci√≥n del programa, se te presentar√° uno de los usos m√°s extendidos del aprendizaje autom√°tico: el procesamiento de lenguaje natural (NLP). Derivado de la ling√º√≠stica computacional, esta categor√≠a de inteligencia artificial es el puente entre los humanos y las m√°quinas a trav√©s de la comunicaci√≥n por voz o texto.

En estas lecciones aprenderemos los conceptos b√°sicos del NLP construyendo peque√±os bots conversacionales para entender c√≥mo el aprendizaje autom√°tico ayuda a que estas conversaciones sean cada vez m√°s 'inteligentes'. Viajar√°s en el tiempo, conversando con Elizabeth Bennett y el Sr. Darcy del cl√°sico de Jane Austen, **Orgullo y Prejuicio**, publicado en 1813. Luego, ampliar√°s tus conocimientos aprendiendo sobre el an√°lisis de sentimientos a trav√©s de rese√±as de hoteles en Europa.

![Libro de Orgullo y Prejuicio y t√©](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/translated_images/es/p&p.279f1c49ecd88941.webp)
> Foto por <a href="https://unsplash.com/@elaineh?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Elaine Howlin</a> en <a href="https://unsplash.com/s/photos/pride-and-prejudice?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
  
## Lecciones

1. [Introducci√≥n al procesamiento de lenguaje natural](1-Introduction-to-NLP/README.md)
2. [Tareas y t√©cnicas comunes de NLP](2-Tasks/README.md)
3. [Traducci√≥n y an√°lisis de sentimientos con aprendizaje autom√°tico](3-Translation-Sentiment/README.md)
4. [Preparando tus datos](4-Hotel-Reviews-1/README.md)
5. [NLTK para an√°lisis de sentimientos](5-Hotel-Reviews-2/README.md)

## Cr√©ditos 

Estas lecciones de procesamiento de lenguaje natural fueron escritas con ‚òï por [Stephen Howell](https://twitter.com/Howell_MSFT)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1c2ec40cf55c98a028a359c27ef7e45a",
  "translation_date": "2025-09-04T22:28:35+00:00",
  "source_file": "6-NLP/1-Introduction-to-NLP/README.md",
  "language_code": "es"
}
-->
# Introducci√≥n al procesamiento de lenguaje natural

Esta lecci√≥n cubre una breve historia y conceptos importantes del *procesamiento de lenguaje natural*, un subcampo de la *ling√º√≠stica computacional*.

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Introducci√≥n

El procesamiento de lenguaje natural, conocido como NLP por sus siglas en ingl√©s, es una de las √°reas m√°s conocidas donde se ha aplicado el aprendizaje autom√°tico y se utiliza en software de producci√≥n.

‚úÖ ¬øPuedes pensar en alg√∫n software que uses todos los d√≠as que probablemente tenga algo de NLP integrado? ¬øQu√© hay de tus programas de procesamiento de texto o aplicaciones m√≥viles que usas regularmente?

Aprender√°s sobre:

- **La idea de los idiomas**. C√≥mo se desarrollaron los idiomas y cu√°les han sido las principales √°reas de estudio.
- **Definici√≥n y conceptos**. Tambi√©n aprender√°s definiciones y conceptos sobre c√≥mo las computadoras procesan texto, incluyendo an√°lisis sint√°ctico, gram√°tica e identificaci√≥n de sustantivos y verbos. Hay algunas tareas de codificaci√≥n en esta lecci√≥n, y se introducen varios conceptos importantes que aprender√°s a programar m√°s adelante en las pr√≥ximas lecciones.

## Ling√º√≠stica computacional

La ling√º√≠stica computacional es un √°rea de investigaci√≥n y desarrollo que, durante muchas d√©cadas, ha estudiado c√≥mo las computadoras pueden trabajar con los idiomas, e incluso entenderlos, traducirlos y comunicarse con ellos. El procesamiento de lenguaje natural (NLP) es un campo relacionado que se centra en c√≥mo las computadoras pueden procesar idiomas 'naturales', es decir, humanos.

### Ejemplo - dictado en el tel√©fono

Si alguna vez has dictado a tu tel√©fono en lugar de escribir o le has hecho una pregunta a un asistente virtual, tu voz fue convertida en texto y luego procesada o *analizada* desde el idioma que hablaste. Las palabras clave detectadas se procesaron en un formato que el tel√©fono o asistente pudo entender y actuar en consecuencia.

![comprensi√≥n](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/1-Introduction-to-NLP/images/comprehension.png)
> ¬°La comprensi√≥n ling√º√≠stica real es dif√≠cil! Imagen por [Jen Looper](https://twitter.com/jenlooper)

### ¬øC√≥mo es posible esta tecnolog√≠a?

Esto es posible porque alguien escribi√≥ un programa de computadora para hacerlo. Hace unas d√©cadas, algunos escritores de ciencia ficci√≥n predijeron que las personas hablar√≠an principalmente con sus computadoras y que estas siempre entender√≠an exactamente lo que quer√≠an decir. Lamentablemente, result√≥ ser un problema m√°s dif√≠cil de lo que muchos imaginaron, y aunque hoy en d√≠a es un problema mucho mejor entendido, existen desaf√≠os significativos para lograr un procesamiento de lenguaje natural 'perfecto' cuando se trata de entender el significado de una oraci√≥n. Este es un problema particularmente dif√≠cil cuando se trata de entender el humor o detectar emociones como el sarcasmo en una oraci√≥n.

En este punto, podr√≠as estar recordando las clases escolares donde el profesor cubr√≠a las partes de la gram√°tica en una oraci√≥n. En algunos pa√≠ses, se ense√±a gram√°tica y ling√º√≠stica como una materia dedicada, pero en muchos, estos temas se incluyen como parte del aprendizaje de un idioma: ya sea tu primer idioma en la escuela primaria (aprendiendo a leer y escribir) y quiz√°s un segundo idioma en la escuela secundaria. ¬°No te preocupes si no eres un experto en diferenciar sustantivos de verbos o adverbios de adjetivos!

Si tienes dificultades con la diferencia entre el *presente simple* y el *presente progresivo*, no est√°s solo. Esto es algo desafiante para muchas personas, incluso hablantes nativos de un idioma. La buena noticia es que las computadoras son muy buenas aplicando reglas formales, y aprender√°s a escribir c√≥digo que pueda *analizar* una oraci√≥n tan bien como un humano. El mayor desaf√≠o que examinar√°s m√°s adelante es entender el *significado* y el *sentimiento* de una oraci√≥n.

## Prerrequisitos

Para esta lecci√≥n, el principal prerrequisito es poder leer y entender el idioma de esta lecci√≥n. No hay problemas matem√°ticos ni ecuaciones que resolver. Aunque el autor original escribi√≥ esta lecci√≥n en ingl√©s, tambi√©n est√° traducida a otros idiomas, por lo que podr√≠as estar leyendo una traducci√≥n. Hay ejemplos donde se utilizan varios idiomas diferentes (para comparar las diferentes reglas gramaticales de distintos idiomas). Estos *no* est√°n traducidos, pero el texto explicativo s√≠ lo est√°, por lo que el significado deber√≠a ser claro.

Para las tareas de codificaci√≥n, usar√°s Python y los ejemplos est√°n en Python 3.8.

En esta secci√≥n, necesitar√°s y usar√°s:

- **Comprensi√≥n de Python 3**. Comprensi√≥n del lenguaje de programaci√≥n en Python 3, esta lecci√≥n utiliza entrada, bucles, lectura de archivos, arreglos.
- **Visual Studio Code + extensi√≥n**. Usaremos Visual Studio Code y su extensi√≥n de Python. Tambi√©n puedes usar un IDE de Python de tu elecci√≥n.
- **TextBlob**. [TextBlob](https://github.com/sloria/TextBlob) es una biblioteca simplificada de procesamiento de texto para Python. Sigue las instrucciones en el sitio de TextBlob para instalarlo en tu sistema (instala tambi√©n los corpora, como se muestra a continuaci√≥n):

   ```bash
   pip install -U textblob
   python -m textblob.download_corpora
   ```

> üí° Consejo: Puedes ejecutar Python directamente en entornos de VS Code. Consulta los [documentos](https://code.visualstudio.com/docs/languages/python?WT.mc_id=academic-77952-leestott) para m√°s informaci√≥n.

## Hablando con m√°quinas

La historia de intentar que las computadoras entiendan el lenguaje humano se remonta a d√©cadas atr√°s, y uno de los primeros cient√≠ficos en considerar el procesamiento de lenguaje natural fue *Alan Turing*.

### La 'prueba de Turing'

Cuando Turing investigaba la *inteligencia artificial* en la d√©cada de 1950, consider√≥ si se podr√≠a realizar una prueba conversacional entre un humano y una computadora (a trav√©s de correspondencia escrita) donde el humano en la conversaci√≥n no estuviera seguro de si estaba conversando con otro humano o con una computadora.

Si, despu√©s de cierto tiempo de conversaci√≥n, el humano no pod√≠a determinar si las respuestas proven√≠an de una computadora o no, ¬øpodr√≠a decirse que la computadora estaba *pensando*?

### La inspiraci√≥n - 'el juego de imitaci√≥n'

La idea para esto provino de un juego de fiesta llamado *El juego de imitaci√≥n*, donde un interrogador est√° solo en una habitaci√≥n y tiene la tarea de determinar cu√°l de dos personas (en otra habitaci√≥n) es hombre y cu√°l es mujer. El interrogador puede enviar notas y debe tratar de pensar en preguntas cuyas respuestas escritas revelen el g√©nero de la persona misteriosa. Por supuesto, los jugadores en la otra habitaci√≥n intentan enga√±ar al interrogador respondiendo preguntas de manera que lo confundan o lo enga√±en, mientras dan la apariencia de responder honestamente.

### Desarrollando Eliza

En la d√©cada de 1960, un cient√≠fico del MIT llamado *Joseph Weizenbaum* desarroll√≥ [*Eliza*](https://wikipedia.org/wiki/ELIZA), una 'terapeuta' computarizada que hac√≠a preguntas al humano y daba la apariencia de entender sus respuestas. Sin embargo, aunque Eliza pod√≠a analizar una oraci√≥n e identificar ciertos constructos gramaticales y palabras clave para dar una respuesta razonable, no pod√≠a decirse que *entendiera* la oraci√≥n. Si a Eliza se le presentaba una oraci√≥n con el formato "**Yo estoy** <u>triste</u>", podr√≠a reorganizar y sustituir palabras en la oraci√≥n para formar la respuesta "¬øCu√°nto tiempo has **estado** <u>triste</u>?".

Esto daba la impresi√≥n de que Eliza entend√≠a la declaraci√≥n y estaba haciendo una pregunta de seguimiento, mientras que en realidad estaba cambiando el tiempo verbal y agregando algunas palabras. Si Eliza no pod√≠a identificar una palabra clave para la que tuviera una respuesta, en su lugar daba una respuesta aleatoria que podr√≠a aplicarse a muchas declaraciones diferentes. Eliza pod√≠a ser f√°cilmente enga√±ada, por ejemplo, si un usuario escrib√≠a "**T√∫ eres** una <u>bicicleta</u>", podr√≠a responder con "¬øCu√°nto tiempo he **sido** una <u>bicicleta</u>?", en lugar de una respuesta m√°s razonada.

[![Conversando con Eliza](https://img.youtube.com/vi/RMK9AphfLco/0.jpg)](https://youtu.be/RMK9AphfLco "Conversando con Eliza")

> üé• Haz clic en la imagen de arriba para ver un video sobre el programa original de ELIZA

> Nota: Puedes leer la descripci√≥n original de [Eliza](https://cacm.acm.org/magazines/1966/1/13317-elizaa-computer-program-for-the-study-of-natural-language-communication-between-man-and-machine/abstract) publicada en 1966 si tienes una cuenta de ACM. Alternativamente, lee sobre Eliza en [Wikipedia](https://wikipedia.org/wiki/ELIZA).

## Ejercicio - programando un bot conversacional b√°sico

Un bot conversacional, como Eliza, es un programa que solicita la entrada del usuario y parece entender y responder de manera inteligente. A diferencia de Eliza, nuestro bot no tendr√° varias reglas que le den la apariencia de tener una conversaci√≥n inteligente. En cambio, nuestro bot tendr√° una sola habilidad: mantener la conversaci√≥n con respuestas aleatorias que podr√≠an funcionar en casi cualquier conversaci√≥n trivial.

### El plan

Tus pasos al construir un bot conversacional:

1. Imprimir instrucciones que aconsejen al usuario c√≥mo interactuar con el bot.
2. Iniciar un bucle:
   1. Aceptar la entrada del usuario.
   2. Si el usuario ha pedido salir, entonces salir.
   3. Procesar la entrada del usuario y determinar la respuesta (en este caso, la respuesta es una elecci√≥n aleatoria de una lista de posibles respuestas gen√©ricas).
   4. Imprimir la respuesta.
3. Volver al paso 2.

### Construyendo el bot

Vamos a crear el bot a continuaci√≥n. Comenzaremos definiendo algunas frases.

1. Crea este bot t√∫ mismo en Python con las siguientes respuestas aleatorias:

    ```python
    random_responses = ["That is quite interesting, please tell me more.",
                        "I see. Do go on.",
                        "Why do you say that?",
                        "Funny weather we've been having, isn't it?",
                        "Let's change the subject.",
                        "Did you catch the game last night?"]
    ```

    Aqu√≠ hay un ejemplo de salida para guiarte (la entrada del usuario est√° en las l√≠neas que comienzan con `>`):

    ```output
    Hello, I am Marvin, the simple robot.
    You can end this conversation at any time by typing 'bye'
    After typing each answer, press 'enter'
    How are you today?
    > I am good thanks
    That is quite interesting, please tell me more.
    > today I went for a walk     
    Did you catch the game last night?
    > I did, but my team lost
    Funny weather we've been having, isn't it?
    > yes but I hope next week is better
    Let's change the subject.
    > ok, lets talk about music
    Why do you say that?
    > because I like music!
    Why do you say that?
    > bye
    It was nice talking to you, goodbye!
    ```

    Una posible soluci√≥n a la tarea est√° [aqu√≠](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/1-Introduction-to-NLP/solution/bot.py).

    ‚úÖ Detente y reflexiona

    1. ¬øCrees que las respuestas aleatorias podr√≠an 'enga√±ar' a alguien para que piense que el bot realmente las entendi√≥?
    2. ¬øQu√© caracter√≠sticas necesitar√≠a el bot para ser m√°s efectivo?
    3. Si un bot realmente pudiera 'entender' el significado de una oraci√≥n, ¬ønecesitar√≠a 'recordar' el significado de oraciones anteriores en una conversaci√≥n tambi√©n?

---

## üöÄDesaf√≠o

Elige uno de los elementos de "detente y reflexiona" anteriores y trata de implementarlo en c√≥digo o escribe una soluci√≥n en papel usando pseudoc√≥digo.

En la pr√≥xima lecci√≥n, aprender√°s sobre una serie de otros enfoques para analizar el lenguaje natural y el aprendizaje autom√°tico.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y autoestudio

Echa un vistazo a las referencias a continuaci√≥n como oportunidades de lectura adicional.

### Referencias

1. Schubert, Lenhart, "Computational Linguistics", *The Stanford Encyclopedia of Philosophy* (Spring 2020 Edition), Edward N. Zalta (ed.), URL = <https://plato.stanford.edu/archives/spr2020/entries/computational-linguistics/>.
2. Princeton University "About WordNet." [WordNet](https://wordnet.princeton.edu/). Princeton University. 2010.

## Tarea

[Busca un bot](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-04T22:27:00+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "es"
}
-->
# Tareas y t√©cnicas comunes de procesamiento de lenguaje natural

Para la mayor√≠a de las tareas de *procesamiento de lenguaje natural*, el texto que se va a procesar debe descomponerse, examinarse y los resultados almacenarse o cruzarse con reglas y conjuntos de datos. Estas tareas permiten al programador derivar el _significado_, la _intenci√≥n_ o solo la _frecuencia_ de t√©rminos y palabras en un texto.

## [Cuestionario previo a la clase](https://ff-quizzes.netlify.app/en/ml/)

Descubramos t√©cnicas comunes utilizadas en el procesamiento de texto. Combinadas con aprendizaje autom√°tico, estas t√©cnicas te ayudan a analizar grandes cantidades de texto de manera eficiente. Sin embargo, antes de aplicar ML a estas tareas, entendamos los problemas que enfrenta un especialista en NLP.

## Tareas comunes en NLP

Existen diferentes formas de analizar un texto con el que est√°s trabajando. Hay tareas que puedes realizar y, a trav√©s de ellas, puedes comprender el texto y sacar conclusiones. Generalmente, estas tareas se llevan a cabo en una secuencia.

### Tokenizaci√≥n

Probablemente, lo primero que la mayor√≠a de los algoritmos de NLP tienen que hacer es dividir el texto en tokens o palabras. Aunque esto suena simple, tener en cuenta la puntuaci√≥n y los delimitadores de palabras y oraciones en diferentes idiomas puede complicarlo. Es posible que tengas que usar varios m√©todos para determinar las demarcaciones.

![tokenizaci√≥n](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/2-Tasks/images/tokenization.png)
> Tokenizando una oraci√≥n de **Orgullo y Prejuicio**. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) son una forma de convertir tus datos de texto en valores num√©ricos. Los embeddings se realizan de manera que las palabras con un significado similar o palabras que se usan juntas se agrupen.

![word embeddings](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/2-Tasks/images/embedding.png)
> "Tengo el mayor respeto por tus nervios, son mis viejos amigos." - Word embeddings para una oraci√≥n en **Orgullo y Prejuicio**. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Prueba [esta herramienta interesante](https://projector.tensorflow.org/) para experimentar con word embeddings. Al hacer clic en una palabra, se muestran grupos de palabras similares: 'juguete' se agrupa con 'disney', 'lego', 'playstation' y 'consola'.

### Parsing y etiquetado de partes del discurso

Cada palabra que ha sido tokenizada puede etiquetarse como una parte del discurso: un sustantivo, verbo o adjetivo. La oraci√≥n `el r√°pido zorro rojo salt√≥ sobre el perro marr√≥n perezoso` podr√≠a etiquetarse como POS con zorro = sustantivo, salt√≥ = verbo.

![parsing](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/2-Tasks/images/parse.png)

> Analizando una oraci√≥n de **Orgullo y Prejuicio**. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

El parsing consiste en reconocer qu√© palabras est√°n relacionadas entre s√≠ en una oraci√≥n; por ejemplo, `el r√°pido zorro rojo salt√≥` es una secuencia de adjetivo-sustantivo-verbo que est√° separada de la secuencia `el perro marr√≥n perezoso`.

### Frecuencia de palabras y frases

Un procedimiento √∫til al analizar un gran cuerpo de texto es construir un diccionario de cada palabra o frase de inter√©s y cu√°ntas veces aparece. La frase `el r√°pido zorro rojo salt√≥ sobre el perro marr√≥n perezoso` tiene una frecuencia de palabras de 2 para "el".

Veamos un texto de ejemplo donde contamos la frecuencia de palabras. El poema Los Ganadores de Rudyard Kipling contiene el siguiente verso:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Como las frecuencias de frases pueden ser sensibles o insensibles a may√∫sculas seg√∫n se requiera, la frase `un amigo` tiene una frecuencia de 2, `el` tiene una frecuencia de 6 y `viajes` tiene una frecuencia de 2.

### N-grams

Un texto puede dividirse en secuencias de palabras de una longitud establecida: una sola palabra (unigram), dos palabras (bigramas), tres palabras (trigramas) o cualquier n√∫mero de palabras (n-grams).

Por ejemplo, `el r√°pido zorro rojo salt√≥ sobre el perro marr√≥n perezoso` con un puntaje n-gram de 2 produce los siguientes n-grams:

1. el r√°pido  
2. r√°pido zorro  
3. zorro rojo  
4. rojo salt√≥  
5. salt√≥ sobre  
6. sobre el  
7. el perro  
8. perro marr√≥n  
9. marr√≥n perezoso  

Podr√≠a ser m√°s f√°cil visualizarlo como una caja deslizante sobre la oraci√≥n. Aqu√≠ est√° para n-grams de 3 palabras, el n-gram est√° en negrita en cada oraci√≥n:

1.   <u>**el r√°pido zorro**</u> salt√≥ sobre el perro marr√≥n perezoso  
2.   el **<u>r√°pido zorro rojo</u>** salt√≥ sobre el perro marr√≥n perezoso  
3.   el r√°pido **<u>zorro rojo salt√≥</u>** sobre el perro marr√≥n perezoso  
4.   el r√°pido zorro **<u>rojo salt√≥ sobre</u>** el perro marr√≥n perezoso  
5.   el r√°pido zorro rojo **<u>salt√≥ sobre el</u>** perro marr√≥n perezoso  
6.   el r√°pido zorro rojo salt√≥ **<u>sobre el perro</u>** marr√≥n perezoso  
7.   el r√°pido zorro rojo salt√≥ sobre <u>**el perro marr√≥n**</u> perezoso  
8.   el r√°pido zorro rojo salt√≥ sobre el **<u>perro marr√≥n perezoso</u>**  

![ventana deslizante n-grams](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/2-Tasks/images/n-grams.gif)

> Valor n-gram de 3: Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

### Extracci√≥n de frases nominales

En la mayor√≠a de las oraciones, hay un sustantivo que es el sujeto u objeto de la oraci√≥n. En ingl√©s, a menudo se identifica porque tiene 'a', 'an' o 'the' antes de √©l. Identificar el sujeto u objeto de una oraci√≥n mediante la 'extracci√≥n de la frase nominal' es una tarea com√∫n en NLP al intentar comprender el significado de una oraci√≥n.

‚úÖ En la oraci√≥n "No puedo fijar la hora, ni el lugar, ni la mirada ni las palabras, que sentaron las bases. Hace demasiado tiempo. Estaba en medio antes de darme cuenta de que hab√≠a comenzado.", ¬øpuedes identificar las frases nominales?

En la oraci√≥n `el r√°pido zorro rojo salt√≥ sobre el perro marr√≥n perezoso` hay 2 frases nominales: **r√°pido zorro rojo** y **perro marr√≥n perezoso**.

### An√°lisis de sentimiento

Una oraci√≥n o texto puede analizarse para determinar el sentimiento, o cu√°n *positivo* o *negativo* es. El sentimiento se mide en *polaridad* y *objetividad/subjetividad*. La polaridad se mide de -1.0 a 1.0 (negativo a positivo) y de 0.0 a 1.0 (m√°s objetivo a m√°s subjetivo).

‚úÖ M√°s adelante aprender√°s que hay diferentes formas de determinar el sentimiento utilizando aprendizaje autom√°tico, pero una forma es tener una lista de palabras y frases que han sido categorizadas como positivas o negativas por un experto humano y aplicar ese modelo al texto para calcular un puntaje de polaridad. ¬øPuedes ver c√≥mo esto funcionar√≠a en algunas circunstancias y menos en otras?

### Inflexi√≥n

La inflexi√≥n te permite tomar una palabra y obtener su forma singular o plural.

### Lematizaci√≥n

Un *lema* es la ra√≠z o palabra principal de un conjunto de palabras; por ejemplo, *vol√≥*, *vuela*, *volando* tienen como lema el verbo *volar*.

Tambi√©n hay bases de datos √∫tiles disponibles para el investigador de NLP, en particular:

### WordNet

[WordNet](https://wordnet.princeton.edu/) es una base de datos de palabras, sin√≥nimos, ant√≥nimos y muchos otros detalles para cada palabra en muchos idiomas diferentes. Es incre√≠blemente √∫til al intentar construir traducciones, correctores ortogr√°ficos o herramientas de lenguaje de cualquier tipo.

## Bibliotecas de NLP

Afortunadamente, no tienes que construir todas estas t√©cnicas t√∫ mismo, ya que hay excelentes bibliotecas de Python disponibles que hacen que sea mucho m√°s accesible para desarrolladores que no est√°n especializados en procesamiento de lenguaje natural o aprendizaje autom√°tico. Las pr√≥ximas lecciones incluyen m√°s ejemplos de estas, pero aqu√≠ aprender√°s algunos ejemplos √∫tiles para ayudarte con la pr√≥xima tarea.

### Ejercicio - usando la biblioteca `TextBlob`

Usemos una biblioteca llamada TextBlob, ya que contiene APIs √∫tiles para abordar este tipo de tareas. TextBlob "se basa en los hombros gigantes de [NLTK](https://nltk.org) y [pattern](https://github.com/clips/pattern), y funciona bien con ambos." Tiene una cantidad considerable de ML integrado en su API.

> Nota: Una √∫til [Gu√≠a r√°pida](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) est√° disponible para TextBlob y se recomienda para desarrolladores experimentados en Python.

Al intentar identificar *frases nominales*, TextBlob ofrece varias opciones de extractores para encontrarlas.

1. Echa un vistazo a `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > ¬øQu√© est√° pasando aqu√≠? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) es "Un extractor de frases nominales que utiliza el an√°lisis de fragmentos entrenado con el corpus de entrenamiento ConLL-2000." ConLL-2000 se refiere a la Conferencia de Aprendizaje Computacional de Lenguaje Natural de 2000. Cada a√±o, la conferencia organizaba un taller para abordar un problema dif√≠cil de NLP, y en 2000 fue el an√°lisis de fragmentos nominales. Se entren√≥ un modelo en el Wall Street Journal, con "las secciones 15-18 como datos de entrenamiento (211727 tokens) y la secci√≥n 20 como datos de prueba (47377 tokens)". Puedes ver los procedimientos utilizados [aqu√≠](https://www.clips.uantwerpen.be/conll2000/chunking/) y los [resultados](https://ifarm.nl/erikt/research/np-chunking.html).

### Desaf√≠o - mejorando tu bot con NLP

En la lecci√≥n anterior construiste un bot de preguntas y respuestas muy simple. Ahora, har√°s que Marvin sea un poco m√°s emp√°tico analizando tu entrada para determinar el sentimiento y mostrando una respuesta que coincida con el sentimiento. Tambi√©n necesitar√°s identificar una `frase nominal` y preguntar sobre ella.

Tus pasos al construir un bot conversacional mejorado:

1. Imprime instrucciones aconsejando al usuario c√≥mo interactuar con el bot.  
2. Inicia un bucle:  
   1. Acepta la entrada del usuario.  
   2. Si el usuario ha pedido salir, entonces sal.  
   3. Procesa la entrada del usuario y determina una respuesta de sentimiento adecuada.  
   4. Si se detecta una frase nominal en el sentimiento, plural√≠zala y pide m√°s informaci√≥n sobre ese tema.  
   5. Imprime la respuesta.  
3. Regresa al paso 2.  

Aqu√≠ est√° el fragmento de c√≥digo para determinar el sentimiento usando TextBlob. Nota que solo hay cuatro *gradientes* de respuesta de sentimiento (puedes tener m√°s si lo deseas):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqu√≠ hay un ejemplo de salida para guiarte (la entrada del usuario est√° en las l√≠neas que comienzan con >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Una posible soluci√≥n a la tarea est√° [aqu√≠](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Verificaci√≥n de conocimiento

1. ¬øCrees que las respuestas emp√°ticas podr√≠an 'enga√±ar' a alguien para que piense que el bot realmente los entiende?  
2. ¬øHace que el bot sea m√°s 'cre√≠ble' identificar la frase nominal?  
3. ¬øPor qu√© ser√≠a √∫til extraer una 'frase nominal' de una oraci√≥n?  

---

Implementa el bot en la verificaci√≥n de conocimiento anterior y pru√©balo con un amigo. ¬øPuede enga√±arlos? ¬øPuedes hacer que tu bot sea m√°s 'cre√≠ble'?

## üöÄDesaf√≠o

Toma una tarea de la verificaci√≥n de conocimiento anterior e intenta implementarla. Prueba el bot con un amigo. ¬øPuede enga√±arlos? ¬øPuedes hacer que tu bot sea m√°s 'cre√≠ble'?

## [Cuestionario posterior a la clase](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y autoestudio

En las pr√≥ximas lecciones aprender√°s m√°s sobre an√°lisis de sentimiento. Investiga esta t√©cnica interesante en art√≠culos como estos en [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Tarea 

[Haz que un bot responda](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "be03c8182982b87ced155e4e9d1438e8",
  "translation_date": "2025-09-04T22:29:03+00:00",
  "source_file": "6-NLP/3-Translation-Sentiment/README.md",
  "language_code": "es"
}
-->
# Traducci√≥n y an√°lisis de sentimientos con ML

En las lecciones anteriores aprendiste c√≥mo construir un bot b√°sico utilizando `TextBlob`, una biblioteca que incorpora ML detr√°s de escena para realizar tareas b√°sicas de PLN como la extracci√≥n de frases nominales. Otro desaf√≠o importante en la ling√º√≠stica computacional es la _traducci√≥n_ precisa de una oraci√≥n de un idioma hablado o escrito a otro.

## [Cuestionario previo a la clase](https://ff-quizzes.netlify.app/en/ml/)

La traducci√≥n es un problema muy dif√≠cil, agravado por el hecho de que hay miles de idiomas y cada uno puede tener reglas gramaticales muy diferentes. Una de las aproximaciones es convertir las reglas gramaticales formales de un idioma, como el ingl√©s, en una estructura independiente del idioma, y luego traducirla convirti√©ndola nuevamente a otro idioma. Este enfoque implica los siguientes pasos:

1. **Identificaci√≥n**. Identificar o etiquetar las palabras en el idioma de entrada como sustantivos, verbos, etc.
2. **Crear la traducci√≥n**. Producir una traducci√≥n directa de cada palabra en el formato del idioma de destino.

### Ejemplo de oraci√≥n, ingl√©s a irland√©s

En 'ingl√©s', la oraci√≥n _I feel happy_ tiene tres palabras en el orden:

- **sujeto** (I)
- **verbo** (feel)
- **adjetivo** (happy)

Sin embargo, en el idioma 'irland√©s', la misma oraci√≥n tiene una estructura gramatical muy diferente: las emociones como "*happy*" o "*sad*" se expresan como algo que est√° *sobre* ti.

La frase en ingl√©s `I feel happy` en irland√©s ser√≠a `T√° athas orm`. Una traducci√≥n *literal* ser√≠a `Happy is upon me`.

Un hablante de irland√©s que traduce al ingl√©s dir√≠a `I feel happy`, no `Happy is upon me`, porque entiende el significado de la oraci√≥n, incluso si las palabras y la estructura de la oraci√≥n son diferentes.

El orden formal de la oraci√≥n en irland√©s es:

- **verbo** (T√° o is)
- **adjetivo** (athas, o happy)
- **sujeto** (orm, o upon me)

## Traducci√≥n

Un programa de traducci√≥n ingenuo podr√≠a traducir solo palabras, ignorando la estructura de la oraci√≥n.

‚úÖ Si has aprendido un segundo (o tercer o m√°s) idioma como adulto, es posible que hayas comenzado pensando en tu idioma nativo, traduciendo un concepto palabra por palabra en tu cabeza al segundo idioma y luego expresando tu traducci√≥n. Esto es similar a lo que hacen los programas de traducci√≥n computacional ingenuos. ¬°Es importante superar esta fase para alcanzar la fluidez!

La traducci√≥n ingenua lleva a malas (y a veces hilarantes) malas traducciones: `I feel happy` se traduce literalmente como `Mise bhraitheann athas` en irland√©s. Eso significa (literalmente) `me feel happy` y no es una oraci√≥n v√°lida en irland√©s. Aunque el ingl√©s y el irland√©s son idiomas hablados en dos islas vecinas, son idiomas muy diferentes con estructuras gramaticales distintas.

> Puedes ver algunos videos sobre las tradiciones ling√º√≠sticas irlandesas como [este](https://www.youtube.com/watch?v=mRIaLSdRMMs)

### Enfoques de aprendizaje autom√°tico

Hasta ahora, has aprendido sobre el enfoque de reglas formales para el procesamiento del lenguaje natural. Otro enfoque es ignorar el significado de las palabras y _en su lugar usar aprendizaje autom√°tico para detectar patrones_. Esto puede funcionar en la traducci√≥n si tienes muchos textos (un *corpus*) o textos (*corpora*) en ambos idiomas, el de origen y el de destino.

Por ejemplo, considera el caso de *Orgullo y Prejuicio*, una novela inglesa muy conocida escrita por Jane Austen en 1813. Si consultas el libro en ingl√©s y una traducci√≥n humana del libro en *franc√©s*, podr√≠as detectar frases en uno que se traducen _idiom√°ticamente_ al otro. Har√°s esto en un momento.

Por ejemplo, cuando una frase en ingl√©s como `I have no money` se traduce literalmente al franc√©s, podr√≠a convertirse en `Je n'ai pas de monnaie`. "Monnaie" es un falso cognado franc√©s complicado, ya que 'money' y 'monnaie' no son sin√≥nimos. Una mejor traducci√≥n que un humano podr√≠a hacer ser√≠a `Je n'ai pas d'argent`, porque transmite mejor el significado de que no tienes dinero (en lugar de 'cambio suelto', que es el significado de 'monnaie').

![monnaie](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/6-NLP/3-Translation-Sentiment/images/monnaie.png)

> Imagen por [Jen Looper](https://twitter.com/jenlooper)

Si un modelo de ML tiene suficientes traducciones humanas para construir un modelo, puede mejorar la precisi√≥n de las traducciones identificando patrones comunes en textos que han sido previamente traducidos por hablantes humanos expertos de ambos idiomas.

### Ejercicio - traducci√≥n

Puedes usar `TextBlob` para traducir oraciones. Prueba la famosa primera l√≠nea de **Orgullo y Prejuicio**:

```python
from textblob import TextBlob

blob = TextBlob(
    "It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife!"
)
print(blob.translate(to="fr"))

```

`TextBlob` hace un buen trabajo con la traducci√≥n: "C'est une v√©rit√© universellement reconnue, qu'un homme c√©libataire en possession d'une bonne fortune doit avoir besoin d'une femme!". 

Se puede argumentar que la traducci√≥n de TextBlob es mucho m√°s precisa, de hecho, que la traducci√≥n francesa de 1932 del libro por V. Leconte y Ch. Pressoir:

"C'est une v√©rit√© universelle qu'un c√©libataire pourvu d'une belle fortune doit avoir envie de se marier, et, si peu que l'on sache de son sentiment √† cet egard, lorsqu'il arrive dans une nouvelle r√©sidence, cette id√©e est si bien fix√©e dans l'esprit de ses voisins qu'ils le consid√®rent sur-le-champ comme la propri√©t√© l√©gitime de l'une ou l'autre de leurs filles."

En este caso, la traducci√≥n informada por ML hace un mejor trabajo que el traductor humano que pone innecesariamente palabras en la boca del autor original para 'claridad'.

> ¬øQu√© est√° pasando aqu√≠? ¬øY por qu√© TextBlob es tan bueno en la traducci√≥n? Bueno, detr√°s de escena, est√° utilizando Google Translate, una IA sofisticada capaz de analizar millones de frases para predecir las mejores cadenas para la tarea en cuesti√≥n. No hay nada manual aqu√≠ y necesitas una conexi√≥n a internet para usar `blob.translate`.

‚úÖ Prueba algunas oraciones m√°s. ¬øCu√°l es mejor, la traducci√≥n por ML o la humana? ¬øEn qu√© casos?

## An√°lisis de sentimientos

Otra √°rea donde el aprendizaje autom√°tico puede funcionar muy bien es el an√°lisis de sentimientos. Un enfoque no basado en ML para el sentimiento es identificar palabras y frases que son 'positivas' y 'negativas'. Luego, dado un nuevo texto, calcular el valor total de las palabras positivas, negativas y neutrales para identificar el sentimiento general. 

Este enfoque es f√°cilmente enga√±ado, como habr√°s visto en la tarea de Marvin: la oraci√≥n `Great, that was a wonderful waste of time, I'm glad we are lost on this dark road` es una oraci√≥n sarc√°stica de sentimiento negativo, pero el algoritmo simple detecta 'great', 'wonderful', 'glad' como positivas y 'waste', 'lost' y 'dark' como negativas. El sentimiento general se ve influido por estas palabras conflictivas.

‚úÖ Detente un momento y piensa en c√≥mo transmitimos sarcasmo como hablantes humanos. La inflexi√≥n del tono juega un papel importante. Intenta decir la frase "Well, that film was awesome" de diferentes maneras para descubrir c√≥mo tu voz transmite significado.

### Enfoques de ML

El enfoque de ML ser√≠a reunir manualmente cuerpos de texto negativos y positivos: tweets, rese√±as de pel√≠culas o cualquier cosa donde el humano haya dado una puntuaci√≥n *y* una opini√≥n escrita. Luego se pueden aplicar t√©cnicas de PLN a las opiniones y puntuaciones, para que emerjan patrones (por ejemplo, las rese√±as de pel√≠culas positivas tienden a tener la frase 'Oscar worthy' m√°s que las rese√±as negativas, o las rese√±as positivas de restaurantes dicen 'gourmet' mucho m√°s que 'disgusting').

> ‚öñÔ∏è **Ejemplo**: Si trabajas en la oficina de un pol√≠tico y se est√° debatiendo una nueva ley, los ciudadanos podr√≠an escribir correos electr√≥nicos a la oficina apoyando o en contra de la ley en particular. Supongamos que te encargan leer los correos electr√≥nicos y clasificarlos en 2 grupos, *a favor* y *en contra*. Si hubiera muchos correos electr√≥nicos, podr√≠as sentirte abrumado intentando leerlos todos. ¬øNo ser√≠a genial si un bot pudiera leerlos todos por ti, entenderlos y decirte en qu√© grupo pertenece cada correo electr√≥nico? 
> 
> Una forma de lograr esto es usar aprendizaje autom√°tico. Entrenar√≠as el modelo con una parte de los correos electr√≥nicos *en contra* y una parte de los correos electr√≥nicos *a favor*. El modelo tender√≠a a asociar frases y palabras con el lado en contra y el lado a favor, *pero no entender√≠a ninguno de los contenidos*, solo que ciertas palabras y patrones son m√°s propensos a aparecer en un correo electr√≥nico *en contra* o *a favor*. Podr√≠as probarlo con algunos correos electr√≥nicos que no hayas usado para entrenar el modelo y ver si llega a la misma conclusi√≥n que t√∫. Luego, una vez que est√©s satisfecho con la precisi√≥n del modelo, podr√≠as procesar correos electr√≥nicos futuros sin tener que leer cada uno.

‚úÖ ¬øEste proceso te suena similar a procesos que has usado en lecciones anteriores?

## Ejercicio - oraciones sentimentales

El sentimiento se mide con una *polaridad* de -1 a 1, donde -1 es el sentimiento m√°s negativo y 1 es el m√°s positivo. El sentimiento tambi√©n se mide con una puntuaci√≥n de 0 - 1 para objetividad (0) y subjetividad (1).

Echa otro vistazo a *Orgullo y Prejuicio* de Jane Austen. El texto est√° disponible aqu√≠ en [Project Gutenberg](https://www.gutenberg.org/files/1342/1342-h/1342-h.htm). El siguiente ejemplo muestra un programa corto que analiza el sentimiento de las primeras y √∫ltimas oraciones del libro y muestra su polaridad de sentimiento y puntuaci√≥n de subjetividad/objetividad.

Debes usar la biblioteca `TextBlob` (descrita anteriormente) para determinar el `sentimiento` (no necesitas escribir tu propio calculador de sentimientos) en la siguiente tarea.

```python
from textblob import TextBlob

quote1 = """It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife."""

quote2 = """Darcy, as well as Elizabeth, really loved them; and they were both ever sensible of the warmest gratitude towards the persons who, by bringing her into Derbyshire, had been the means of uniting them."""

sentiment1 = TextBlob(quote1).sentiment
sentiment2 = TextBlob(quote2).sentiment

print(quote1 + " has a sentiment of " + str(sentiment1))
print(quote2 + " has a sentiment of " + str(sentiment2))
```

Ves el siguiente resultado:

```output
It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want # of a wife. has a sentiment of Sentiment(polarity=0.20952380952380953, subjectivity=0.27142857142857146)

Darcy, as well as Elizabeth, really loved them; and they were
     both ever sensible of the warmest gratitude towards the persons
      who, by bringing her into Derbyshire, had been the means of
      uniting them. has a sentiment of Sentiment(polarity=0.7, subjectivity=0.8)
```

## Desaf√≠o - verificar polaridad de sentimientos

Tu tarea es determinar, utilizando la polaridad de sentimientos, si *Orgullo y Prejuicio* tiene m√°s oraciones absolutamente positivas que absolutamente negativas. Para esta tarea, puedes asumir que una puntuaci√≥n de polaridad de 1 o -1 es absolutamente positiva o negativa respectivamente.

**Pasos:**

1. Descarga una [copia de Orgullo y Prejuicio](https://www.gutenberg.org/files/1342/1342-h/1342-h.htm) de Project Gutenberg como un archivo .txt. Elimina los metadatos al inicio y al final del archivo, dejando solo el texto original.
2. Abre el archivo en Python y extrae el contenido como una cadena.
3. Crea un TextBlob utilizando la cadena del libro.
4. Analiza cada oraci√≥n del libro en un bucle.
   1. Si la polaridad es 1 o -1, almacena la oraci√≥n en un array o lista de mensajes positivos o negativos.
5. Al final, imprime todas las oraciones positivas y negativas (por separado) y el n√∫mero de cada una.

Aqu√≠ hay una [soluci√≥n de ejemplo](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/3-Translation-Sentiment/solution/notebook.ipynb).

‚úÖ Verificaci√≥n de conocimiento

1. El sentimiento se basa en las palabras utilizadas en la oraci√≥n, pero ¬øel c√≥digo *entiende* las palabras?
2. ¬øCrees que la polaridad de sentimientos es precisa, o en otras palabras, ¬øest√°s de acuerdo con las puntuaciones?
   1. En particular, ¬øest√°s de acuerdo o en desacuerdo con la polaridad absolutamente **positiva** de las siguientes oraciones?
      * ‚ÄúWhat an excellent father you have, girls!‚Äù said she, when the door was shut.
      * ‚ÄúYour examination of Mr. Darcy is over, I presume,‚Äù said Miss Bingley; ‚Äúand pray what is the result?‚Äù ‚ÄúI am perfectly convinced by it that Mr. Darcy has no defect.
      * How wonderfully these sort of things occur!
      * I have the greatest dislike in the world to that sort of thing.
      * Charlotte is an excellent manager, I dare say.
      * ‚ÄúThis is delightful indeed!
      * I am so happy!
      * Your idea of the ponies is delightful.
   2. Las siguientes 3 oraciones fueron puntuadas con un sentimiento absolutamente positivo, pero al leerlas detenidamente, no son oraciones positivas. ¬øPor qu√© el an√°lisis de sentimientos pens√≥ que eran oraciones positivas?
      * Happy shall I be, when his stay at Netherfield is over!‚Äù ‚ÄúI wish I could say anything to comfort you,‚Äù replied Elizabeth; ‚Äúbut it is wholly out of my power.
      * If I could but see you as happy!
      * Our distress, my dear Lizzy, is very great.
   3. ¬øEst√°s de acuerdo o en desacuerdo con la polaridad absolutamente **negativa** de las siguientes oraciones?
      - Everybody is disgusted with his pride.
      - ‚ÄúI should like to know how he behaves among strangers.‚Äù ‚ÄúYou shall hear then‚Äîbut prepare yourself for something very dreadful.
      - The pause was to Elizabeth‚Äôs feelings dreadful.
      - It would be dreadful!

‚úÖ Cualquier aficionado a Jane Austen entender√° que ella a menudo usa sus libros para criticar los aspectos m√°s rid√≠culos de la sociedad de la Regencia inglesa. Elizabeth Bennett, el personaje principal en *Orgullo y Prejuicio*, es una observadora social aguda (como la autora) y su lenguaje a menudo est√° muy matizado. Incluso Mr. Darcy (el inter√©s amoroso en la historia) nota el uso juguet√≥n y burl√≥n del lenguaje por parte de Elizabeth: "He tenido el placer de conocerte lo suficiente como para saber que disfrutas mucho ocasionalmente profesando opiniones que en realidad no son tuyas".

---

## üöÄDesaf√≠o

¬øPuedes mejorar a Marvin a√∫n m√°s extrayendo otras caracter√≠sticas de la entrada del usuario?

## [Cuestionario posterior a la clase](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y autoestudio
Hay muchas maneras de extraer el sentimiento de un texto. Piensa en las aplicaciones empresariales que podr√≠an utilizar esta t√©cnica. Reflexiona sobre c√≥mo podr√≠a salir mal. Lee m√°s sobre sistemas sofisticados y listos para empresas que analizan sentimientos, como [Azure Text Analysis](https://docs.microsoft.com/azure/cognitive-services/Text-Analytics/how-tos/text-analytics-how-to-sentiment-analysis?tabs=version-3-1?WT.mc_id=academic-77952-leestott). Prueba algunas de las frases de Orgullo y Prejuicio mencionadas anteriormente y observa si puede detectar matices.

## Tarea

[Licencia po√©tica](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8d32dadeda93c6fb5c43619854882ab1",
  "translation_date": "2025-09-04T22:27:31+00:00",
  "source_file": "6-NLP/4-Hotel-Reviews-1/README.md",
  "language_code": "es"
}
-->
# An√°lisis de sentimientos con rese√±as de hoteles - procesando los datos

En esta secci√≥n, utilizar√°s las t√©cnicas de las lecciones anteriores para realizar un an√°lisis exploratorio de datos en un conjunto de datos grande. Una vez que tengas una buena comprensi√≥n de la utilidad de las diferentes columnas, aprender√°s:

- c√≥mo eliminar las columnas innecesarias
- c√≥mo calcular nuevos datos basados en las columnas existentes
- c√≥mo guardar el conjunto de datos resultante para usarlo en el desaf√≠o final

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

### Introducci√≥n

Hasta ahora has aprendido que los datos de texto son bastante diferentes de los datos num√©ricos. Si el texto fue escrito o hablado por un humano, puede analizarse para encontrar patrones, frecuencias, sentimientos y significados. Esta lecci√≥n te lleva a un conjunto de datos real con un desaf√≠o real: **[515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)**, que incluye una [licencia CC0: Dominio P√∫blico](https://creativecommons.org/publicdomain/zero/1.0/). Fue recopilado de Booking.com a partir de fuentes p√∫blicas. El creador del conjunto de datos es Jiashen Liu.

### Preparaci√≥n

Necesitar√°s:

* La capacidad de ejecutar notebooks .ipynb usando Python 3
* pandas
* NLTK, [que deber√≠as instalar localmente](https://www.nltk.org/install.html)
* El conjunto de datos disponible en Kaggle [515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe). Tiene un tama√±o aproximado de 230 MB descomprimido. Desc√°rgalo en la carpeta ra√≠z `/data` asociada con estas lecciones de NLP.

## An√°lisis exploratorio de datos

Este desaf√≠o asume que est√°s construyendo un bot de recomendaci√≥n de hoteles utilizando an√°lisis de sentimientos y puntuaciones de rese√±as de hu√©spedes. El conjunto de datos que usar√°s incluye rese√±as de 1493 hoteles diferentes en 6 ciudades.

Usando Python, un conjunto de datos de rese√±as de hoteles y el an√°lisis de sentimientos de NLTK, podr√≠as descubrir:

* ¬øCu√°les son las palabras y frases m√°s utilizadas en las rese√±as?
* ¬øLas *etiquetas* oficiales que describen un hotel se correlacionan con las puntuaciones de las rese√±as (por ejemplo, hay rese√±as m√°s negativas para un hotel en particular por *Familia con ni√±os peque√±os* que por *Viajero solo*, lo que podr√≠a indicar que es mejor para *Viajeros solos*)?
* ¬øLas puntuaciones de sentimientos de NLTK "coinciden" con la puntuaci√≥n num√©rica del revisor del hotel?

#### Conjunto de datos

Exploremos el conjunto de datos que has descargado y guardado localmente. Abre el archivo en un editor como VS Code o incluso Excel.

Los encabezados en el conjunto de datos son los siguientes:

*Hotel_Address, Additional_Number_of_Scoring, Review_Date, Average_Score, Hotel_Name, Reviewer_Nationality, Negative_Review, Review_Total_Negative_Word_Counts, Total_Number_of_Reviews, Positive_Review, Review_Total_Positive_Word_Counts, Total_Number_of_Reviews_Reviewer_Has_Given, Reviewer_Score, Tags, days_since_review, lat, lng*

Aqu√≠ est√°n agrupados de una manera que podr√≠a ser m√°s f√°cil de examinar: 
##### Columnas del hotel

* `Hotel_Name`, `Hotel_Address`, `lat` (latitud), `lng` (longitud)
  * Usando *lat* y *lng* podr√≠as trazar un mapa con Python mostrando las ubicaciones de los hoteles (quiz√°s codificado por colores para rese√±as negativas y positivas)
  * Hotel_Address no parece ser √∫til para nosotros, y probablemente lo reemplazaremos con un pa√≠s para facilitar la clasificaci√≥n y b√∫squeda

**Columnas de meta-rese√±as del hotel**

* `Average_Score`
  * Seg√∫n el creador del conjunto de datos, esta columna es la *Puntuaci√≥n promedio del hotel, calculada en base al √∫ltimo comentario del √∫ltimo a√±o*. Esto parece una forma inusual de calcular la puntuaci√≥n, pero es el dato recopilado, as√≠ que por ahora lo tomaremos como v√°lido.
  
  ‚úÖ Bas√°ndote en las otras columnas de este conjunto de datos, ¬øpuedes pensar en otra forma de calcular la puntuaci√≥n promedio?

* `Total_Number_of_Reviews`
  * El n√∫mero total de rese√±as que ha recibido este hotel - no est√° claro (sin escribir algo de c√≥digo) si esto se refiere a las rese√±as en el conjunto de datos.
* `Additional_Number_of_Scoring`
  * Esto significa que se dio una puntuaci√≥n de rese√±a pero no se escribi√≥ una rese√±a positiva o negativa por parte del revisor.

**Columnas de rese√±as**

- `Reviewer_Score`
  - Este es un valor num√©rico con un m√°ximo de 1 decimal entre los valores m√≠nimos y m√°ximos 2.5 y 10
  - No se explica por qu√© 2.5 es la puntuaci√≥n m√°s baja posible
- `Negative_Review`
  - Si un revisor no escribi√≥ nada, este campo tendr√° "**No Negative**"
  - Ten en cuenta que un revisor puede escribir una rese√±a positiva en la columna de rese√±a negativa (por ejemplo, "no hay nada malo en este hotel")
- `Review_Total_Negative_Word_Counts`
  - Un mayor conteo de palabras negativas indica una puntuaci√≥n m√°s baja (sin verificar la sentimentalidad)
- `Positive_Review`
  - Si un revisor no escribi√≥ nada, este campo tendr√° "**No Positive**"
  - Ten en cuenta que un revisor puede escribir una rese√±a negativa en la columna de rese√±a positiva (por ejemplo, "no hay nada bueno en este hotel en absoluto")
- `Review_Total_Positive_Word_Counts`
  - Un mayor conteo de palabras positivas indica una puntuaci√≥n m√°s alta (sin verificar la sentimentalidad)
- `Review_Date` y `days_since_review`
  - Se podr√≠a aplicar una medida de frescura o antig√ºedad a una rese√±a (las rese√±as m√°s antiguas podr√≠an no ser tan precisas como las m√°s recientes debido a cambios en la gesti√≥n del hotel, renovaciones, adici√≥n de una piscina, etc.)
- `Tags`
  - Estas son descripciones breves que un revisor puede seleccionar para describir el tipo de hu√©sped que era (por ejemplo, solo o en familia), el tipo de habitaci√≥n que ten√≠a, la duraci√≥n de la estancia y c√≥mo se envi√≥ la rese√±a.
  - Desafortunadamente, usar estas etiquetas es problem√°tico, consulta la secci√≥n a continuaci√≥n que discute su utilidad.

**Columnas del revisor**

- `Total_Number_of_Reviews_Reviewer_Has_Given`
  - Esto podr√≠a ser un factor en un modelo de recomendaci√≥n, por ejemplo, si pudieras determinar que los revisores m√°s prol√≠ficos con cientos de rese√±as eran m√°s propensos a ser negativos que positivos. Sin embargo, el revisor de cualquier rese√±a en particular no est√° identificado con un c√≥digo √∫nico, y por lo tanto no puede vincularse a un conjunto de rese√±as. Hay 30 revisores con 100 o m√°s rese√±as, pero es dif√≠cil ver c√≥mo esto puede ayudar al modelo de recomendaci√≥n.
- `Reviewer_Nationality`
  - Algunas personas podr√≠an pensar que ciertas nacionalidades son m√°s propensas a dar una rese√±a positiva o negativa debido a una inclinaci√≥n nacional. Ten cuidado al construir este tipo de puntos de vista anecd√≥ticos en tus modelos. Estos son estereotipos nacionales (y a veces raciales), y cada revisor fue un individuo que escribi√≥ una rese√±a basada en su experiencia. Esta pudo haber sido filtrada a trav√©s de muchas perspectivas, como sus estancias previas en hoteles, la distancia recorrida y su temperamento personal. Pensar que su nacionalidad fue la raz√≥n de una puntuaci√≥n de rese√±a es dif√≠cil de justificar.

##### Ejemplos

| Average  Score | Total Number   Reviews | Reviewer   Score | Negative <br />Review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Positive   Review                 | Tags                                                                                      |
| -------------- | ---------------------- | ---------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------- | ----------------------------------------------------------------------------------------- |
| 7.8            | 1945                   | 2.5              | Este no es actualmente un hotel sino un sitio de construcci√≥n. Fui aterrorizado desde temprano en la ma√±ana y todo el d√≠a con ruidos de construcci√≥n inaceptables mientras descansaba despu√©s de un largo viaje y trabajaba en la habitaci√≥n. La gente trabajaba todo el d√≠a, es decir, con martillos neum√°ticos en las habitaciones adyacentes. Ped√≠ un cambio de habitaci√≥n pero no hab√≠a ninguna habitaci√≥n silenciosa disponible. Para empeorar las cosas, me cobraron de m√°s. Me fui en la noche ya que ten√≠a un vuelo muy temprano y recib√≠ una factura adecuada. Un d√≠a despu√©s, el hotel hizo otro cargo sin mi consentimiento por encima del precio reservado. Es un lugar terrible. No te castigues reservando aqu√≠. | Nada. Lugar terrible. Al√©jate.   | Viaje de negocios. Pareja. Habitaci√≥n doble est√°ndar. Estancia de 2 noches.              |

Como puedes ver, este hu√©sped no tuvo una estancia feliz en este hotel. El hotel tiene una buena puntuaci√≥n promedio de 7.8 y 1945 rese√±as, pero este revisor le dio un 2.5 y escribi√≥ 115 palabras sobre lo negativa que fue su estancia. Si no escribi√≥ nada en absoluto en la columna Positive_Review, podr√≠as deducir que no hubo nada positivo, pero a√∫n as√≠ escribi√≥ 7 palabras de advertencia. Si solo cont√°ramos palabras en lugar del significado o sentimiento de las palabras, podr√≠amos tener una visi√≥n sesgada de la intenci√≥n del revisor. Curiosamente, su puntuaci√≥n de 2.5 es confusa, porque si esa estancia en el hotel fue tan mala, ¬øpor qu√© darle alg√∫n punto? Al investigar el conjunto de datos de cerca, ver√°s que la puntuaci√≥n m√°s baja posible es 2.5, no 0. La puntuaci√≥n m√°s alta posible es 10.

##### Tags

Como se mencion√≥ anteriormente, a primera vista, la idea de usar `Tags` para categorizar los datos tiene sentido. Desafortunadamente, estas etiquetas no est√°n estandarizadas, lo que significa que en un hotel dado, las opciones podr√≠an ser *Habitaci√≥n individual*, *Habitaci√≥n doble*, y *Habitaci√≥n twin*, pero en el siguiente hotel, son *Habitaci√≥n individual deluxe*, *Habitaci√≥n cl√°sica queen*, y *Habitaci√≥n ejecutiva king*. Podr√≠an ser lo mismo, pero hay tantas variaciones que la elecci√≥n se convierte en:

1. Intentar cambiar todos los t√©rminos a un est√°ndar √∫nico, lo cual es muy dif√≠cil, porque no est√° claro cu√°l ser√≠a el camino de conversi√≥n en cada caso (por ejemplo, *Habitaci√≥n individual cl√°sica* se mapea a *Habitaci√≥n individual* pero *Habitaci√≥n superior queen con vista al jard√≠n del patio o a la ciudad* es mucho m√°s dif√≠cil de mapear).

1. Podemos tomar un enfoque de NLP y medir la frecuencia de ciertos t√©rminos como *Solo*, *Viajero de negocios*, o *Familia con ni√±os peque√±os* seg√∫n se aplican a cada hotel, y factorizar eso en la recomendaci√≥n.

Las etiquetas suelen ser (pero no siempre) un solo campo que contiene una lista de 5 a 6 valores separados por comas que se alinean con *Tipo de viaje*, *Tipo de hu√©spedes*, *Tipo de habitaci√≥n*, *N√∫mero de noches*, y *Tipo de dispositivo en el que se envi√≥ la rese√±a*. Sin embargo, debido a que algunos revisores no completan cada campo (pueden dejar uno en blanco), los valores no siempre est√°n en el mismo orden.

Como ejemplo, toma *Tipo de grupo*. Hay 1025 posibilidades √∫nicas en este campo en la columna `Tags`, y desafortunadamente solo algunas de ellas se refieren a un grupo (algunas son el tipo de habitaci√≥n, etc.). Si filtras solo las que mencionan familia, los resultados contienen muchos resultados del tipo *Habitaci√≥n familiar*. Si incluyes el t√©rmino *con*, es decir, cuentas los valores *Familia con*, los resultados son mejores, con m√°s de 80,000 de los 515,000 resultados que contienen la frase "Familia con ni√±os peque√±os" o "Familia con ni√±os mayores".

Esto significa que la columna de etiquetas no es completamente in√∫til para nosotros, pero requerir√° algo de trabajo para hacerla √∫til.

##### Puntuaci√≥n promedio del hotel

Hay una serie de rarezas o discrepancias con el conjunto de datos que no puedo resolver, pero se ilustran aqu√≠ para que est√©s al tanto de ellas al construir tus modelos. Si lo resuelves, por favor h√°znoslo saber en la secci√≥n de discusi√≥n.

El conjunto de datos tiene las siguientes columnas relacionadas con la puntuaci√≥n promedio y el n√∫mero de rese√±as:

1. Hotel_Name
2. Additional_Number_of_Scoring
3. Average_Score
4. Total_Number_of_Reviews
5. Reviewer_Score  

El √∫nico hotel con m√°s rese√±as en este conjunto de datos es *Britannia International Hotel Canary Wharf* con 4789 rese√±as de 515,000. Pero si miramos el valor de `Total_Number_of_Reviews` para este hotel, es 9086. Podr√≠as deducir que hay muchas m√°s puntuaciones sin rese√±as, as√≠ que tal vez deber√≠amos sumar el valor de la columna `Additional_Number_of_Scoring`. Ese valor es 2682, y sum√°ndolo a 4789 obtenemos 7471, que a√∫n est√° 1615 por debajo de `Total_Number_of_Reviews`.

Si tomas la columna `Average_Score`, podr√≠as deducir que es el promedio de las rese√±as en el conjunto de datos, pero la descripci√≥n de Kaggle es "*Puntuaci√≥n promedio del hotel, calculada en base al √∫ltimo comentario del √∫ltimo a√±o*". Eso no parece muy √∫til, pero podemos calcular nuestro propio promedio basado en las puntuaciones de las rese√±as en el conjunto de datos. Usando el mismo hotel como ejemplo, la puntuaci√≥n promedio del hotel se da como 7.1 pero la puntuaci√≥n calculada (promedio de las puntuaciones de los revisores *en* el conjunto de datos) es 6.8. Esto es cercano, pero no el mismo valor, y solo podemos suponer que las puntuaciones dadas en las rese√±as de `Additional_Number_of_Scoring` aumentaron el promedio a 7.1. Desafortunadamente, sin forma de probar o demostrar esa afirmaci√≥n, es dif√≠cil usar o confiar en `Average_Score`, `Additional_Number_of_Scoring` y `Total_Number_of_Reviews` cuando se basan en, o se refieren a, datos que no tenemos.

Para complicar a√∫n m√°s las cosas, el hotel con el segundo mayor n√∫mero de rese√±as tiene una puntuaci√≥n promedio calculada de 8.12 y la `Average_Score` del conjunto de datos es 8.1. ¬øEs esta puntuaci√≥n correcta una coincidencia o es el primer hotel una discrepancia?

En la posibilidad de que este hotel pueda ser un caso at√≠pico, y que tal vez la mayor√≠a de los valores coincidan (pero algunos no por alguna raz√≥n), escribiremos un programa corto a continuaci√≥n para explorar los valores en el conjunto de datos y determinar el uso correcto (o no uso) de los valores.
> üö® Una nota de precauci√≥n  
>  
> Al trabajar con este conjunto de datos, escribir√°s c√≥digo que calcula algo a partir del texto sin necesidad de leer o analizar el texto t√∫ mismo. Esta es la esencia del procesamiento de lenguaje natural (NLP), interpretar el significado o el sentimiento sin que un humano tenga que hacerlo. Sin embargo, es posible que leas algunas de las rese√±as negativas. Te recomendar√≠a que no lo hagas, porque no es necesario. Algunas de ellas son absurdas o irrelevantes, como rese√±as negativas de hoteles que dicen: "El clima no fue bueno", algo que est√° fuera del control del hotel, o de cualquier persona. Pero tambi√©n hay un lado oscuro en algunas rese√±as. A veces, las rese√±as negativas son racistas, sexistas o discriminatorias por edad. Esto es desafortunado pero esperable en un conjunto de datos extra√≠do de un sitio web p√∫blico. Algunos usuarios dejan rese√±as que podr√≠an resultarte desagradables, inc√≥modas o perturbadoras. Es mejor dejar que el c√≥digo mida el sentimiento en lugar de leerlas t√∫ mismo y sentirte afectado. Dicho esto, es una minor√≠a la que escribe este tipo de cosas, pero existen de todos modos.
## Ejercicio - Exploraci√≥n de datos
### Cargar los datos

Ya basta de examinar los datos visualmente, ¬°ahora escribir√°s algo de c√≥digo y obtendr√°s respuestas! Esta secci√≥n utiliza la biblioteca pandas. Tu primera tarea es asegurarte de que puedes cargar y leer los datos en formato CSV. La biblioteca pandas tiene un cargador r√°pido de CSV, y el resultado se coloca en un dataframe, como en lecciones anteriores. El CSV que estamos cargando tiene m√°s de medio mill√≥n de filas, pero solo 17 columnas. Pandas te ofrece muchas formas poderosas de interactuar con un dataframe, incluyendo la capacidad de realizar operaciones en cada fila.

A partir de aqu√≠, en esta lecci√≥n, habr√° fragmentos de c√≥digo y algunas explicaciones del c√≥digo, adem√°s de una discusi√≥n sobre lo que significan los resultados. Usa el archivo _notebook.ipynb_ incluido para tu c√≥digo.

Comencemos cargando el archivo de datos que usar√°s:

```python
# Load the hotel reviews from CSV
import pandas as pd
import time
# importing time so the start and end time can be used to calculate file loading time
print("Loading data file now, this could take a while depending on file size")
start = time.time()
# df is 'DataFrame' - make sure you downloaded the file to the data folder
df = pd.read_csv('../../data/Hotel_Reviews.csv')
end = time.time()
print("Loading took " + str(round(end - start, 2)) + " seconds")
```

Ahora que los datos est√°n cargados, podemos realizar algunas operaciones sobre ellos. Mant√©n este c√≥digo en la parte superior de tu programa para la siguiente parte.

## Explorar los datos

En este caso, los datos ya est√°n *limpios*, lo que significa que est√°n listos para trabajar y no tienen caracteres en otros idiomas que puedan causar problemas a los algoritmos que esperan solo caracteres en ingl√©s.

‚úÖ Es posible que tengas que trabajar con datos que requieran un procesamiento inicial para formatearlos antes de aplicar t√©cnicas de NLP, pero no en esta ocasi√≥n. Si tuvieras que hacerlo, ¬øc√≥mo manejar√≠as los caracteres que no est√°n en ingl√©s?

T√≥mate un momento para asegurarte de que, una vez cargados los datos, puedes explorarlos con c√≥digo. Es muy f√°cil querer centrarse en las columnas `Negative_Review` y `Positive_Review`. Estas est√°n llenas de texto natural para que tus algoritmos de NLP lo procesen. ¬°Pero espera! Antes de sumergirte en el NLP y el an√°lisis de sentimientos, deber√≠as seguir el c√≥digo a continuaci√≥n para verificar si los valores dados en el conjunto de datos coinciden con los valores que calculas con pandas.

## Operaciones con el dataframe

La primera tarea en esta lecci√≥n es verificar si las siguientes afirmaciones son correctas escribiendo algo de c√≥digo que examine el dataframe (sin modificarlo).

> Como en muchas tareas de programaci√≥n, hay varias formas de completarlas, pero un buen consejo es hacerlo de la manera m√°s simple y f√°cil posible, especialmente si ser√° m√°s f√°cil de entender cuando vuelvas a este c√≥digo en el futuro. Con los dataframes, hay una API completa que a menudo tendr√° una forma eficiente de hacer lo que necesitas.

Trata las siguientes preguntas como tareas de codificaci√≥n e intenta responderlas sin mirar la soluci√≥n.

1. Imprime la *forma* del dataframe que acabas de cargar (la forma es el n√∫mero de filas y columnas).
2. Calcula el conteo de frecuencia para las nacionalidades de los revisores:
   1. ¬øCu√°ntos valores distintos hay en la columna `Reviewer_Nationality` y cu√°les son?
   2. ¬øQu√© nacionalidad de revisor es la m√°s com√∫n en el conjunto de datos (imprime el pa√≠s y el n√∫mero de rese√±as)?
   3. ¬øCu√°les son las siguientes 10 nacionalidades m√°s frecuentes y su conteo de frecuencia?
3. ¬øCu√°l fue el hotel m√°s rese√±ado para cada una de las 10 nacionalidades de revisores m√°s frecuentes?
4. ¬øCu√°ntas rese√±as hay por hotel (conteo de frecuencia de hotel) en el conjunto de datos?
5. Aunque hay una columna `Average_Score` para cada hotel en el conjunto de datos, tambi√©n puedes calcular un puntaje promedio (obteniendo el promedio de todos los puntajes de los revisores en el conjunto de datos para cada hotel). Agrega una nueva columna a tu dataframe con el encabezado `Calc_Average_Score` que contenga ese promedio calculado.
6. ¬øHay hoteles que tengan el mismo `Average_Score` (redondeado a 1 decimal) y `Calc_Average_Score`?
   1. Intenta escribir una funci√≥n en Python que tome una Serie (fila) como argumento y compare los valores, imprimiendo un mensaje cuando los valores no sean iguales. Luego usa el m√©todo `.apply()` para procesar cada fila con la funci√≥n.
7. Calcula e imprime cu√°ntas filas tienen valores de la columna `Negative_Review` iguales a "No Negative".
8. Calcula e imprime cu√°ntas filas tienen valores de la columna `Positive_Review` iguales a "No Positive".
9. Calcula e imprime cu√°ntas filas tienen valores de la columna `Positive_Review` iguales a "No Positive" **y** valores de la columna `Negative_Review` iguales a "No Negative".

### Respuestas en c√≥digo

1. Imprime la *forma* del dataframe que acabas de cargar (la forma es el n√∫mero de filas y columnas).

   ```python
   print("The shape of the data (rows, cols) is " + str(df.shape))
   > The shape of the data (rows, cols) is (515738, 17)
   ```

2. Calcula el conteo de frecuencia para las nacionalidades de los revisores:

   1. ¬øCu√°ntos valores distintos hay en la columna `Reviewer_Nationality` y cu√°les son?
   2. ¬øQu√© nacionalidad de revisor es la m√°s com√∫n en el conjunto de datos (imprime el pa√≠s y el n√∫mero de rese√±as)?

   ```python
   # value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality
   nationality_freq = df["Reviewer_Nationality"].value_counts()
   print("There are " + str(nationality_freq.size) + " different nationalities")
   # print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data
   print(nationality_freq) 
   
   There are 227 different nationalities
    United Kingdom               245246
    United States of America      35437
    Australia                     21686
    Ireland                       14827
    United Arab Emirates          10235
                                  ...  
    Comoros                           1
    Palau                             1
    Northern Mariana Islands          1
    Cape Verde                        1
    Guinea                            1
   Name: Reviewer_Nationality, Length: 227, dtype: int64
   ```

   3. ¬øCu√°les son las siguientes 10 nacionalidades m√°s frecuentes y su conteo de frecuencia?

      ```python
      print("The highest frequency reviewer nationality is " + str(nationality_freq.index[0]).strip() + " with " + str(nationality_freq[0]) + " reviews.")
      # Notice there is a leading space on the values, strip() removes that for printing
      # What is the top 10 most common nationalities and their frequencies?
      print("The next 10 highest frequency reviewer nationalities are:")
      print(nationality_freq[1:11].to_string())
      
      The highest frequency reviewer nationality is United Kingdom with 245246 reviews.
      The next 10 highest frequency reviewer nationalities are:
       United States of America     35437
       Australia                    21686
       Ireland                      14827
       United Arab Emirates         10235
       Saudi Arabia                  8951
       Netherlands                   8772
       Switzerland                   8678
       Germany                       7941
       Canada                        7894
       France                        7296
      ```

3. ¬øCu√°l fue el hotel m√°s rese√±ado para cada una de las 10 nacionalidades de revisores m√°s frecuentes?

   ```python
   # What was the most frequently reviewed hotel for the top 10 nationalities
   # Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)
   for nat in nationality_freq[:10].index:
      # First, extract all the rows that match the criteria into a new dataframe
      nat_df = df[df["Reviewer_Nationality"] == nat]   
      # Now get the hotel freq
      freq = nat_df["Hotel_Name"].value_counts()
      print("The most reviewed hotel for " + str(nat).strip() + " was " + str(freq.index[0]) + " with " + str(freq[0]) + " reviews.") 
      
   The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.
   The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.
   The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.
   The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.
   The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.
   The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.
   The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.
   The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.
   The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.
   The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.
   ```

4. ¬øCu√°ntas rese√±as hay por hotel (conteo de frecuencia de hotel) en el conjunto de datos?

   ```python
   # First create a new dataframe based on the old one, removing the uneeded columns
   hotel_freq_df = df.drop(["Hotel_Address", "Additional_Number_of_Scoring", "Review_Date", "Average_Score", "Reviewer_Nationality", "Negative_Review", "Review_Total_Negative_Word_Counts", "Positive_Review", "Review_Total_Positive_Word_Counts", "Total_Number_of_Reviews_Reviewer_Has_Given", "Reviewer_Score", "Tags", "days_since_review", "lat", "lng"], axis = 1)
   
   # Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found
   hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')
   
   # Get rid of all the duplicated rows
   hotel_freq_df = hotel_freq_df.drop_duplicates(subset = ["Hotel_Name"])
   display(hotel_freq_df) 
   ```
   |                 Hotel_Name                 | Total_Number_of_Reviews | Total_Reviews_Found |
   | :----------------------------------------: | :---------------------: | :-----------------: |
   | Britannia International Hotel Canary Wharf |          9086           |        4789         |
   |    Park Plaza Westminster Bridge London    |          12158          |        4169         |
   |   Copthorne Tara Hotel London Kensington   |          7105           |        3578         |
   |                    ...                     |           ...           |         ...         |
   |       Mercure Paris Porte d Orleans        |           110           |         10          |
   |                Hotel Wagner                |           135           |         10          |
   |            Hotel Gallitzinberg             |           173           |          8          |

   Puedes notar que los resultados *contados en el conjunto de datos* no coinciden con el valor en `Total_Number_of_Reviews`. No est√° claro si este valor en el conjunto de datos representa el n√∫mero total de rese√±as que tuvo el hotel, pero no todas fueron extra√≠das, o alg√∫n otro c√°lculo. `Total_Number_of_Reviews` no se utiliza en el modelo debido a esta falta de claridad.

5. Aunque hay una columna `Average_Score` para cada hotel en el conjunto de datos, tambi√©n puedes calcular un puntaje promedio (obteniendo el promedio de todos los puntajes de los revisores en el conjunto de datos para cada hotel). Agrega una nueva columna a tu dataframe con el encabezado `Calc_Average_Score` que contenga ese promedio calculado. Imprime las columnas `Hotel_Name`, `Average_Score` y `Calc_Average_Score`.

   ```python
   # define a function that takes a row and performs some calculation with it
   def get_difference_review_avg(row):
     return row["Average_Score"] - row["Calc_Average_Score"]
   
   # 'mean' is mathematical word for 'average'
   df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)
   
   # Add a new column with the difference between the two average scores
   df["Average_Score_Difference"] = df.apply(get_difference_review_avg, axis = 1)
   
   # Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)
   review_scores_df = df.drop_duplicates(subset = ["Hotel_Name"])
   
   # Sort the dataframe to find the lowest and highest average score difference
   review_scores_df = review_scores_df.sort_values(by=["Average_Score_Difference"])
   
   display(review_scores_df[["Average_Score_Difference", "Average_Score", "Calc_Average_Score", "Hotel_Name"]])
   ```

   Tambi√©n puedes preguntarte sobre el valor de `Average_Score` y por qu√© a veces es diferente del puntaje promedio calculado. Como no podemos saber por qu√© algunos valores coinciden, pero otros tienen una diferencia, lo m√°s seguro en este caso es usar los puntajes de las rese√±as que tenemos para calcular el promedio nosotros mismos. Dicho esto, las diferencias suelen ser muy peque√±as, aqu√≠ est√°n los hoteles con la mayor desviaci√≥n entre el promedio del conjunto de datos y el promedio calculado:

   | Average_Score_Difference | Average_Score | Calc_Average_Score |                                  Hotel_Name |
   | :----------------------: | :-----------: | :----------------: | ------------------------------------------: |
   |           -0.8           |      7.7      |        8.5         |                  Best Western Hotel Astoria |
   |           -0.7           |      8.8      |        9.5         | Hotel Stendhal Place Vend me Paris MGallery |
   |           -0.7           |      7.5      |        8.2         |               Mercure Paris Porte d Orleans |
   |           -0.7           |      7.9      |        8.6         |             Renaissance Paris Vendome Hotel |
   |           -0.5           |      7.0      |        7.5         |                         Hotel Royal Elys es |
   |           ...            |      ...      |        ...         |                                         ... |
   |           0.7            |      7.5      |        6.8         |     Mercure Paris Op ra Faubourg Montmartre |
   |           0.8            |      7.1      |        6.3         |      Holiday Inn Paris Montparnasse Pasteur |
   |           0.9            |      6.8      |        5.9         |                               Villa Eugenie |
   |           0.9            |      8.6      |        7.7         |   MARQUIS Faubourg St Honor Relais Ch teaux |
   |           1.3            |      7.2      |        5.9         |                          Kube Hotel Ice Bar |

   Con solo 1 hotel teniendo una diferencia de puntaje mayor a 1, significa que probablemente podemos ignorar la diferencia y usar el puntaje promedio calculado.

6. Calcula e imprime cu√°ntas filas tienen valores de la columna `Negative_Review` iguales a "No Negative".

7. Calcula e imprime cu√°ntas filas tienen valores de la columna `Positive_Review` iguales a "No Positive".

8. Calcula e imprime cu√°ntas filas tienen valores de la columna `Positive_Review` iguales a "No Positive" **y** valores de la columna `Negative_Review` iguales a "No Negative".

   ```python
   # with lambdas:
   start = time.time()
   no_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" else False , axis=1)
   print("Number of No Negative reviews: " + str(len(no_negative_reviews[no_negative_reviews == True].index)))
   
   no_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of No Positive reviews: " + str(len(no_positive_reviews[no_positive_reviews == True].index)))
   
   both_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" and x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of both No Negative and No Positive reviews: " + str(len(both_no_reviews[both_no_reviews == True].index)))
   end = time.time()
   print("Lambdas took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Lambdas took 9.64 seconds
   ```

## Otra forma

Otra forma de contar elementos sin Lambdas, y usar sum para contar las filas:

   ```python
   # without lambdas (using a mixture of notations to show you can use both)
   start = time.time()
   no_negative_reviews = sum(df.Negative_Review == "No Negative")
   print("Number of No Negative reviews: " + str(no_negative_reviews))
   
   no_positive_reviews = sum(df["Positive_Review"] == "No Positive")
   print("Number of No Positive reviews: " + str(no_positive_reviews))
   
   both_no_reviews = sum((df.Negative_Review == "No Negative") & (df.Positive_Review == "No Positive"))
   print("Number of both No Negative and No Positive reviews: " + str(both_no_reviews))
   
   end = time.time()
   print("Sum took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Sum took 0.19 seconds
   ```

   Puede que hayas notado que hay 127 filas que tienen valores "No Negative" y "No Positive" en las columnas `Negative_Review` y `Positive_Review`, respectivamente. Esto significa que el revisor dio al hotel un puntaje num√©rico, pero se neg√≥ a escribir una rese√±a positiva o negativa. Afortunadamente, esta es una peque√±a cantidad de filas (127 de 515738, o 0.02%), por lo que probablemente no sesgar√° nuestro modelo o resultados en ninguna direcci√≥n en particular, pero podr√≠as no haber esperado que un conjunto de datos de rese√±as tuviera filas sin rese√±as, por lo que vale la pena explorar los datos para descubrir filas como esta.

Ahora que has explorado el conjunto de datos, en la pr√≥xima lecci√≥n filtrar√°s los datos y agregar√°s algo de an√°lisis de sentimientos.

---
## üöÄDesaf√≠o

Esta lecci√≥n demuestra, como vimos en lecciones anteriores, lo cr√≠ticamente importante que es entender tus datos y sus peculiaridades antes de realizar operaciones sobre ellos. Los datos basados en texto, en particular, requieren un escrutinio cuidadoso. Explora varios conjuntos de datos ricos en texto y ve si puedes descubrir √°reas que podr√≠an introducir sesgos o sentimientos distorsionados en un modelo.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y autoestudio

Toma [este Learning Path sobre NLP](https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77952-leestott) para descubrir herramientas que puedes probar al construir modelos basados en texto y voz.

## Tarea 

[NLTK](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2c742993fe95d5bcbb2846eda3d442a1",
  "translation_date": "2025-09-04T22:29:39+00:00",
  "source_file": "6-NLP/5-Hotel-Reviews-2/README.md",
  "language_code": "es"
}
-->
# An√°lisis de sentimientos con rese√±as de hoteles

Ahora que has explorado el conjunto de datos en detalle, es momento de filtrar las columnas y luego usar t√©cnicas de procesamiento de lenguaje natural (NLP) en el conjunto de datos para obtener nuevas perspectivas sobre los hoteles.

## [Cuestionario previo a la clase](https://ff-quizzes.netlify.app/en/ml/)

### Operaciones de filtrado y an√°lisis de sentimientos

Como probablemente hayas notado, el conjunto de datos tiene algunos problemas. Algunas columnas est√°n llenas de informaci√≥n in√∫til, otras parecen incorrectas. Si son correctas, no est√° claro c√≥mo se calcularon, y las respuestas no pueden ser verificadas de manera independiente con tus propios c√°lculos.

## Ejercicio: un poco m√°s de procesamiento de datos

Limpia los datos un poco m√°s. Agrega columnas que ser√°n √∫tiles m√°s adelante, cambia los valores en otras columnas y elimina ciertas columnas por completo.

1. Procesamiento inicial de columnas

   1. Elimina `lat` y `lng`.

   2. Reemplaza los valores de `Hotel_Address` con los siguientes valores (si la direcci√≥n contiene el nombre de la ciudad y el pa√≠s, c√°mbialo por solo la ciudad y el pa√≠s).

      Estas son las √∫nicas ciudades y pa√≠ses en el conjunto de datos:

      √Åmsterdam, Pa√≠ses Bajos

      Barcelona, Espa√±a

      Londres, Reino Unido

      Mil√°n, Italia

      Par√≠s, Francia

      Viena, Austria 

      ```python
      def replace_address(row):
          if "Netherlands" in row["Hotel_Address"]:
              return "Amsterdam, Netherlands"
          elif "Barcelona" in row["Hotel_Address"]:
              return "Barcelona, Spain"
          elif "United Kingdom" in row["Hotel_Address"]:
              return "London, United Kingdom"
          elif "Milan" in row["Hotel_Address"]:        
              return "Milan, Italy"
          elif "France" in row["Hotel_Address"]:
              return "Paris, France"
          elif "Vienna" in row["Hotel_Address"]:
              return "Vienna, Austria" 
      
      # Replace all the addresses with a shortened, more useful form
      df["Hotel_Address"] = df.apply(replace_address, axis = 1)
      # The sum of the value_counts() should add up to the total number of reviews
      print(df["Hotel_Address"].value_counts())
      ```

      Ahora puedes consultar datos a nivel de pa√≠s:

      ```python
      display(df.groupby("Hotel_Address").agg({"Hotel_Name": "nunique"}))
      ```

      | Hotel_Address          | Hotel_Name |
      | :--------------------- | :--------: |
      | √Åmsterdam, Pa√≠ses Bajos |    105     |
      | Barcelona, Espa√±a       |    211     |
      | Londres, Reino Unido    |    400     |
      | Mil√°n, Italia           |    162     |
      | Par√≠s, Francia          |    458     |
      | Viena, Austria          |    158     |

2. Procesar columnas de meta-rese√±as de hoteles

   1. Elimina `Additional_Number_of_Scoring`.

   2. Reemplaza `Total_Number_of_Reviews` con el n√∫mero total de rese√±as para ese hotel que realmente est√°n en el conjunto de datos.

   3. Reemplaza `Average_Score` con nuestro propio puntaje calculado.

   ```python
  # Drop `Additional_Number_of_Scoring`
  df.drop(["Additional_Number_of_Scoring"], axis = 1, inplace=True)
  # Replace `Total_Number_of_Reviews` and `Average_Score` with our own calculated values
  df.Total_Number_of_Reviews = df.groupby('Hotel_Name').transform('count')
  df.Average_Score = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)
  ```

3. Procesar columnas de rese√±as

   1. Elimina `Review_Total_Negative_Word_Counts`, `Review_Total_Positive_Word_Counts`, `Review_Date` y `days_since_review`.

   2. Conserva `Reviewer_Score`, `Negative_Review` y `Positive_Review` tal como est√°n.

   3. Conserva `Tags` por ahora.

      - Realizaremos algunas operaciones de filtrado adicionales en las etiquetas en la siguiente secci√≥n y luego las eliminaremos.

4. Procesar columnas de los revisores

   1. Elimina `Total_Number_of_Reviews_Reviewer_Has_Given`.

   2. Conserva `Reviewer_Nationality`.

### Columnas de etiquetas

La columna `Tag` es problem√°tica ya que es una lista (en forma de texto) almacenada en la columna. Desafortunadamente, el orden y el n√∫mero de subsecciones en esta columna no siempre son los mismos. Es dif√≠cil para un humano identificar las frases correctas de inter√©s, porque hay 515,000 filas y 1427 hoteles, y cada uno tiene opciones ligeramente diferentes que un revisor podr√≠a elegir. Aqu√≠ es donde el NLP brilla. Puedes escanear el texto y encontrar las frases m√°s comunes, y contarlas.

Desafortunadamente, no estamos interesados en palabras individuales, sino en frases de varias palabras (por ejemplo, *Viaje de negocios*). Ejecutar un algoritmo de distribuci√≥n de frecuencia de frases en tantos datos (6762646 palabras) podr√≠a tomar un tiempo extraordinario, pero sin mirar los datos, parecer√≠a que es un gasto necesario. Aqu√≠ es donde el an√°lisis exploratorio de datos resulta √∫til, porque al haber visto una muestra de las etiquetas como `[' Viaje de negocios  ', ' Viajero solo ', ' Habitaci√≥n individual ', ' Estancia de 5 noches ', ' Enviado desde un dispositivo m√≥vil ']`, puedes comenzar a preguntarte si es posible reducir significativamente el procesamiento que tienes que hacer. Afortunadamente, lo es, pero primero necesitas seguir algunos pasos para determinar las etiquetas de inter√©s.

### Filtrar etiquetas

Recuerda que el objetivo del conjunto de datos es agregar sentimientos y columnas que te ayuden a elegir el mejor hotel (para ti o tal vez para un cliente que te encargue crear un bot de recomendaci√≥n de hoteles). Debes preguntarte si las etiquetas son √∫tiles o no en el conjunto de datos final. Aqu√≠ hay una interpretaci√≥n (si necesitaras el conjunto de datos por otras razones, diferentes etiquetas podr√≠an permanecer o salir de la selecci√≥n):

1. El tipo de viaje es relevante y deber√≠a permanecer.
2. El tipo de grupo de hu√©spedes es importante y deber√≠a permanecer.
3. El tipo de habitaci√≥n, suite o estudio en el que se hosped√≥ el hu√©sped es irrelevante (todos los hoteles tienen b√°sicamente las mismas habitaciones).
4. El dispositivo desde el cual se envi√≥ la rese√±a es irrelevante.
5. El n√∫mero de noches que el revisor se hosped√≥ *podr√≠a* ser relevante si atribuyes estancias m√°s largas con que les gust√≥ m√°s el hotel, pero es poco probable y probablemente irrelevante.

En resumen, **conserva 2 tipos de etiquetas y elimina las dem√°s**.

Primero, no quieres contar las etiquetas hasta que est√©n en un formato mejor, lo que significa eliminar los corchetes y las comillas. Puedes hacer esto de varias maneras, pero quieres la m√°s r√°pida ya que podr√≠a tomar mucho tiempo procesar muchos datos. Afortunadamente, pandas tiene una forma f√°cil de realizar cada uno de estos pasos.

```Python
# Remove opening and closing brackets
df.Tags = df.Tags.str.strip("[']")
# remove all quotes too
df.Tags = df.Tags.str.replace(" ', '", ",", regex = False)
```

Cada etiqueta se convierte en algo como: `Viaje de negocios, Viajero solo, Habitaci√≥n individual, Estancia de 5 noches, Enviado desde un dispositivo m√≥vil`.

A continuaci√≥n, encontramos un problema. Algunas rese√±as, o filas, tienen 5 columnas, otras 3, otras 6. Esto es resultado de c√≥mo se cre√≥ el conjunto de datos y es dif√≠cil de corregir. Quieres obtener un conteo de frecuencia de cada frase, pero est√°n en diferentes √≥rdenes en cada rese√±a, por lo que el conteo podr√≠a estar incorrecto y un hotel podr√≠a no recibir una etiqueta que merec√≠a.

En cambio, usar√°s el orden diferente a tu favor, porque cada etiqueta es de varias palabras pero tambi√©n est√° separada por una coma. La forma m√°s sencilla de hacer esto es crear 6 columnas temporales con cada etiqueta insertada en la columna correspondiente a su orden en la etiqueta. Luego puedes fusionar las 6 columnas en una gran columna y ejecutar el m√©todo `value_counts()` en la columna resultante. Al imprimir eso, ver√°s que hab√≠a 2428 etiquetas √∫nicas. Aqu√≠ hay una peque√±a muestra:

| Tag                            | Count  |
| ------------------------------ | ------ |
| Viaje de ocio                  | 417778 |
| Enviado desde un dispositivo m√≥vil | 307640 |
| Pareja                         | 252294 |
| Estancia de 1 noche            | 193645 |
| Estancia de 2 noches           | 133937 |
| Viajero solo                   | 108545 |
| Estancia de 3 noches           | 95821  |
| Viaje de negocios              | 82939  |
| Grupo                          | 65392  |
| Familia con ni√±os peque√±os     | 61015  |
| Estancia de 4 noches           | 47817  |
| Habitaci√≥n doble               | 35207  |
| Habitaci√≥n doble est√°ndar      | 32248  |
| Habitaci√≥n doble superior      | 31393  |
| Familia con ni√±os mayores      | 26349  |
| Habitaci√≥n doble deluxe        | 24823  |
| Habitaci√≥n doble o twin        | 22393  |
| Estancia de 5 noches           | 20845  |
| Habitaci√≥n doble est√°ndar o twin | 17483  |
| Habitaci√≥n doble cl√°sica       | 16989  |
| Habitaci√≥n doble superior o twin | 13570 |
| 2 habitaciones                 | 12393  |

Algunas de las etiquetas comunes como `Enviado desde un dispositivo m√≥vil` no nos son √∫tiles, por lo que podr√≠a ser inteligente eliminarlas antes de contar la ocurrencia de frases, pero es una operaci√≥n tan r√°pida que puedes dejarlas y simplemente ignorarlas.

### Eliminar las etiquetas de duraci√≥n de la estancia

Eliminar estas etiquetas es el paso 1, reduce ligeramente el n√∫mero total de etiquetas a considerar. Nota que no las eliminas del conjunto de datos, solo eliges eliminarlas de la consideraci√≥n como valores para contar/conservar en el conjunto de rese√±as.

| Duraci√≥n de la estancia | Count  |
| ----------------------- | ------ |
| Estancia de 1 noche     | 193645 |
| Estancia de 2 noches    | 133937 |
| Estancia de 3 noches    | 95821  |
| Estancia de 4 noches    | 47817  |
| Estancia de 5 noches    | 20845  |
| Estancia de 6 noches    | 9776   |
| Estancia de 7 noches    | 7399   |
| Estancia de 8 noches    | 2502   |
| Estancia de 9 noches    | 1293   |
| ...                     | ...    |

Hay una gran variedad de habitaciones, suites, estudios, apartamentos y dem√°s. Todos significan aproximadamente lo mismo y no son relevantes para ti, as√≠ que elim√≠nalos de la consideraci√≥n.

| Tipo de habitaci√≥n              | Count |
| ------------------------------- | ----- |
| Habitaci√≥n doble                | 35207 |
| Habitaci√≥n doble est√°ndar       | 32248 |
| Habitaci√≥n doble superior       | 31393 |
| Habitaci√≥n doble deluxe         | 24823 |
| Habitaci√≥n doble o twin         | 22393 |
| Habitaci√≥n doble est√°ndar o twin | 17483 |
| Habitaci√≥n doble cl√°sica        | 16989 |
| Habitaci√≥n doble superior o twin | 13570 |

Finalmente, y esto es encantador (porque no tom√≥ mucho procesamiento en absoluto), te quedar√°s con las siguientes etiquetas *√∫tiles*:

| Tag                                           | Count  |
| --------------------------------------------- | ------ |
| Viaje de ocio                                 | 417778 |
| Pareja                                        | 252294 |
| Viajero solo                                  | 108545 |
| Viaje de negocios                             | 82939  |
| Grupo (combinado con Viajeros con amigos)     | 67535  |
| Familia con ni√±os peque√±os                    | 61015  |
| Familia con ni√±os mayores                     | 26349  |
| Con una mascota                               | 1405   |

Podr√≠as argumentar que `Viajeros con amigos` es lo mismo que `Grupo` m√°s o menos, y ser√≠a justo combinarlos como se muestra arriba. El c√≥digo para identificar las etiquetas correctas est√° en [el cuaderno de etiquetas](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/5-Hotel-Reviews-2/solution/1-notebook.ipynb).

El paso final es crear nuevas columnas para cada una de estas etiquetas. Luego, para cada fila de rese√±a, si la columna `Tag` coincide con una de las nuevas columnas, agrega un 1, si no, agrega un 0. El resultado final ser√° un conteo de cu√°ntos revisores eligieron este hotel (en conjunto) para, por ejemplo, negocios vs ocio, o para llevar una mascota, y esta es informaci√≥n √∫til al recomendar un hotel.

```python
# Process the Tags into new columns
# The file Hotel_Reviews_Tags.py, identifies the most important tags
# Leisure trip, Couple, Solo traveler, Business trip, Group combined with Travelers with friends, 
# Family with young children, Family with older children, With a pet
df["Leisure_trip"] = df.Tags.apply(lambda tag: 1 if "Leisure trip" in tag else 0)
df["Couple"] = df.Tags.apply(lambda tag: 1 if "Couple" in tag else 0)
df["Solo_traveler"] = df.Tags.apply(lambda tag: 1 if "Solo traveler" in tag else 0)
df["Business_trip"] = df.Tags.apply(lambda tag: 1 if "Business trip" in tag else 0)
df["Group"] = df.Tags.apply(lambda tag: 1 if "Group" in tag or "Travelers with friends" in tag else 0)
df["Family_with_young_children"] = df.Tags.apply(lambda tag: 1 if "Family with young children" in tag else 0)
df["Family_with_older_children"] = df.Tags.apply(lambda tag: 1 if "Family with older children" in tag else 0)
df["With_a_pet"] = df.Tags.apply(lambda tag: 1 if "With a pet" in tag else 0)

```

### Guarda tu archivo

Finalmente, guarda el conjunto de datos tal como est√° ahora con un nuevo nombre.

```python
df.drop(["Review_Total_Negative_Word_Counts", "Review_Total_Positive_Word_Counts", "days_since_review", "Total_Number_of_Reviews_Reviewer_Has_Given"], axis = 1, inplace=True)

# Saving new data file with calculated columns
print("Saving results to Hotel_Reviews_Filtered.csv")
df.to_csv(r'../data/Hotel_Reviews_Filtered.csv', index = False)
```

## Operaciones de an√°lisis de sentimientos

En esta secci√≥n final, aplicar√°s an√°lisis de sentimientos a las columnas de rese√±as y guardar√°s los resultados en un conjunto de datos.

## Ejercicio: cargar y guardar los datos filtrados

Nota que ahora est√°s cargando el conjunto de datos filtrado que se guard√≥ en la secci√≥n anterior, **no** el conjunto de datos original.

```python
import time
import pandas as pd
import nltk as nltk
from nltk.corpus import stopwords
from nltk.sentiment.vader import SentimentIntensityAnalyzer
nltk.download('vader_lexicon')

# Load the filtered hotel reviews from CSV
df = pd.read_csv('../../data/Hotel_Reviews_Filtered.csv')

# You code will be added here


# Finally remember to save the hotel reviews with new NLP data added
print("Saving results to Hotel_Reviews_NLP.csv")
df.to_csv(r'../data/Hotel_Reviews_NLP.csv', index = False)
```

### Eliminar palabras vac√≠as

Si ejecutaras an√°lisis de sentimientos en las columnas de rese√±as negativas y positivas, podr√≠a tomar mucho tiempo. Probado en una laptop de prueba potente con CPU r√°pida, tom√≥ entre 12 y 14 minutos dependiendo de la biblioteca de an√°lisis de sentimientos utilizada. Ese es un tiempo (relativamente) largo, por lo que vale la pena investigar si se puede acelerar.

Eliminar palabras vac√≠as, o palabras comunes en ingl√©s que no cambian el sentimiento de una oraci√≥n, es el primer paso. Al eliminarlas, el an√°lisis de sentimientos deber√≠a ejecutarse m√°s r√°pido, pero no ser menos preciso (ya que las palabras vac√≠as no afectan el sentimiento, pero s√≠ ralentizan el an√°lisis).

La rese√±a negativa m√°s larga ten√≠a 395 palabras, pero despu√©s de eliminar las palabras vac√≠as, tiene 195 palabras.

Eliminar las palabras vac√≠as tambi√©n es una operaci√≥n r√°pida, eliminarlas de 2 columnas de rese√±as en m√°s de 515,000 filas tom√≥ 3.3 segundos en el dispositivo de prueba. Podr√≠a tomar un poco m√°s o menos tiempo para ti dependiendo de la velocidad de tu CPU, RAM, si tienes un SSD o no, y algunos otros factores. La relativa brevedad de la operaci√≥n significa que si mejora el tiempo de an√°lisis de sentimientos, entonces vale la pena hacerlo.

```python
from nltk.corpus import stopwords

# Load the hotel reviews from CSV
df = pd.read_csv("../../data/Hotel_Reviews_Filtered.csv")

# Remove stop words - can be slow for a lot of text!
# Ryan Han (ryanxjhan on Kaggle) has a great post measuring performance of different stop words removal approaches
# https://www.kaggle.com/ryanxjhan/fast-stop-words-removal # using the approach that Ryan recommends
start = time.time()
cache = set(stopwords.words("english"))
def remove_stopwords(review):
    text = " ".join([word for word in review.split() if word not in cache])
    return text

# Remove the stop words from both columns
df.Negative_Review = df.Negative_Review.apply(remove_stopwords)   
df.Positive_Review = df.Positive_Review.apply(remove_stopwords)
```

### Realizar an√°lisis de sentimientos

Ahora deber√≠as calcular el an√°lisis de sentimientos para las columnas de rese√±as negativas y positivas, y almacenar el resultado en 2 nuevas columnas. La prueba del sentimiento ser√° compararlo con la puntuaci√≥n del revisor para la misma rese√±a. Por ejemplo, si el an√°lisis de sentimientos piensa que la rese√±a negativa ten√≠a un sentimiento de 1 (sentimiento extremadamente positivo) y un sentimiento de rese√±a positiva de 1, pero el revisor dio al hotel la puntuaci√≥n m√°s baja posible, entonces o el texto de la rese√±a no coincide con la puntuaci√≥n, o el analizador de sentimientos no pudo reconocer correctamente el sentimiento. Deber√≠as esperar que algunas puntuaciones de sentimiento sean completamente incorrectas, y a menudo eso ser√° explicable, por ejemplo, la rese√±a podr√≠a ser extremadamente sarc√°stica: "Por supuesto que AM√â dormir en una habitaci√≥n sin calefacci√≥n" y el analizador de sentimientos piensa que eso es un sentimiento positivo, aunque un humano que lo lea sabr√≠a que es sarcasmo.
NLTK ofrece diferentes analizadores de sentimientos para aprender, y puedes sustituirlos y ver si el an√°lisis de sentimientos es m√°s o menos preciso. Aqu√≠ se utiliza el an√°lisis de sentimientos VADER.

> Hutto, C.J. & Gilbert, E.E. (2014). VADER: Un modelo parsimonioso basado en reglas para el an√°lisis de sentimientos de textos en redes sociales. Octava Conferencia Internacional sobre Blogs y Redes Sociales (ICWSM-14). Ann Arbor, MI, junio de 2014.

```python
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Create the vader sentiment analyser (there are others in NLTK you can try too)
vader_sentiment = SentimentIntensityAnalyzer()
# Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.

# There are 3 possibilities of input for a review:
# It could be "No Negative", in which case, return 0
# It could be "No Positive", in which case, return 0
# It could be a review, in which case calculate the sentiment
def calc_sentiment(review):    
    if review == "No Negative" or review == "No Positive":
        return 0
    return vader_sentiment.polarity_scores(review)["compound"]    
```

M√°s adelante en tu programa, cuando est√©s listo para calcular el sentimiento, puedes aplicarlo a cada rese√±a de la siguiente manera:

```python
# Add a negative sentiment and positive sentiment column
print("Calculating sentiment columns for both positive and negative reviews")
start = time.time()
df["Negative_Sentiment"] = df.Negative_Review.apply(calc_sentiment)
df["Positive_Sentiment"] = df.Positive_Review.apply(calc_sentiment)
end = time.time()
print("Calculating sentiment took " + str(round(end - start, 2)) + " seconds")
```

Esto toma aproximadamente 120 segundos en mi computadora, pero puede variar en cada equipo. Si deseas imprimir los resultados y verificar si el sentimiento coincide con la rese√±a:

```python
df = df.sort_values(by=["Negative_Sentiment"], ascending=True)
print(df[["Negative_Review", "Negative_Sentiment"]])
df = df.sort_values(by=["Positive_Sentiment"], ascending=True)
print(df[["Positive_Review", "Positive_Sentiment"]])
```

Lo √∫ltimo que debes hacer con el archivo antes de usarlo en el desaf√≠o es ¬°guardarlo! Tambi√©n deber√≠as considerar reorganizar todas tus nuevas columnas para que sean f√°ciles de trabajar (para una persona, es un cambio est√©tico).

```python
# Reorder the columns (This is cosmetic, but to make it easier to explore the data later)
df = df.reindex(["Hotel_Name", "Hotel_Address", "Total_Number_of_Reviews", "Average_Score", "Reviewer_Score", "Negative_Sentiment", "Positive_Sentiment", "Reviewer_Nationality", "Leisure_trip", "Couple", "Solo_traveler", "Business_trip", "Group", "Family_with_young_children", "Family_with_older_children", "With_a_pet", "Negative_Review", "Positive_Review"], axis=1)

print("Saving results to Hotel_Reviews_NLP.csv")
df.to_csv(r"../data/Hotel_Reviews_NLP.csv", index = False)
```

Debes ejecutar todo el c√≥digo del [notebook de an√°lisis](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/5-Hotel-Reviews-2/solution/3-notebook.ipynb) (despu√©s de haber ejecutado [el notebook de filtrado](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/5-Hotel-Reviews-2/solution/1-notebook.ipynb) para generar el archivo Hotel_Reviews_Filtered.csv).

Para repasar, los pasos son:

1. El archivo del conjunto de datos original **Hotel_Reviews.csv** se explora en la lecci√≥n anterior con [el notebook explorador](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/4-Hotel-Reviews-1/solution/notebook.ipynb)
2. Hotel_Reviews.csv se filtra con [el notebook de filtrado](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/5-Hotel-Reviews-2/solution/1-notebook.ipynb), resultando en **Hotel_Reviews_Filtered.csv**
3. Hotel_Reviews_Filtered.csv se procesa con [el notebook de an√°lisis de sentimientos](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/5-Hotel-Reviews-2/solution/3-notebook.ipynb), resultando en **Hotel_Reviews_NLP.csv**
4. Usa Hotel_Reviews_NLP.csv en el desaf√≠o de NLP a continuaci√≥n

### Conclusi√≥n

Cuando comenzaste, ten√≠as un conjunto de datos con columnas y datos, pero no todo pod√≠a ser verificado o utilizado. Has explorado los datos, filtrado lo que no necesitas, convertido etiquetas en algo √∫til, calculado tus propios promedios, a√±adido algunas columnas de sentimientos y, con suerte, aprendido cosas interesantes sobre el procesamiento de texto natural.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Desaf√≠o

Ahora que tienes tu conjunto de datos analizado para sentimientos, intenta usar las estrategias que has aprendido en este curso (¬øquiz√°s agrupamiento?) para determinar patrones relacionados con los sentimientos.

## Revisi√≥n y autoestudio

Toma [este m√≥dulo de aprendizaje](https://docs.microsoft.com/en-us/learn/modules/classify-user-feedback-with-the-text-analytics-api/?WT.mc_id=academic-77952-leestott) para aprender m√°s y usar diferentes herramientas para explorar sentimientos en texto.

## Tarea

[Prueba con un conjunto de datos diferente](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---
