# ML para Principiantes ü§ñ
## Parte 1: Fundamentos
**Introducci√≥n al Machine Learning y Regresi√≥n**

---


# Introducci√≥n al Machine Learning

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "cf8ecc83f28e5b98051d2179eca08e08",
  "translation_date": "2025-09-03T23:26:11+00:00",
  "source_file": "1-Introduction/README.md",
  "language_code": "es"
}
-->
# Introducci√≥n al aprendizaje autom√°tico

En esta secci√≥n del plan de estudios, se te presentar√°n los conceptos b√°sicos que sustentan el campo del aprendizaje autom√°tico, qu√© es, y aprender√°s sobre su historia y las t√©cnicas que los investigadores utilizan para trabajar con √©l. ¬°Exploremos juntos este nuevo mundo del aprendizaje autom√°tico!

![globo](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/translated_images/es/globe.59f26379ceb40428.webp)
> Foto de <a href="https://unsplash.com/@bill_oxford?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Bill Oxford</a> en <a href="https://unsplash.com/s/photos/globe?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
  
### Lecciones

1. [Introducci√≥n al aprendizaje autom√°tico](1-intro-to-ML/README.md)
1. [La historia del aprendizaje autom√°tico y la inteligencia artificial](2-history-of-ML/README.md)
1. [Equidad y aprendizaje autom√°tico](3-fairness/README.md)
1. [T√©cnicas de aprendizaje autom√°tico](4-techniques-of-ML/README.md)

### Cr√©ditos

"Introducci√≥n al Aprendizaje Autom√°tico" fue escrito con ‚ô•Ô∏è por un equipo de personas que incluye [Muhammad Sakib Khan Inan](https://twitter.com/Sakibinan), [Ornella Altunyan](https://twitter.com/ornelladotcom) y [Jen Looper](https://twitter.com/jenlooper)

"La Historia del Aprendizaje Autom√°tico" fue escrita con ‚ô•Ô∏è por [Jen Looper](https://twitter.com/jenlooper) y [Amy Boyd](https://twitter.com/AmyKateNicho)

"Equidad y Aprendizaje Autom√°tico" fue escrito con ‚ô•Ô∏è por [Tomomi Imura](https://twitter.com/girliemac) 

"T√©cnicas de Aprendizaje Autom√°tico" fue escrito con ‚ô•Ô∏è por [Jen Looper](https://twitter.com/jenlooper) y [Chris Noring](https://twitter.com/softchris)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "69389392fa6346e0dfa30f664b7b6fec",
  "translation_date": "2025-09-04T22:21:40+00:00",
  "source_file": "1-Introduction/1-intro-to-ML/README.md",
  "language_code": "es"
}
-->
# Introducci√≥n al aprendizaje autom√°tico

## [Cuestionario previo a la clase](https://ff-quizzes.netlify.app/en/ml/)

---

[![ML para principiantes - Introducci√≥n al aprendizaje autom√°tico para principiantes](https://img.youtube.com/vi/6mSx_KJxcHI/0.jpg)](https://youtu.be/6mSx_KJxcHI "ML para principiantes - Introducci√≥n al aprendizaje autom√°tico para principiantes")

> üé• Haz clic en la imagen de arriba para ver un breve video sobre esta lecci√≥n.

¬°Bienvenido a este curso sobre aprendizaje autom√°tico cl√°sico para principiantes! Ya sea que seas completamente nuevo en este tema o un practicante experimentado de ML que busca repasar un √°rea, ¬°nos alegra que te unas a nosotros! Queremos crear un punto de partida amigable para tu estudio de ML y estaremos encantados de evaluar, responder e incorporar tus [comentarios](https://github.com/microsoft/ML-For-Beginners/discussions).

[![Introducci√≥n al aprendizaje autom√°tico](https://img.youtube.com/vi/h0e2HAPTGF4/0.jpg)](https://youtu.be/h0e2HAPTGF4 "Introducci√≥n al aprendizaje autom√°tico")

> üé• Haz clic en la imagen de arriba para ver un video: John Guttag del MIT introduce el aprendizaje autom√°tico.

---
## Comenzando con el aprendizaje autom√°tico

Antes de comenzar con este plan de estudios, necesitas tener tu computadora configurada y lista para ejecutar notebooks de manera local.

- **Configura tu m√°quina con estos videos**. Usa los siguientes enlaces para aprender [c√≥mo instalar Python](https://youtu.be/CXZYvNRIAKM) en tu sistema y [configurar un editor de texto](https://youtu.be/EU8eayHWoZg) para el desarrollo.
- **Aprende Python**. Tambi√©n se recomienda tener un entendimiento b√°sico de [Python](https://docs.microsoft.com/learn/paths/python-language/?WT.mc_id=academic-77952-leestott), un lenguaje de programaci√≥n √∫til para cient√≠ficos de datos que utilizamos en este curso.
- **Aprende Node.js y JavaScript**. Tambi√©n utilizamos JavaScript algunas veces en este curso al construir aplicaciones web, por lo que necesitar√°s tener [node](https://nodejs.org) y [npm](https://www.npmjs.com/) instalados, as√≠ como [Visual Studio Code](https://code.visualstudio.com/) disponible para el desarrollo tanto en Python como en JavaScript.
- **Crea una cuenta de GitHub**. Ya que nos encontraste aqu√≠ en [GitHub](https://github.com), es posible que ya tengas una cuenta, pero si no, crea una y luego haz un fork de este plan de estudios para usarlo por tu cuenta. (Tambi√©n puedes darnos una estrella üòä).
- **Explora Scikit-learn**. Familiar√≠zate con [Scikit-learn](https://scikit-learn.org/stable/user_guide.html), un conjunto de bibliotecas de ML que referenciamos en estas lecciones.

---
## ¬øQu√© es el aprendizaje autom√°tico?

El t√©rmino 'aprendizaje autom√°tico' es uno de los m√°s populares y frecuentemente utilizados hoy en d√≠a. Existe una posibilidad no trivial de que hayas escuchado este t√©rmino al menos una vez si tienes alg√∫n tipo de familiaridad con la tecnolog√≠a, sin importar el √°rea en la que trabajes. Sin embargo, la mec√°nica del aprendizaje autom√°tico es un misterio para la mayor√≠a de las personas. Para un principiante en aprendizaje autom√°tico, el tema puede parecer abrumador a veces. Por lo tanto, es importante entender qu√© es realmente el aprendizaje autom√°tico y aprender sobre √©l paso a paso, a trav√©s de ejemplos pr√°cticos.

---
## La curva de expectativas

![curva de expectativas de ML](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/1-intro-to-ML/images/hype.png)

> Google Trends muestra la reciente 'curva de expectativas' del t√©rmino 'aprendizaje autom√°tico'.

---
## Un universo misterioso

Vivimos en un universo lleno de misterios fascinantes. Grandes cient√≠ficos como Stephen Hawking, Albert Einstein y muchos m√°s han dedicado sus vidas a buscar informaci√≥n significativa que revele los misterios del mundo que nos rodea. Esta es la condici√≥n humana de aprender: un ni√±o humano aprende cosas nuevas y descubre la estructura de su mundo a√±o tras a√±o mientras crece hasta la adultez.

---
## El cerebro de un ni√±o

El cerebro y los sentidos de un ni√±o perciben los hechos de su entorno y gradualmente aprenden los patrones ocultos de la vida que ayudan al ni√±o a crear reglas l√≥gicas para identificar patrones aprendidos. El proceso de aprendizaje del cerebro humano hace que los humanos sean la criatura m√°s sofisticada de este mundo. Aprender continuamente descubriendo patrones ocultos y luego innovando sobre esos patrones nos permite mejorar continuamente a lo largo de nuestra vida. Esta capacidad de aprendizaje y evoluci√≥n est√° relacionada con un concepto llamado [plasticidad cerebral](https://www.simplypsychology.org/brain-plasticity.html). Superficialmente, podemos establecer algunas similitudes motivacionales entre el proceso de aprendizaje del cerebro humano y los conceptos del aprendizaje autom√°tico.

---
## El cerebro humano

El [cerebro humano](https://www.livescience.com/29365-human-brain.html) percibe cosas del mundo real, procesa la informaci√≥n percibida, toma decisiones racionales y realiza ciertas acciones seg√∫n las circunstancias. Esto es lo que llamamos comportarse de manera inteligente. Cuando programamos una r√©plica del proceso de comportamiento inteligente en una m√°quina, se llama inteligencia artificial (IA).

---
## Algunos t√©rminos

Aunque los t√©rminos pueden confundirse, el aprendizaje autom√°tico (ML) es un subconjunto importante de la inteligencia artificial. **ML se ocupa de usar algoritmos especializados para descubrir informaci√≥n significativa y encontrar patrones ocultos a partir de datos percibidos para corroborar el proceso de toma de decisiones racionales**.

---
## IA, ML, Aprendizaje profundo

![IA, ML, aprendizaje profundo, ciencia de datos](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/1-intro-to-ML/images/ai-ml-ds.png)

> Un diagrama que muestra las relaciones entre IA, ML, aprendizaje profundo y ciencia de datos. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper) inspirada en [este gr√°fico](https://softwareengineering.stackexchange.com/questions/366996/distinction-between-ai-ml-neural-networks-deep-learning-and-data-mining).

---
## Conceptos a cubrir

En este plan de estudios, vamos a cubrir solo los conceptos b√°sicos del aprendizaje autom√°tico que un principiante debe conocer. Cubrimos lo que llamamos 'aprendizaje autom√°tico cl√°sico', principalmente utilizando Scikit-learn, una excelente biblioteca que muchos estudiantes usan para aprender los fundamentos. Para entender conceptos m√°s amplios de inteligencia artificial o aprendizaje profundo, es indispensable tener un conocimiento fundamental s√≥lido del aprendizaje autom√°tico, y por eso queremos ofrecerlo aqu√≠.

---
## En este curso aprender√°s:

- conceptos b√°sicos del aprendizaje autom√°tico
- la historia del ML
- ML y equidad
- t√©cnicas de regresi√≥n en ML
- t√©cnicas de clasificaci√≥n en ML
- t√©cnicas de agrupamiento en ML
- t√©cnicas de procesamiento de lenguaje natural en ML
- t√©cnicas de predicci√≥n de series temporales en ML
- aprendizaje por refuerzo
- aplicaciones reales del ML

---
## Lo que no cubriremos

- aprendizaje profundo
- redes neuronales
- IA

Para ofrecer una mejor experiencia de aprendizaje, evitaremos las complejidades de las redes neuronales, el 'aprendizaje profundo' - construcci√≥n de modelos con muchas capas utilizando redes neuronales - y la IA, que discutiremos en un plan de estudios diferente. Tambi√©n ofreceremos un pr√≥ximo plan de estudios sobre ciencia de datos para centrarnos en ese aspecto de este campo m√°s amplio.

---
## ¬øPor qu√© estudiar aprendizaje autom√°tico?

El aprendizaje autom√°tico, desde una perspectiva de sistemas, se define como la creaci√≥n de sistemas automatizados que pueden aprender patrones ocultos a partir de datos para ayudar en la toma de decisiones inteligentes.

Esta motivaci√≥n est√° vagamente inspirada en c√≥mo el cerebro humano aprende ciertas cosas bas√°ndose en los datos que percibe del mundo exterior.

‚úÖ Piensa por un momento por qu√© una empresa querr√≠a intentar usar estrategias de aprendizaje autom√°tico en lugar de crear un motor basado en reglas codificadas.

---
## Aplicaciones del aprendizaje autom√°tico

Las aplicaciones del aprendizaje autom√°tico est√°n ahora casi en todas partes y son tan ubicuas como los datos que fluyen en nuestras sociedades, generados por nuestros tel√©fonos inteligentes, dispositivos conectados y otros sistemas. Considerando el inmenso potencial de los algoritmos de aprendizaje autom√°tico de √∫ltima generaci√≥n, los investigadores han estado explorando su capacidad para resolver problemas reales multidimensionales y multidisciplinarios con grandes resultados positivos.

---
## Ejemplos de ML aplicado

**Puedes usar el aprendizaje autom√°tico de muchas maneras**:

- Para predecir la probabilidad de una enfermedad a partir del historial m√©dico o informes de un paciente.
- Para aprovechar los datos meteorol√≥gicos y predecir eventos clim√°ticos.
- Para entender el sentimiento de un texto.
- Para detectar noticias falsas y detener la propagaci√≥n de propaganda.

Finanzas, econom√≠a, ciencias de la tierra, exploraci√≥n espacial, ingenier√≠a biom√©dica, ciencias cognitivas e incluso √°reas de las humanidades han adaptado el aprendizaje autom√°tico para resolver los arduos problemas de procesamiento de datos en sus dominios.

---
## Conclusi√≥n

El aprendizaje autom√°tico automatiza el proceso de descubrimiento de patrones al encontrar informaci√≥n significativa a partir de datos reales o generados. Ha demostrado ser altamente valioso en aplicaciones empresariales, de salud y financieras, entre otras.

En un futuro cercano, entender los fundamentos del aprendizaje autom√°tico ser√° imprescindible para personas de cualquier √°rea debido a su adopci√≥n generalizada.

---
# üöÄ Desaf√≠o

Dibuja, en papel o usando una aplicaci√≥n en l√≠nea como [Excalidraw](https://excalidraw.com/), tu comprensi√≥n de las diferencias entre IA, ML, aprendizaje profundo y ciencia de datos. Agrega algunas ideas sobre los problemas que cada una de estas t√©cnicas es buena para resolver.

# [Cuestionario posterior a la clase](https://ff-quizzes.netlify.app/en/ml/)

---
# Revisi√≥n y autoestudio

Para aprender m√°s sobre c√≥mo trabajar con algoritmos de ML en la nube, sigue este [Camino de Aprendizaje](https://docs.microsoft.com/learn/paths/create-no-code-predictive-models-azure-machine-learning/?WT.mc_id=academic-77952-leestott).

Toma un [Camino de Aprendizaje](https://docs.microsoft.com/learn/modules/introduction-to-machine-learning/?WT.mc_id=academic-77952-leestott) sobre los fundamentos del ML.

---
# Tarea

[Ponte en marcha](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6a05fec147e734c3e6bfa54505648e2b",
  "translation_date": "2025-09-04T22:22:07+00:00",
  "source_file": "1-Introduction/2-history-of-ML/README.md",
  "language_code": "es"
}
-->
# Historia del aprendizaje autom√°tico

![Resumen de la historia del aprendizaje autom√°tico en un sketchnote](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/sketchnotes/ml-history.png)
> Sketchnote por [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

---

[![ML para principiantes - Historia del aprendizaje autom√°tico](https://img.youtube.com/vi/N6wxM4wZ7V0/0.jpg)](https://youtu.be/N6wxM4wZ7V0 "ML para principiantes - Historia del aprendizaje autom√°tico")

> üé• Haz clic en la imagen de arriba para ver un breve video sobre esta lecci√≥n.

En esta lecci√≥n, repasaremos los hitos m√°s importantes en la historia del aprendizaje autom√°tico y la inteligencia artificial.

La historia de la inteligencia artificial (IA) como campo est√° entrelazada con la historia del aprendizaje autom√°tico, ya que los algoritmos y avances computacionales que sustentan el aprendizaje autom√°tico contribuyeron al desarrollo de la IA. Es √∫til recordar que, aunque estos campos como √°reas de investigaci√≥n distintas comenzaron a cristalizar en la d√©cada de 1950, importantes [descubrimientos algor√≠tmicos, estad√≠sticos, matem√°ticos, computacionales y t√©cnicos](https://wikipedia.org/wiki/Timeline_of_machine_learning) precedieron y se superpusieron a esta era. De hecho, las personas han estado reflexionando sobre estas cuestiones durante [cientos de a√±os](https://wikipedia.org/wiki/History_of_artificial_intelligence): este art√≠culo analiza los fundamentos intelectuales hist√≥ricos de la idea de una 'm√°quina pensante'.

---
## Descubrimientos notables

- 1763, 1812 [Teorema de Bayes](https://wikipedia.org/wiki/Bayes%27_theorem) y sus predecesores. Este teorema y sus aplicaciones son fundamentales para la inferencia, describiendo la probabilidad de que ocurra un evento basado en conocimientos previos.
- 1805 [Teor√≠a de los m√≠nimos cuadrados](https://wikipedia.org/wiki/Least_squares) por el matem√°tico franc√©s Adrien-Marie Legendre. Esta teor√≠a, que aprender√°s en nuestra unidad de Regresi√≥n, ayuda en el ajuste de datos.
- 1913 [Cadenas de Markov](https://wikipedia.org/wiki/Markov_chain), nombradas en honor al matem√°tico ruso Andrey Markov, se utilizan para describir una secuencia de eventos posibles basada en un estado previo.
- 1957 [Perceptr√≥n](https://wikipedia.org/wiki/Perceptron), un tipo de clasificador lineal inventado por el psic√≥logo estadounidense Frank Rosenblatt que sustenta los avances en el aprendizaje profundo.

---

- 1967 [Vecino m√°s cercano](https://wikipedia.org/wiki/Nearest_neighbor) es un algoritmo originalmente dise√±ado para trazar rutas. En un contexto de aprendizaje autom√°tico, se utiliza para detectar patrones.
- 1970 [Retropropagaci√≥n](https://wikipedia.org/wiki/Backpropagation) se utiliza para entrenar [redes neuronales feedforward](https://wikipedia.org/wiki/Feedforward_neural_network).
- 1982 [Redes neuronales recurrentes](https://wikipedia.org/wiki/Recurrent_neural_network) son redes neuronales artificiales derivadas de las redes neuronales feedforward que crean gr√°ficos temporales.

‚úÖ Investiga un poco. ¬øQu√© otras fechas destacan como fundamentales en la historia del aprendizaje autom√°tico y la IA?

---
## 1950: M√°quinas que piensan

Alan Turing, una persona verdaderamente extraordinaria que fue votada [por el p√∫blico en 2019](https://wikipedia.org/wiki/Icons:_The_Greatest_Person_of_the_20th_Century) como el mejor cient√≠fico del siglo XX, es reconocido por ayudar a sentar las bases del concepto de una 'm√°quina que puede pensar'. Se enfrent√≥ a detractores y a su propia necesidad de evidencia emp√≠rica de este concepto en parte creando el [Test de Turing](https://www.bbc.com/news/technology-18475646), que explorar√°s en nuestras lecciones de procesamiento de lenguaje natural.

---
## 1956: Proyecto de investigaci√≥n de verano en Dartmouth

"El Proyecto de investigaci√≥n de verano en Dartmouth sobre inteligencia artificial fue un evento fundamental para la inteligencia artificial como campo", y fue aqu√≠ donde se acu√±√≥ el t√©rmino 'inteligencia artificial' ([fuente](https://250.dartmouth.edu/highlights/artificial-intelligence-ai-coined-dartmouth)).

> Cada aspecto del aprendizaje o cualquier otra caracter√≠stica de la inteligencia puede, en principio, describirse tan precisamente que se pueda construir una m√°quina que lo simule.

---

El investigador principal, el profesor de matem√°ticas John McCarthy, esperaba "proceder sobre la base de la conjetura de que cada aspecto del aprendizaje o cualquier otra caracter√≠stica de la inteligencia puede, en principio, describirse tan precisamente que se pueda construir una m√°quina que lo simule". Los participantes incluyeron a otro destacado en el campo, Marvin Minsky.

El taller es reconocido por haber iniciado y fomentado varias discusiones, incluyendo "el auge de los m√©todos simb√≥licos, sistemas enfocados en dominios limitados (primeros sistemas expertos) y sistemas deductivos frente a sistemas inductivos". ([fuente](https://wikipedia.org/wiki/Dartmouth_workshop)).

---
## 1956 - 1974: "Los a√±os dorados"

Desde la d√©cada de 1950 hasta mediados de los a√±os 70, el optimismo era alto con la esperanza de que la IA pudiera resolver muchos problemas. En 1967, Marvin Minsky afirm√≥ con confianza que "Dentro de una generaci√≥n... el problema de crear 'inteligencia artificial' estar√° sustancialmente resuelto". (Minsky, Marvin (1967), Computation: Finite and Infinite Machines, Englewood Cliffs, N.J.: Prentice-Hall)

La investigaci√≥n en procesamiento de lenguaje natural floreci√≥, la b√∫squeda se refin√≥ y se hizo m√°s poderosa, y se cre√≥ el concepto de 'micro-mundos', donde se completaban tareas simples utilizando instrucciones en lenguaje sencillo.

---

La investigaci√≥n fue bien financiada por agencias gubernamentales, se lograron avances en computaci√≥n y algoritmos, y se construyeron prototipos de m√°quinas inteligentes. Algunas de estas m√°quinas incluyen:

* [Shakey el robot](https://wikipedia.org/wiki/Shakey_the_robot), que pod√≠a maniobrar y decidir c√≥mo realizar tareas 'inteligentemente'.

    ![Shakey, un robot inteligente](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/2-history-of-ML/images/shakey.jpg)
    > Shakey en 1972

---

* Eliza, un primer 'chatterbot', pod√≠a conversar con personas y actuar como un 'terapeuta' primitivo. Aprender√°s m√°s sobre Eliza en las lecciones de procesamiento de lenguaje natural.

    ![Eliza, un bot](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/2-history-of-ML/images/eliza.png)
    > Una versi√≥n de Eliza, un chatbot

---

* "Blocks world" fue un ejemplo de un micro-mundo donde los bloques pod√≠an apilarse y ordenarse, y se pod√≠an probar experimentos para ense√±ar a las m√°quinas a tomar decisiones. Los avances construidos con bibliotecas como [SHRDLU](https://wikipedia.org/wiki/SHRDLU) ayudaron a impulsar el procesamiento de lenguaje.

    [![blocks world con SHRDLU](https://img.youtube.com/vi/QAJz4YKUwqw/0.jpg)](https://www.youtube.com/watch?v=QAJz4YKUwqw "blocks world con SHRDLU")

    > üé• Haz clic en la imagen de arriba para ver un video: Blocks world con SHRDLU

---
## 1974 - 1980: "Invierno de la IA"

A mediados de los a√±os 70, se hizo evidente que la complejidad de crear 'm√°quinas inteligentes' hab√≠a sido subestimada y que su promesa, dada la potencia computacional disponible, hab√≠a sido exagerada. Los fondos se agotaron y la confianza en el campo disminuy√≥. Algunos problemas que afectaron la confianza incluyeron:
---
- **Limitaciones**. La potencia computacional era demasiado limitada.
- **Explosi√≥n combinatoria**. La cantidad de par√°metros necesarios para entrenar creci√≥ exponencialmente a medida que se ped√≠a m√°s a las computadoras, sin una evoluci√≥n paralela de la potencia y capacidad computacional.
- **Escasez de datos**. Hab√≠a una escasez de datos que dificultaba el proceso de probar, desarrollar y refinar algoritmos.
- **¬øEstamos haciendo las preguntas correctas?**. Las mismas preguntas que se estaban planteando comenzaron a ser cuestionadas. Los investigadores comenzaron a recibir cr√≠ticas sobre sus enfoques:
  - Los tests de Turing fueron cuestionados mediante, entre otras ideas, la 'teor√≠a de la habitaci√≥n china', que postulaba que, "programar una computadora digital puede hacer que parezca entender el lenguaje pero no podr√≠a producir una comprensi√≥n real". ([fuente](https://plato.stanford.edu/entries/chinese-room/))
  - Se cuestion√≥ la √©tica de introducir inteligencias artificiales como el "terapeuta" ELIZA en la sociedad.

---

Al mismo tiempo, comenzaron a formarse varias escuelas de pensamiento sobre IA. Se estableci√≥ una dicotom√≠a entre las pr√°cticas de ["IA desordenada" vs. "IA ordenada"](https://wikipedia.org/wiki/Neats_and_scruffies). Los laboratorios _desordenados_ ajustaban programas durante horas hasta obtener los resultados deseados. Los laboratorios _ordenados_ "se enfocaban en la l√≥gica y la resoluci√≥n formal de problemas". ELIZA y SHRDLU eran sistemas _desordenados_ bien conocidos. En la d√©cada de 1980, a medida que surgi√≥ la demanda de hacer que los sistemas de aprendizaje autom√°tico fueran reproducibles, el enfoque _ordenado_ gradualmente tom√≥ la delantera, ya que sus resultados son m√°s explicables.

---
## Sistemas expertos en los a√±os 80

A medida que el campo creci√≥, su beneficio para los negocios se hizo m√°s claro, y en la d√©cada de 1980 tambi√©n lo hizo la proliferaci√≥n de 'sistemas expertos'. "Los sistemas expertos estuvieron entre las primeras formas verdaderamente exitosas de software de inteligencia artificial (IA)." ([fuente](https://wikipedia.org/wiki/Expert_system)).

Este tipo de sistema es en realidad _h√≠brido_, compuesto parcialmente por un motor de reglas que define los requisitos empresariales y un motor de inferencia que aprovecha el sistema de reglas para deducir nuevos hechos.

Esta era tambi√©n vio una creciente atenci√≥n hacia las redes neuronales.

---
## 1987 - 1993: Enfriamiento de la IA

La proliferaci√≥n de hardware especializado para sistemas expertos tuvo el desafortunado efecto de volverse demasiado especializado. El auge de las computadoras personales tambi√©n compiti√≥ con estos sistemas grandes, especializados y centralizados. La democratizaci√≥n de la inform√°tica hab√≠a comenzado, y eventualmente allan√≥ el camino para la explosi√≥n moderna de big data.

---
## 1993 - 2011

Esta √©poca marc√≥ una nueva era para el aprendizaje autom√°tico y la IA, permitiendo resolver algunos de los problemas causados anteriormente por la falta de datos y potencia computacional. La cantidad de datos comenz√≥ a aumentar r√°pidamente y a estar m√°s ampliamente disponible, para bien y para mal, especialmente con la llegada del smartphone alrededor de 2007. La potencia computacional se expandi√≥ exponencialmente, y los algoritmos evolucionaron junto con ella. El campo comenz√≥ a ganar madurez a medida que los d√≠as desenfrenados del pasado comenzaron a cristalizarse en una verdadera disciplina.

---
## Hoy

Hoy en d√≠a, el aprendizaje autom√°tico y la IA tocan casi todas las partes de nuestras vidas. Esta era exige una comprensi√≥n cuidadosa de los riesgos y los efectos potenciales de estos algoritmos en la vida humana. Como ha afirmado Brad Smith de Microsoft, "La tecnolog√≠a de la informaci√≥n plantea cuestiones que van al coraz√≥n de las protecciones fundamentales de los derechos humanos, como la privacidad y la libertad de expresi√≥n. Estas cuestiones aumentan la responsabilidad de las empresas tecnol√≥gicas que crean estos productos. En nuestra opini√≥n, tambi√©n exigen una regulaci√≥n gubernamental reflexiva y el desarrollo de normas sobre usos aceptables" ([fuente](https://www.technologyreview.com/2019/12/18/102365/the-future-of-ais-impact-on-society/)).

---

Queda por ver qu√© depara el futuro, pero es importante comprender estos sistemas inform√°ticos y el software y los algoritmos que ejecutan. Esperamos que este plan de estudios te ayude a obtener una mejor comprensi√≥n para que puedas decidir por ti mismo.

[![La historia del aprendizaje profundo](https://img.youtube.com/vi/mTtDfKgLm54/0.jpg)](https://www.youtube.com/watch?v=mTtDfKgLm54 "La historia del aprendizaje profundo")
> üé• Haz clic en la imagen de arriba para ver un video: Yann LeCun habla sobre la historia del aprendizaje profundo en esta conferencia

---
## üöÄDesaf√≠o

Investiga uno de estos momentos hist√≥ricos y aprende m√°s sobre las personas detr√°s de ellos. Hay personajes fascinantes, y ning√∫n descubrimiento cient√≠fico se cre√≥ jam√°s en un vac√≠o cultural. ¬øQu√© descubres?

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

---
## Revisi√≥n y autoestudio

Aqu√≠ tienes elementos para ver y escuchar:

[Este podcast donde Amy Boyd analiza la evoluci√≥n de la IA](http://runasradio.com/Shows/Show/739)

[![La historia de la IA por Amy Boyd](https://img.youtube.com/vi/EJt3_bFYKss/0.jpg)](https://www.youtube.com/watch?v=EJt3_bFYKss "La historia de la IA por Amy Boyd")

---

## Tarea

[Crear una l√≠nea de tiempo](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a6b702d1437c0467e3c5c28d763dac2",
  "translation_date": "2025-09-04T22:20:36+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "es"
}
-->
# Construyendo soluciones de aprendizaje autom√°tico con IA responsable

![Resumen de IA responsable en aprendizaje autom√°tico en un sketchnote](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/sketchnotes/ml-fairness.png)
> Sketchnote por [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Introducci√≥n

En este curr√≠culo, comenzar√°s a descubrir c√≥mo el aprendizaje autom√°tico puede y est√° impactando nuestras vidas cotidianas. Incluso ahora, los sistemas y modelos est√°n involucrados en tareas de toma de decisiones diarias, como diagn√≥sticos m√©dicos, aprobaciones de pr√©stamos o detecci√≥n de fraudes. Por lo tanto, es importante que estos modelos funcionen bien para proporcionar resultados confiables. Al igual que cualquier aplicaci√≥n de software, los sistemas de IA pueden no cumplir con las expectativas o tener un resultado indeseable. Es por eso que es esencial poder entender y explicar el comportamiento de un modelo de IA.

Imagina lo que puede suceder cuando los datos que utilizas para construir estos modelos carecen de ciertos grupos demogr√°ficos, como raza, g√©nero, visi√≥n pol√≠tica, religi√≥n, o representan desproporcionadamente dichos grupos. ¬øQu√© pasa cuando la salida del modelo se interpreta para favorecer a alg√∫n grupo demogr√°fico? ¬øCu√°l es la consecuencia para la aplicaci√≥n? Adem√°s, ¬øqu√© sucede cuando el modelo tiene un resultado adverso y es perjudicial para las personas? ¬øQui√©n es responsable del comportamiento de los sistemas de IA? Estas son algunas preguntas que exploraremos en este curr√≠culo.

En esta lecci√≥n, aprender√°s a:

- Concienciarte sobre la importancia de la equidad en el aprendizaje autom√°tico y los da√±os relacionados con la falta de equidad.
- Familiarizarte con la pr√°ctica de explorar valores at√≠picos y escenarios inusuales para garantizar confiabilidad y seguridad.
- Comprender la necesidad de empoderar a todos mediante el dise√±o de sistemas inclusivos.
- Explorar lo vital que es proteger la privacidad y seguridad de los datos y las personas.
- Ver la importancia de tener un enfoque de caja de cristal para explicar el comportamiento de los modelos de IA.
- Ser consciente de c√≥mo la responsabilidad es esencial para generar confianza en los sistemas de IA.

## Prerrequisito

Como prerrequisito, toma el "Camino de Aprendizaje de Principios de IA Responsable" y mira el siguiente video sobre el tema:

Aprende m√°s sobre IA Responsable siguiendo este [Camino de Aprendizaje](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott)

[![Enfoque de Microsoft hacia la IA Responsable](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "Enfoque de Microsoft hacia la IA Responsable")

> üé• Haz clic en la imagen de arriba para ver el video: Enfoque de Microsoft hacia la IA Responsable

## Equidad

Los sistemas de IA deben tratar a todos de manera justa y evitar afectar a grupos similares de personas de diferentes maneras. Por ejemplo, cuando los sistemas de IA proporcionan orientaci√≥n sobre tratamientos m√©dicos, solicitudes de pr√©stamos o empleo, deben hacer las mismas recomendaciones a todos con s√≠ntomas similares, circunstancias financieras o calificaciones profesionales. Cada uno de nosotros, como humanos, lleva consigo sesgos heredados que afectan nuestras decisiones y acciones. Estos sesgos pueden ser evidentes en los datos que usamos para entrenar sistemas de IA. A veces, esta manipulaci√≥n ocurre de manera no intencional. A menudo es dif√≠cil saber conscientemente cu√°ndo est√°s introduciendo sesgos en los datos.

**‚ÄúInjusticia‚Äù** abarca impactos negativos, o ‚Äúda√±os‚Äù, para un grupo de personas, como aquellos definidos en t√©rminos de raza, g√©nero, edad o estado de discapacidad. Los principales da√±os relacionados con la equidad pueden clasificarse como:

- **Asignaci√≥n**, si, por ejemplo, se favorece un g√©nero o etnia sobre otro.
- **Calidad del servicio**. Si entrenas los datos para un escenario espec√≠fico pero la realidad es mucho m√°s compleja, esto lleva a un servicio de bajo rendimiento. Por ejemplo, un dispensador de jab√≥n que no parece ser capaz de detectar personas con piel oscura. [Referencia](https://gizmodo.com/why-cant-this-soap-dispenser-identify-dark-skin-1797931773)
- **Denigraci√≥n**. Criticar y etiquetar algo o alguien de manera injusta. Por ejemplo, una tecnolog√≠a de etiquetado de im√°genes etiquet√≥ err√≥neamente im√°genes de personas de piel oscura como gorilas.
- **Sobre- o sub-representaci√≥n**. La idea de que un cierto grupo no se ve en una determinada profesi√≥n, y cualquier servicio o funci√≥n que siga promoviendo eso est√° contribuyendo al da√±o.
- **Estereotipos**. Asociar un grupo dado con atributos preasignados. Por ejemplo, un sistema de traducci√≥n entre ingl√©s y turco puede tener inexactitudes debido a palabras con asociaciones estereot√≠picas de g√©nero.

![traducci√≥n al turco](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/3-fairness/images/gender-bias-translate-en-tr.png)
> traducci√≥n al turco

![traducci√≥n de vuelta al ingl√©s](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/3-fairness/images/gender-bias-translate-tr-en.png)
> traducci√≥n de vuelta al ingl√©s

Al dise√±ar y probar sistemas de IA, debemos asegurarnos de que la IA sea justa y no est√© programada para tomar decisiones sesgadas o discriminatorias, las cuales tambi√©n est√°n prohibidas para los seres humanos. Garantizar la equidad en la IA y el aprendizaje autom√°tico sigue siendo un desaf√≠o sociot√©cnico complejo.

### Confiabilidad y seguridad

Para generar confianza, los sistemas de IA deben ser confiables, seguros y consistentes bajo condiciones normales e inesperadas. Es importante saber c√≥mo se comportar√°n los sistemas de IA en una variedad de situaciones, especialmente cuando son valores at√≠picos. Al construir soluciones de IA, se necesita un enfoque sustancial en c√≥mo manejar una amplia variedad de circunstancias que las soluciones de IA podr√≠an encontrar. Por ejemplo, un autom√≥vil aut√≥nomo debe priorizar la seguridad de las personas. Como resultado, la IA que impulsa el autom√≥vil debe considerar todos los posibles escenarios que el autom√≥vil podr√≠a enfrentar, como la noche, tormentas el√©ctricas o ventiscas, ni√±os cruzando la calle, mascotas, construcciones en la carretera, etc. Qu√© tan bien un sistema de IA puede manejar una amplia gama de condiciones de manera confiable y segura refleja el nivel de anticipaci√≥n que el cient√≠fico de datos o desarrollador de IA consider√≥ durante el dise√±o o prueba del sistema.

> [üé• Haz clic aqu√≠ para ver un video: ](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### Inclusi√≥n

Los sistemas de IA deben dise√±arse para involucrar y empoderar a todos. Al dise√±ar e implementar sistemas de IA, los cient√≠ficos de datos y desarrolladores de IA identifican y abordan posibles barreras en el sistema que podr√≠an excluir a las personas de manera no intencional. Por ejemplo, hay 1,000 millones de personas con discapacidades en todo el mundo. Con el avance de la IA, pueden acceder a una amplia gama de informaci√≥n y oportunidades m√°s f√°cilmente en su vida diaria. Al abordar las barreras, se crean oportunidades para innovar y desarrollar productos de IA con mejores experiencias que beneficien a todos.

> [üé• Haz clic aqu√≠ para ver un video: inclusi√≥n en IA](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### Seguridad y privacidad

Los sistemas de IA deben ser seguros y respetar la privacidad de las personas. Las personas tienen menos confianza en sistemas que ponen en riesgo su privacidad, informaci√≥n o vidas. Al entrenar modelos de aprendizaje autom√°tico, dependemos de los datos para producir los mejores resultados. Al hacerlo, se debe considerar el origen de los datos y su integridad. Por ejemplo, ¬ølos datos fueron enviados por el usuario o estaban disponibles p√∫blicamente? Luego, al trabajar con los datos, es crucial desarrollar sistemas de IA que puedan proteger informaci√≥n confidencial y resistir ataques. A medida que la IA se vuelve m√°s prevalente, proteger la privacidad y asegurar informaci√≥n personal y empresarial importante se est√° volviendo m√°s cr√≠tico y complejo. Los problemas de privacidad y seguridad de los datos requieren especial atenci√≥n en la IA porque el acceso a los datos es esencial para que los sistemas de IA hagan predicciones y decisiones precisas e informadas sobre las personas.

> [üé• Haz clic aqu√≠ para ver un video: seguridad en IA](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Como industria, hemos logrado avances significativos en privacidad y seguridad, impulsados significativamente por regulaciones como el GDPR (Reglamento General de Protecci√≥n de Datos).
- Sin embargo, con los sistemas de IA debemos reconocer la tensi√≥n entre la necesidad de m√°s datos personales para hacer los sistemas m√°s efectivos y la privacidad.
- Al igual que con el nacimiento de las computadoras conectadas a internet, tambi√©n estamos viendo un gran aumento en el n√∫mero de problemas de seguridad relacionados con la IA.
- Al mismo tiempo, hemos visto que la IA se utiliza para mejorar la seguridad. Por ejemplo, la mayor√≠a de los esc√°neres antivirus modernos est√°n impulsados por heur√≠sticas de IA.
- Necesitamos asegurarnos de que nuestros procesos de Ciencia de Datos se integren armoniosamente con las √∫ltimas pr√°cticas de privacidad y seguridad.

### Transparencia

Los sistemas de IA deben ser comprensibles. Una parte crucial de la transparencia es explicar el comportamiento de los sistemas de IA y sus componentes. Mejorar la comprensi√≥n de los sistemas de IA requiere que las partes interesadas comprendan c√≥mo y por qu√© funcionan para que puedan identificar posibles problemas de rendimiento, preocupaciones de seguridad y privacidad, sesgos, pr√°cticas excluyentes o resultados no deseados. Tambi√©n creemos que quienes usan sistemas de IA deben ser honestos y transparentes sobre cu√°ndo, por qu√© y c√≥mo eligen implementarlos, as√≠ como las limitaciones de los sistemas que utilizan. Por ejemplo, si un banco utiliza un sistema de IA para apoyar sus decisiones de pr√©stamos al consumidor, es importante examinar los resultados y entender qu√© datos influyen en las recomendaciones del sistema. Los gobiernos est√°n comenzando a regular la IA en diversas industrias, por lo que los cient√≠ficos de datos y las organizaciones deben explicar si un sistema de IA cumple con los requisitos regulatorios, especialmente cuando hay un resultado no deseado.

> [üé• Haz clic aqu√≠ para ver un video: transparencia en IA](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Debido a que los sistemas de IA son tan complejos, es dif√≠cil entender c√≥mo funcionan e interpretar los resultados.
- Esta falta de comprensi√≥n afecta la forma en que se gestionan, operacionalizan y documentan estos sistemas.
- M√°s importante a√∫n, esta falta de comprensi√≥n afecta las decisiones tomadas utilizando los resultados que producen estos sistemas.

### Responsabilidad

Las personas que dise√±an y despliegan sistemas de IA deben ser responsables de c√≥mo operan sus sistemas. La necesidad de responsabilidad es particularmente crucial con tecnolog√≠as de uso sensible como el reconocimiento facial. Recientemente, ha habido una creciente demanda de tecnolog√≠a de reconocimiento facial, especialmente por parte de organizaciones de aplicaci√≥n de la ley que ven el potencial de la tecnolog√≠a en usos como encontrar ni√±os desaparecidos. Sin embargo, estas tecnolog√≠as podr√≠an ser utilizadas por un gobierno para poner en riesgo las libertades fundamentales de sus ciudadanos, por ejemplo, habilitando la vigilancia continua de individuos espec√≠ficos. Por lo tanto, los cient√≠ficos de datos y las organizaciones deben ser responsables de c√≥mo su sistema de IA impacta a las personas o la sociedad.

[![Investigador l√≠der en IA advierte sobre vigilancia masiva a trav√©s del reconocimiento facial](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/3-fairness/images/accountability.png)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "Enfoque de Microsoft hacia la IA Responsable")

> üé• Haz clic en la imagen de arriba para ver el video: Advertencias sobre vigilancia masiva a trav√©s del reconocimiento facial

En √∫ltima instancia, una de las mayores preguntas para nuestra generaci√≥n, como la primera generaci√≥n que est√° llevando la IA a la sociedad, es c√≥mo garantizar que las computadoras sigan siendo responsables ante las personas y c√≥mo garantizar que las personas que dise√±an computadoras sean responsables ante todos los dem√°s.

## Evaluaci√≥n de impacto

Antes de entrenar un modelo de aprendizaje autom√°tico, es importante realizar una evaluaci√≥n de impacto para entender el prop√≥sito del sistema de IA; cu√°l es el uso previsto; d√≥nde se desplegar√°; y qui√©n interactuar√° con el sistema. Esto es √∫til para los revisores o evaluadores del sistema para saber qu√© factores considerar al identificar riesgos potenciales y consecuencias esperadas.

Las siguientes son √°reas de enfoque al realizar una evaluaci√≥n de impacto:

* **Impacto adverso en individuos**. Ser consciente de cualquier restricci√≥n o requisito, uso no compatible o cualquier limitaci√≥n conocida que obstaculice el rendimiento del sistema es vital para garantizar que el sistema no se utilice de manera que pueda causar da√±o a las personas.
* **Requisitos de datos**. Comprender c√≥mo y d√≥nde el sistema utilizar√° datos permite a los revisores explorar cualquier requisito de datos que debas tener en cuenta (por ejemplo, regulaciones de datos como GDPR o HIPAA). Adem√°s, examina si la fuente o cantidad de datos es suficiente para el entrenamiento.
* **Resumen del impacto**. Re√∫ne una lista de posibles da√±os que podr√≠an surgir del uso del sistema. A lo largo del ciclo de vida del aprendizaje autom√°tico, revisa si los problemas identificados se han mitigado o abordado.
* **Metas aplicables** para cada uno de los seis principios fundamentales. Eval√∫a si las metas de cada principio se cumplen y si hay alguna brecha.

## Depuraci√≥n con IA responsable

Al igual que depurar una aplicaci√≥n de software, depurar un sistema de IA es un proceso necesario para identificar y resolver problemas en el sistema. Hay muchos factores que pueden afectar que un modelo no funcione como se espera o de manera responsable. La mayor√≠a de las m√©tricas tradicionales de rendimiento de modelos son agregados cuantitativos del rendimiento de un modelo, lo cual no es suficiente para analizar c√≥mo un modelo viola los principios de IA responsable. Adem√°s, un modelo de aprendizaje autom√°tico es una caja negra que dificulta entender qu√© impulsa su resultado o proporcionar explicaciones cuando comete un error. M√°s adelante en este curso, aprenderemos c√≥mo usar el panel de IA Responsable para ayudar a depurar sistemas de IA. El panel proporciona una herramienta integral para que los cient√≠ficos de datos y desarrolladores de IA realicen:

* **An√°lisis de errores**. Para identificar la distribuci√≥n de errores del modelo que puede afectar la equidad o confiabilidad del sistema.
* **Visi√≥n general del modelo**. Para descubrir d√≥nde hay disparidades en el rendimiento del modelo entre cohortes de datos.
* **An√°lisis de datos**. Para entender la distribuci√≥n de datos e identificar cualquier sesgo potencial en los datos que podr√≠a generar problemas de equidad, inclusi√≥n y confiabilidad.
* **Interpretabilidad del modelo**. Para entender qu√© afecta o influye en las predicciones del modelo. Esto ayuda a explicar el comportamiento del modelo, lo cual es importante para la transparencia y la responsabilidad.

## üöÄ Desaf√≠o

Para prevenir da√±os desde el principio, deber√≠amos:

- contar con diversidad de antecedentes y perspectivas entre las personas que trabajan en los sistemas
- invertir en conjuntos de datos que reflejen la diversidad de nuestra sociedad
- desarrollar mejores m√©todos a lo largo del ciclo de vida del aprendizaje autom√°tico para detectar y corregir problemas de IA responsable cuando ocurran

Piensa en escenarios de la vida real donde la falta de confianza en un modelo sea evidente en su construcci√≥n y uso. ¬øQu√© m√°s deber√≠amos considerar?

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y autoestudio

En esta lecci√≥n, has aprendido algunos conceptos b√°sicos sobre la equidad y la falta de equidad en el aprendizaje autom√°tico.
Mira este taller para profundizar en los temas:

- En busca de una IA responsable: Llevando los principios a la pr√°ctica por Besmira Nushi, Mehrnoosh Sameki y Amit Sharma

[![Responsible AI Toolbox: Un marco de c√≥digo abierto para construir IA responsable](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: Un marco de c√≥digo abierto para construir IA responsable")

> üé• Haz clic en la imagen de arriba para ver el video: RAI Toolbox: Un marco de c√≥digo abierto para construir IA responsable por Besmira Nushi, Mehrnoosh Sameki y Amit Sharma

Adem√°s, lee:

- Centro de recursos de RAI de Microsoft: [Responsible AI Resources ‚Äì Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Grupo de investigaci√≥n FATE de Microsoft: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

RAI Toolbox:

- [Repositorio de GitHub de Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox)

Lee sobre las herramientas de Azure Machine Learning para garantizar la equidad:

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott)

## Tarea

[Explora RAI Toolbox](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9d91f3af3758fdd4569fb410575995ef",
  "translation_date": "2025-09-04T22:21:15+00:00",
  "source_file": "1-Introduction/4-techniques-of-ML/README.md",
  "language_code": "es"
}
-->
# T√©cnicas de Aprendizaje Autom√°tico

El proceso de construir, usar y mantener modelos de aprendizaje autom√°tico y los datos que utilizan es muy diferente de muchos otros flujos de trabajo de desarrollo. En esta lecci√≥n, desmitificaremos el proceso y describiremos las principales t√©cnicas que necesitas conocer. T√∫:

- Comprender√°s los procesos que sustentan el aprendizaje autom√°tico a un nivel general.
- Explorar√°s conceptos b√°sicos como 'modelos', 'predicciones' y 'datos de entrenamiento'.

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

[![ML para principiantes - T√©cnicas de Aprendizaje Autom√°tico](https://img.youtube.com/vi/4NGM0U2ZSHU/0.jpg)](https://youtu.be/4NGM0U2ZSHU "ML para principiantes - T√©cnicas de Aprendizaje Autom√°tico")

> üé• Haz clic en la imagen de arriba para ver un breve video sobre esta lecci√≥n.

## Introducci√≥n

A un nivel general, el arte de crear procesos de aprendizaje autom√°tico (ML) se compone de varios pasos:

1. **Decidir la pregunta**. La mayor√≠a de los procesos de ML comienzan formulando una pregunta que no puede ser respondida mediante un programa condicional simple o un motor basado en reglas. Estas preguntas suelen girar en torno a predicciones basadas en una colecci√≥n de datos.
2. **Recopilar y preparar datos**. Para poder responder a tu pregunta, necesitas datos. La calidad y, a veces, la cantidad de tus datos determinar√°n qu√© tan bien puedes responder a tu pregunta inicial. Visualizar los datos es un aspecto importante de esta fase. Esta fase tambi√©n incluye dividir los datos en un grupo de entrenamiento y prueba para construir un modelo.
3. **Elegir un m√©todo de entrenamiento**. Dependiendo de tu pregunta y la naturaleza de tus datos, necesitas elegir c√≥mo deseas entrenar un modelo para reflejar mejor tus datos y hacer predicciones precisas. Esta es la parte de tu proceso de ML que requiere experiencia espec√≠fica y, a menudo, una cantidad considerable de experimentaci√≥n.
4. **Entrenar el modelo**. Usando tus datos de entrenamiento, utilizar√°s varios algoritmos para entrenar un modelo que reconozca patrones en los datos. El modelo puede aprovechar pesos internos que se ajustan para privilegiar ciertas partes de los datos sobre otras y construir un mejor modelo.
5. **Evaluar el modelo**. Utilizas datos nunca antes vistos (tus datos de prueba) de tu conjunto recopilado para ver c√≥mo est√° funcionando el modelo.
6. **Ajuste de par√°metros**. Bas√°ndote en el rendimiento de tu modelo, puedes repetir el proceso utilizando diferentes par√°metros o variables que controlan el comportamiento de los algoritmos utilizados para entrenar el modelo.
7. **Predecir**. Usa nuevas entradas para probar la precisi√≥n de tu modelo.

## Qu√© pregunta hacer

Las computadoras son particularmente h√°biles para descubrir patrones ocultos en los datos. Esta utilidad es muy √∫til para los investigadores que tienen preguntas sobre un dominio dado que no pueden ser respondidas f√°cilmente creando un motor basado en reglas condicionales. Dado un trabajo actuarial, por ejemplo, un cient√≠fico de datos podr√≠a construir reglas manuales sobre la mortalidad de fumadores frente a no fumadores.

Sin embargo, cuando se introducen muchas otras variables en la ecuaci√≥n, un modelo de ML podr√≠a resultar m√°s eficiente para predecir tasas de mortalidad futuras bas√°ndose en historiales de salud pasados. Un ejemplo m√°s alegre podr√≠a ser hacer predicciones meteorol√≥gicas para el mes de abril en una ubicaci√≥n dada bas√°ndose en datos que incluyen latitud, longitud, cambio clim√°tico, proximidad al oc√©ano, patrones de la corriente en chorro y m√°s.

‚úÖ Este [conjunto de diapositivas](https://www2.cisl.ucar.edu/sites/default/files/2021-10/0900%20June%2024%20Haupt_0.pdf) sobre modelos meteorol√≥gicos ofrece una perspectiva hist√≥rica sobre el uso de ML en el an√°lisis del clima.  

## Tareas previas a la construcci√≥n

Antes de comenzar a construir tu modelo, hay varias tareas que necesitas completar. Para probar tu pregunta y formular una hip√≥tesis basada en las predicciones de un modelo, necesitas identificar y configurar varios elementos.

### Datos

Para poder responder a tu pregunta con alg√∫n tipo de certeza, necesitas una buena cantidad de datos del tipo correcto. Hay dos cosas que necesitas hacer en este punto:

- **Recopilar datos**. Teniendo en cuenta la lecci√≥n anterior sobre equidad en el an√°lisis de datos, recopila tus datos con cuidado. S√© consciente de las fuentes de estos datos, cualquier sesgo inherente que puedan tener y documenta su origen.
- **Preparar datos**. Hay varios pasos en el proceso de preparaci√≥n de datos. Es posible que necesites compilar datos y normalizarlos si provienen de fuentes diversas. Puedes mejorar la calidad y cantidad de los datos mediante varios m√©todos, como convertir cadenas en n√∫meros (como hacemos en [Clustering](../../5-Clustering/1-Visualize/README.md)). Tambi√©n puedes generar nuevos datos basados en los originales (como hacemos en [Clasificaci√≥n](../../4-Classification/1-Introduction/README.md)). Puedes limpiar y editar los datos (como haremos antes de la lecci√≥n de [Aplicaci√≥n Web](../../3-Web-App/README.md)). Finalmente, tambi√©n podr√≠as necesitar aleatorizarlos y mezclarlos, dependiendo de tus t√©cnicas de entrenamiento.

‚úÖ Despu√©s de recopilar y procesar tus datos, t√≥mate un momento para ver si su forma te permitir√° abordar tu pregunta. Puede ser que los datos no funcionen bien en tu tarea dada, como descubrimos en nuestras lecciones de [Clustering](../../5-Clustering/1-Visualize/README.md).

### Caracter√≠sticas y Objetivo

Una [caracter√≠stica](https://www.datasciencecentral.com/profiles/blogs/an-introduction-to-variable-and-feature-selection) es una propiedad medible de tus datos. En muchos conjuntos de datos se expresa como un encabezado de columna como 'fecha', 'tama√±o' o 'color'. Tu variable de caracter√≠stica, usualmente representada como `X` en el c√≥digo, representa la variable de entrada que se usar√° para entrenar el modelo.

Un objetivo es aquello que est√°s tratando de predecir. El objetivo, usualmente representado como `y` en el c√≥digo, representa la respuesta a la pregunta que est√°s tratando de hacer a tus datos: en diciembre, ¬øqu√© **color** de calabazas ser√° el m√°s barato? En San Francisco, ¬øqu√© vecindarios tendr√°n el mejor **precio** inmobiliario? A veces el objetivo tambi√©n se denomina atributo de etiqueta.

### Selecci√≥n de tu variable de caracter√≠stica

üéì **Selecci√≥n de Caracter√≠sticas y Extracci√≥n de Caracter√≠sticas** ¬øC√≥mo sabes qu√© variable elegir al construir un modelo? Probablemente pasar√°s por un proceso de selecci√≥n de caracter√≠sticas o extracci√≥n de caracter√≠sticas para elegir las variables correctas para el modelo m√°s eficiente. Sin embargo, no son lo mismo: "La extracci√≥n de caracter√≠sticas crea nuevas caracter√≠sticas a partir de funciones de las caracter√≠sticas originales, mientras que la selecci√≥n de caracter√≠sticas devuelve un subconjunto de las caracter√≠sticas." ([fuente](https://wikipedia.org/wiki/Feature_selection))

### Visualiza tus datos

Un aspecto importante del conjunto de herramientas del cient√≠fico de datos es el poder de visualizar datos utilizando varias bibliotecas excelentes como Seaborn o MatPlotLib. Representar tus datos visualmente podr√≠a permitirte descubrir correlaciones ocultas que puedes aprovechar. Tus visualizaciones tambi√©n podr√≠an ayudarte a descubrir sesgos o datos desequilibrados (como descubrimos en [Clasificaci√≥n](../../4-Classification/2-Classifiers-1/README.md)).

### Divide tu conjunto de datos

Antes de entrenar, necesitas dividir tu conjunto de datos en dos o m√°s partes de tama√±o desigual que a√∫n representen bien los datos.

- **Entrenamiento**. Esta parte del conjunto de datos se ajusta a tu modelo para entrenarlo. Este conjunto constituye la mayor√≠a del conjunto de datos original.
- **Prueba**. Un conjunto de prueba es un grupo independiente de datos, a menudo recopilado del conjunto original, que utilizas para confirmar el rendimiento del modelo construido.
- **Validaci√≥n**. Un conjunto de validaci√≥n es un grupo independiente m√°s peque√±o de ejemplos que utilizas para ajustar los hiperpar√°metros o la arquitectura del modelo para mejorarlo. Dependiendo del tama√±o de tus datos y la pregunta que est√°s haciendo, es posible que no necesites construir este tercer conjunto (como se√±alamos en [Pron√≥stico de Series Temporales](../../7-TimeSeries/1-Introduction/README.md)).

## Construcci√≥n de un modelo

Usando tus datos de entrenamiento, tu objetivo es construir un modelo, o una representaci√≥n estad√≠stica de tus datos, utilizando varios algoritmos para **entrenarlo**. Entrenar un modelo lo expone a datos y le permite hacer suposiciones sobre patrones percibidos que descubre, valida y acepta o rechaza.

### Decidir un m√©todo de entrenamiento

Dependiendo de tu pregunta y la naturaleza de tus datos, elegir√°s un m√©todo para entrenarlo. Al recorrer la [documentaci√≥n de Scikit-learn](https://scikit-learn.org/stable/user_guide.html) - que usamos en este curso - puedes explorar muchas formas de entrenar un modelo. Dependiendo de tu experiencia, es posible que tengas que probar varios m√©todos diferentes para construir el mejor modelo. Es probable que pases por un proceso en el que los cient√≠ficos de datos eval√∫an el rendimiento de un modelo aliment√°ndolo con datos no vistos, verificando su precisi√≥n, sesgo y otros problemas que degradan la calidad, y seleccionando el m√©todo de entrenamiento m√°s apropiado para la tarea en cuesti√≥n.

### Entrenar un modelo

Con tus datos de entrenamiento, est√°s listo para 'ajustarlo' y crear un modelo. Notar√°s que en muchas bibliotecas de ML encontrar√°s el c√≥digo 'model.fit' - es en este momento que env√≠as tu variable de caracter√≠stica como un arreglo de valores (usualmente 'X') y una variable objetivo (usualmente 'y').

### Evaluar el modelo

Una vez que el proceso de entrenamiento est√© completo (puede tomar muchas iteraciones, o '√©pocas', para entrenar un modelo grande), podr√°s evaluar la calidad del modelo utilizando datos de prueba para medir su rendimiento. Estos datos son un subconjunto de los datos originales que el modelo no ha analizado previamente. Puedes imprimir una tabla de m√©tricas sobre la calidad de tu modelo.

üéì **Ajuste del modelo**

En el contexto del aprendizaje autom√°tico, el ajuste del modelo se refiere a la precisi√≥n de la funci√≥n subyacente del modelo mientras intenta analizar datos con los que no est√° familiarizado.

üéì **Subajuste** y **sobreajuste** son problemas comunes que degradan la calidad del modelo, ya que el modelo se ajusta demasiado poco o demasiado bien. Esto hace que el modelo haga predicciones demasiado alineadas o demasiado poco alineadas con sus datos de entrenamiento. Un modelo sobreajustado predice los datos de entrenamiento demasiado bien porque ha aprendido demasiado bien los detalles y el ruido de los datos. Un modelo subajustado no es preciso ya que no puede analizar con precisi√≥n ni sus datos de entrenamiento ni los datos que a√∫n no ha 'visto'.

![modelo sobreajustado](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/1-Introduction/4-techniques-of-ML/images/overfitting.png)
> Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

## Ajuste de par√°metros

Una vez que tu entrenamiento inicial est√© completo, observa la calidad del modelo y considera mejorarlo ajustando sus 'hiperpar√°metros'. Lee m√°s sobre el proceso [en la documentaci√≥n](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters?WT.mc_id=academic-77952-leestott).

## Predicci√≥n

Este es el momento en el que puedes usar datos completamente nuevos para probar la precisi√≥n de tu modelo. En un entorno de ML 'aplicado', donde est√°s construyendo activos web para usar el modelo en producci√≥n, este proceso podr√≠a implicar recopilar la entrada del usuario (por ejemplo, presionar un bot√≥n) para establecer una variable y enviarla al modelo para inferencia o evaluaci√≥n.

En estas lecciones, descubrir√°s c√≥mo usar estos pasos para preparar, construir, probar, evaluar y predecir: todos los gestos de un cient√≠fico de datos y m√°s, mientras avanzas en tu camino para convertirte en un ingeniero de ML 'full stack'.

---

## üöÄDesaf√≠o

Dibuja un diagrama de flujo que refleje los pasos de un practicante de ML. ¬øD√≥nde te ves ahora en el proceso? ¬øD√≥nde predices que encontrar√°s dificultades? ¬øQu√© te parece f√°cil?

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y Autoestudio

Busca en l√≠nea entrevistas con cient√≠ficos de datos que hablen sobre su trabajo diario. Aqu√≠ tienes [una](https://www.youtube.com/watch?v=Z3IjgbbCEfs).

## Tarea

[Entrevista a un cient√≠fico de datos](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---


# Regresi√≥n

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "508582278dbb8edd2a8a80ac96ef416c",
  "translation_date": "2025-09-03T22:15:28+00:00",
  "source_file": "2-Regression/README.md",
  "language_code": "es"
}
-->
# Modelos de regresi√≥n para aprendizaje autom√°tico
## Tema regional: Modelos de regresi√≥n para precios de calabazas en Am√©rica del Norte üéÉ

En Am√©rica del Norte, las calabazas suelen tallarse con caras aterradoras para Halloween. ¬°Descubramos m√°s sobre estos fascinantes vegetales!

![jack-o-lanterns](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/translated_images/es/jack-o-lanterns.181c661a9212457d.webp)
> Foto por <a href="https://unsplash.com/@teutschmann?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Beth Teutschmann</a> en <a href="https://unsplash.com/s/photos/jack-o-lanterns?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
  
## Lo que aprender√°s

[![Introducci√≥n a la regresi√≥n](https://img.youtube.com/vi/5QnJtDad4iQ/0.jpg)](https://youtu.be/5QnJtDad4iQ "Video de introducci√≥n a la regresi√≥n - ¬°Haz clic para verlo!")
> üé• Haz clic en la imagen de arriba para ver un video introductorio r√°pido de esta lecci√≥n.

Las lecciones en esta secci√≥n cubren los tipos de regresi√≥n en el contexto del aprendizaje autom√°tico. Los modelos de regresi√≥n pueden ayudar a determinar la _relaci√≥n_ entre variables. Este tipo de modelo puede predecir valores como longitud, temperatura o edad, revelando as√≠ relaciones entre variables mientras analiza puntos de datos.

En esta serie de lecciones, descubrir√°s las diferencias entre regresi√≥n lineal y log√≠stica, y cu√°ndo deber√≠as preferir una sobre la otra.

[![ML para principiantes - Introducci√≥n a los modelos de regresi√≥n para aprendizaje autom√°tico](https://img.youtube.com/vi/XA3OaoW86R8/0.jpg)](https://youtu.be/XA3OaoW86R8 "ML para principiantes - Introducci√≥n a los modelos de regresi√≥n para aprendizaje autom√°tico")

> üé• Haz clic en la imagen de arriba para ver un breve video que introduce los modelos de regresi√≥n.

En este grupo de lecciones, te preparar√°s para comenzar tareas de aprendizaje autom√°tico, incluyendo la configuraci√≥n de Visual Studio Code para gestionar notebooks, el entorno com√∫n para los cient√≠ficos de datos. Descubrir√°s Scikit-learn, una biblioteca para aprendizaje autom√°tico, y construir√°s tus primeros modelos, enfoc√°ndote en modelos de regresi√≥n en este cap√≠tulo.

> Hay herramientas √∫tiles de bajo c√≥digo que pueden ayudarte a aprender sobre el trabajo con modelos de regresi√≥n. Prueba [Azure ML para esta tarea](https://docs.microsoft.com/learn/modules/create-regression-model-azure-machine-learning-designer/?WT.mc_id=academic-77952-leestott)

### Lecciones

1. [Herramientas del oficio](1-Tools/README.md)
2. [Gesti√≥n de datos](2-Data/README.md)
3. [Regresi√≥n lineal y polin√≥mica](3-Linear/README.md)
4. [Regresi√≥n log√≠stica](4-Logistic/README.md)

---
### Cr√©ditos

"ML con regresi√≥n" fue escrito con ‚ô•Ô∏è por [Jen Looper](https://twitter.com/jenlooper)

‚ô•Ô∏è Los colaboradores de los cuestionarios incluyen: [Muhammad Sakib Khan Inan](https://twitter.com/Sakibinan) y [Ornella Altunyan](https://twitter.com/ornelladotcom)

El conjunto de datos de calabazas es sugerido por [este proyecto en Kaggle](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) y sus datos provienen de los [Informes est√°ndar de mercados terminales de cultivos especializados](https://www.marketnews.usda.gov/mnp/fv-report-config-step1?type=termPrice) distribuidos por el Departamento de Agricultura de los Estados Unidos. Hemos a√±adido algunos puntos sobre el color seg√∫n la variedad para normalizar la distribuci√≥n. Estos datos est√°n en el dominio p√∫blico.

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "fa81d226c71d5af7a2cade31c1c92b88",
  "translation_date": "2025-09-04T22:13:49+00:00",
  "source_file": "2-Regression/1-Tools/README.md",
  "language_code": "es"
}
-->
# Comienza con Python y Scikit-learn para modelos de regresi√≥n

![Resumen de regresiones en un sketchnote](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/sketchnotes/ml-regression.png)

> Sketchnote por [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

> ### [¬°Esta lecci√≥n est√° disponible en R!](../../../../2-Regression/1-Tools/solution/R/lesson_1.html)

## Introducci√≥n

En estas cuatro lecciones, descubrir√°s c√≥mo construir modelos de regresi√≥n. Hablaremos sobre para qu√© sirven en breve. Pero antes de hacer nada, ¬°aseg√∫rate de tener las herramientas adecuadas para comenzar el proceso!

En esta lecci√≥n, aprender√°s a:

- Configurar tu computadora para tareas locales de aprendizaje autom√°tico.
- Trabajar con Jupyter notebooks.
- Usar Scikit-learn, incluyendo su instalaci√≥n.
- Explorar la regresi√≥n lineal con un ejercicio pr√°ctico.

## Instalaciones y configuraciones

[![ML para principiantes - Configura tus herramientas para construir modelos de aprendizaje autom√°tico](https://img.youtube.com/vi/-DfeD2k2Kj0/0.jpg)](https://youtu.be/-DfeD2k2Kj0 "ML para principiantes - Configura tus herramientas para construir modelos de aprendizaje autom√°tico")

> üé• Haz clic en la imagen de arriba para ver un video corto sobre c√≥mo configurar tu computadora para ML.

1. **Instalar Python**. Aseg√∫rate de que [Python](https://www.python.org/downloads/) est√© instalado en tu computadora. Usar√°s Python para muchas tareas de ciencia de datos y aprendizaje autom√°tico. La mayor√≠a de los sistemas inform√°ticos ya incluyen una instalaci√≥n de Python. Tambi√©n hay disponibles [Paquetes de Codificaci√≥n de Python](https://code.visualstudio.com/learn/educators/installers?WT.mc_id=academic-77952-leestott) √∫tiles para facilitar la configuraci√≥n a algunos usuarios.

   Sin embargo, algunos usos de Python requieren una versi√≥n espec√≠fica del software, mientras que otros requieren una versi√≥n diferente. Por esta raz√≥n, es √∫til trabajar dentro de un [entorno virtual](https://docs.python.org/3/library/venv.html).

2. **Instalar Visual Studio Code**. Aseg√∫rate de tener Visual Studio Code instalado en tu computadora. Sigue estas instrucciones para [instalar Visual Studio Code](https://code.visualstudio.com/) para la instalaci√≥n b√°sica. Vas a usar Python en Visual Studio Code en este curso, por lo que podr√≠as querer repasar c√≥mo [configurar Visual Studio Code](https://docs.microsoft.com/learn/modules/python-install-vscode?WT.mc_id=academic-77952-leestott) para el desarrollo en Python.

   > Familiar√≠zate con Python trabajando en esta colecci√≥n de [m√≥dulos de aprendizaje](https://docs.microsoft.com/users/jenlooper-2911/collections/mp1pagggd5qrq7?WT.mc_id=academic-77952-leestott)
   >
   > [![Configura Python con Visual Studio Code](https://img.youtube.com/vi/yyQM70vi7V8/0.jpg)](https://youtu.be/yyQM70vi7V8 "Configura Python con Visual Studio Code")
   >
   > üé• Haz clic en la imagen de arriba para ver un video: usando Python dentro de VS Code.

3. **Instalar Scikit-learn**, siguiendo [estas instrucciones](https://scikit-learn.org/stable/install.html). Dado que necesitas asegurarte de usar Python 3, se recomienda que utilices un entorno virtual. Nota: si est√°s instalando esta biblioteca en una Mac M1, hay instrucciones especiales en la p√°gina enlazada arriba.

4. **Instalar Jupyter Notebook**. Necesitar√°s [instalar el paquete Jupyter](https://pypi.org/project/jupyter/).

## Tu entorno de autor√≠a de ML

Vas a usar **notebooks** para desarrollar tu c√≥digo en Python y crear modelos de aprendizaje autom√°tico. Este tipo de archivo es una herramienta com√∫n para los cient√≠ficos de datos y se identifican por su sufijo o extensi√≥n `.ipynb`.

Los notebooks son un entorno interactivo que permite al desarrollador tanto codificar como agregar notas y escribir documentaci√≥n alrededor del c√≥digo, lo cual es bastante √∫til para proyectos experimentales o de investigaci√≥n.

[![ML para principiantes - Configura Jupyter Notebooks para comenzar a construir modelos de regresi√≥n](https://img.youtube.com/vi/7E-jC8FLA2E/0.jpg)](https://youtu.be/7E-jC8FLA2E "ML para principiantes - Configura Jupyter Notebooks para comenzar a construir modelos de regresi√≥n")

> üé• Haz clic en la imagen de arriba para ver un video corto sobre este ejercicio.

### Ejercicio - trabajar con un notebook

En esta carpeta, encontrar√°s el archivo _notebook.ipynb_.

1. Abre _notebook.ipynb_ en Visual Studio Code.

   Se iniciar√° un servidor Jupyter con Python 3+. Encontrar√°s √°reas del notebook que pueden ser `ejecutadas`, piezas de c√≥digo. Puedes ejecutar un bloque de c√≥digo seleccionando el √≠cono que parece un bot√≥n de reproducci√≥n.

2. Selecciona el √≠cono `md` y agrega un poco de markdown, y el siguiente texto **# Bienvenido a tu notebook**.

   Luego, agrega algo de c√≥digo en Python.

3. Escribe **print('hello notebook')** en el bloque de c√≥digo.
4. Selecciona la flecha para ejecutar el c√≥digo.

   Deber√≠as ver la declaraci√≥n impresa:

    ```output
    hello notebook
    ```

![VS Code con un notebook abierto](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/1-Tools/images/notebook.jpg)

Puedes intercalar tu c√≥digo con comentarios para auto-documentar el notebook.

‚úÖ Piensa por un momento en c√≥mo es diferente el entorno de trabajo de un desarrollador web en comparaci√≥n con el de un cient√≠fico de datos.

## Puesta en marcha con Scikit-learn

Ahora que Python est√° configurado en tu entorno local y te sientes c√≥modo con los notebooks de Jupyter, vamos a familiarizarnos con Scikit-learn (se pronuncia `sci` como en `science`). Scikit-learn proporciona una [API extensa](https://scikit-learn.org/stable/modules/classes.html#api-ref) para ayudarte a realizar tareas de ML.

Seg√∫n su [sitio web](https://scikit-learn.org/stable/getting_started.html), "Scikit-learn es una biblioteca de aprendizaje autom√°tico de c√≥digo abierto que admite aprendizaje supervisado y no supervisado. Tambi√©n proporciona varias herramientas para ajuste de modelos, preprocesamiento de datos, selecci√≥n y evaluaci√≥n de modelos, y muchas otras utilidades."

En este curso, usar√°s Scikit-learn y otras herramientas para construir modelos de aprendizaje autom√°tico para realizar lo que llamamos tareas de 'aprendizaje autom√°tico tradicional'. Hemos evitado deliberadamente redes neuronales y aprendizaje profundo, ya que est√°n mejor cubiertos en nuestro pr√≥ximo curr√≠culo 'AI para Principiantes'.

Scikit-learn hace que sea sencillo construir modelos y evaluarlos para su uso. Se centra principalmente en el uso de datos num√©ricos y contiene varios conjuntos de datos listos para usar como herramientas de aprendizaje. Tambi√©n incluye modelos preconstruidos para que los estudiantes los prueben. Vamos a explorar el proceso de cargar datos preempaquetados y usar un estimador para el primer modelo de ML con Scikit-learn con algunos datos b√°sicos.

## Ejercicio - tu primer notebook con Scikit-learn

> Este tutorial fue inspirado por el [ejemplo de regresi√≥n lineal](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#sphx-glr-auto-examples-linear-model-plot-ols-py) en el sitio web de Scikit-learn.

[![ML para principiantes - Tu primer proyecto de regresi√≥n lineal en Python](https://img.youtube.com/vi/2xkXL5EUpS0/0.jpg)](https://youtu.be/2xkXL5EUpS0 "ML para principiantes - Tu primer proyecto de regresi√≥n lineal en Python")

> üé• Haz clic en la imagen de arriba para ver un video corto sobre este ejercicio.

En el archivo _notebook.ipynb_ asociado a esta lecci√≥n, elimina todas las celdas presionando el √≠cono de 'papelera'.

En esta secci√≥n, trabajar√°s con un peque√±o conjunto de datos sobre diabetes que est√° integrado en Scikit-learn para prop√≥sitos de aprendizaje. Imagina que quisieras probar un tratamiento para pacientes diab√©ticos. Los modelos de aprendizaje autom√°tico podr√≠an ayudarte a determinar qu√© pacientes responder√≠an mejor al tratamiento, bas√°ndote en combinaciones de variables. Incluso un modelo de regresi√≥n muy b√°sico, cuando se visualiza, podr√≠a mostrar informaci√≥n sobre variables que te ayudar√≠an a organizar tus ensayos cl√≠nicos te√≥ricos.

‚úÖ Hay muchos tipos de m√©todos de regresi√≥n, y cu√°l elijas depende de la respuesta que est√©s buscando. Si quieres predecir la altura probable de una persona dada su edad, usar√≠as regresi√≥n lineal, ya que est√°s buscando un **valor num√©rico**. Si est√°s interesado en descubrir si un tipo de cocina deber√≠a considerarse vegana o no, est√°s buscando una **asignaci√≥n de categor√≠a**, por lo que usar√≠as regresi√≥n log√≠stica. Aprender√°s m√°s sobre regresi√≥n log√≠stica m√°s adelante. Piensa un poco en algunas preguntas que puedes hacer a los datos y cu√°l de estos m√©todos ser√≠a m√°s apropiado.

Vamos a comenzar con esta tarea.

### Importar bibliotecas

Para esta tarea, importaremos algunas bibliotecas:

- **matplotlib**. Es una herramienta √∫til para [graficar](https://matplotlib.org/) y la usaremos para crear un gr√°fico de l√≠neas.
- **numpy**. [numpy](https://numpy.org/doc/stable/user/whatisnumpy.html) es una biblioteca √∫til para manejar datos num√©ricos en Python.
- **sklearn**. Esta es la biblioteca [Scikit-learn](https://scikit-learn.org/stable/user_guide.html).

Importa algunas bibliotecas para ayudarte con tus tareas.

1. Agrega las importaciones escribiendo el siguiente c√≥digo:

   ```python
   import matplotlib.pyplot as plt
   import numpy as np
   from sklearn import datasets, linear_model, model_selection
   ```

   Arriba est√°s importando `matplotlib`, `numpy` y est√°s importando `datasets`, `linear_model` y `model_selection` de `sklearn`. `model_selection` se usa para dividir datos en conjuntos de entrenamiento y prueba.

### El conjunto de datos de diabetes

El [conjunto de datos de diabetes](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset) integrado incluye 442 muestras de datos sobre diabetes, con 10 variables de caracter√≠sticas, algunas de las cuales incluyen:

- age: edad en a√±os
- bmi: √≠ndice de masa corporal
- bp: presi√≥n arterial promedio
- s1 tc: c√©lulas T (un tipo de gl√≥bulos blancos)

‚úÖ Este conjunto de datos incluye el concepto de 'sexo' como una variable de caracter√≠stica importante para la investigaci√≥n sobre diabetes. Muchos conjuntos de datos m√©dicos incluyen este tipo de clasificaci√≥n binaria. Piensa un poco en c√≥mo categorizaciones como esta podr√≠an excluir a ciertas partes de la poblaci√≥n de los tratamientos.

Ahora, carga los datos X e y.

> üéì Recuerda, esto es aprendizaje supervisado, y necesitamos un objetivo 'y' nombrado.

En una nueva celda de c√≥digo, carga el conjunto de datos de diabetes llamando a `load_diabetes()`. El par√°metro `return_X_y=True` indica que `X` ser√° una matriz de datos y `y` ser√° el objetivo de regresi√≥n.

1. Agrega algunos comandos de impresi√≥n para mostrar la forma de la matriz de datos y su primer elemento:

    ```python
    X, y = datasets.load_diabetes(return_X_y=True)
    print(X.shape)
    print(X[0])
    ```

    Lo que est√°s obteniendo como respuesta es una tupla. Lo que est√°s haciendo es asignar los dos primeros valores de la tupla a `X` e `y` respectivamente. Aprende m√°s [sobre tuplas](https://wikipedia.org/wiki/Tuple).

    Puedes ver que estos datos tienen 442 elementos organizados en matrices de 10 elementos:

    ```text
    (442, 10)
    [ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076
    -0.04340085 -0.00259226  0.01990842 -0.01764613]
    ```

    ‚úÖ Piensa un poco sobre la relaci√≥n entre los datos y el objetivo de regresi√≥n. La regresi√≥n lineal predice relaciones entre la caracter√≠stica X y la variable objetivo y. ¬øPuedes encontrar el [objetivo](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset) para el conjunto de datos de diabetes en la documentaci√≥n? ¬øQu√© est√° demostrando este conjunto de datos, dado ese objetivo?

2. A continuaci√≥n, selecciona una porci√≥n de este conjunto de datos para graficar seleccionando la tercera columna del conjunto de datos. Puedes hacerlo usando el operador `:` para seleccionar todas las filas y luego seleccionando la tercera columna usando el √≠ndice (2). Tambi√©n puedes cambiar la forma de los datos para que sean una matriz 2D, como se requiere para graficar, usando `reshape(n_rows, n_columns)`. Si uno de los par√°metros es -1, la dimensi√≥n correspondiente se calcula autom√°ticamente.

   ```python
   X = X[:, 2]
   X = X.reshape((-1,1))
   ```

   ‚úÖ En cualquier momento, imprime los datos para verificar su forma.

3. Ahora que tienes los datos listos para ser graficados, puedes ver si una m√°quina puede ayudar a determinar una divisi√≥n l√≥gica entre los n√∫meros en este conjunto de datos. Para hacer esto, necesitas dividir tanto los datos (X) como el objetivo (y) en conjuntos de prueba y entrenamiento. Scikit-learn tiene una forma sencilla de hacer esto; puedes dividir tus datos de prueba en un punto dado.

   ```python
   X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33)
   ```

4. ¬°Ahora est√°s listo para entrenar tu modelo! Carga el modelo de regresi√≥n lineal y entr√©nalo con tus conjuntos de entrenamiento X e y usando `model.fit()`:

    ```python
    model = linear_model.LinearRegression()
    model.fit(X_train, y_train)
    ```

    ‚úÖ `model.fit()` es una funci√≥n que ver√°s en muchas bibliotecas de ML como TensorFlow.

5. Luego, crea una predicci√≥n usando datos de prueba, utilizando la funci√≥n `predict()`. Esto se usar√° para dibujar la l√≠nea entre los grupos de datos.

    ```python
    y_pred = model.predict(X_test)
    ```

6. Ahora es momento de mostrar los datos en un gr√°fico. Matplotlib es una herramienta muy √∫til para esta tarea. Crea un gr√°fico de dispersi√≥n de todos los datos de prueba X e y, y usa la predicci√≥n para dibujar una l√≠nea en el lugar m√°s apropiado, entre los grupos de datos del modelo.

    ```python
    plt.scatter(X_test, y_test,  color='black')
    plt.plot(X_test, y_pred, color='blue', linewidth=3)
    plt.xlabel('Scaled BMIs')
    plt.ylabel('Disease Progression')
    plt.title('A Graph Plot Showing Diabetes Progression Against BMI')
    plt.show()
    ```

   ![un gr√°fico de dispersi√≥n mostrando puntos de datos sobre diabetes](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/1-Tools/images/scatterplot.png)
‚úÖ Piensa un poco en lo que est√° sucediendo aqu√≠. Una l√≠nea recta est√° atravesando muchos peque√±os puntos de datos, pero ¬øqu√© est√° haciendo exactamente? ¬øPuedes ver c√≥mo deber√≠as poder usar esta l√≠nea para predecir d√≥nde deber√≠a encajar un nuevo punto de datos no visto en relaci√≥n con el eje y del gr√°fico? Intenta poner en palabras el uso pr√°ctico de este modelo.

¬°Felicidades! Has construido tu primer modelo de regresi√≥n lineal, creado una predicci√≥n con √©l y la has mostrado en un gr√°fico.

---
## üöÄDesaf√≠o

Grafica una variable diferente de este conjunto de datos. Pista: edita esta l√≠nea: `X = X[:,2]`. Dado el objetivo de este conjunto de datos, ¬øqu√© puedes descubrir sobre la progresi√≥n de la diabetes como enfermedad?

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y Autoestudio

En este tutorial, trabajaste con regresi√≥n lineal simple, en lugar de regresi√≥n univariante o m√∫ltiple. Lee un poco sobre las diferencias entre estos m√©todos, o echa un vistazo a [este video](https://www.coursera.org/lecture/quantifying-relationships-regression-models/linear-vs-nonlinear-categorical-variables-ai2Ef).

Lee m√°s sobre el concepto de regresi√≥n y piensa en qu√© tipo de preguntas pueden responderse con esta t√©cnica. Toma este [tutorial](https://docs.microsoft.com/learn/modules/train-evaluate-regression-models?WT.mc_id=academic-77952-leestott) para profundizar tu comprensi√≥n.

## Tarea

[Un conjunto de datos diferente](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7c077988328ebfe33b24d07945f16eca",
  "translation_date": "2025-09-04T22:14:22+00:00",
  "source_file": "2-Regression/2-Data/README.md",
  "language_code": "es"
}
-->
# Construir un modelo de regresi√≥n usando Scikit-learn: preparar y visualizar datos

![Infograf√≠a de visualizaci√≥n de datos](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/2-Data/images/data-visualization.png)

Infograf√≠a por [Dasani Madipalli](https://twitter.com/dasani_decoded)

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

> ### [¬°Esta lecci√≥n est√° disponible en R!](../../../../2-Regression/2-Data/solution/R/lesson_2.html)

## Introducci√≥n

Ahora que tienes las herramientas necesarias para comenzar a construir modelos de aprendizaje autom√°tico con Scikit-learn, est√°s listo para empezar a formular preguntas sobre tus datos. Al trabajar con datos y aplicar soluciones de ML, es muy importante saber c√≥mo hacer la pregunta correcta para desbloquear adecuadamente el potencial de tu conjunto de datos.

En esta lecci√≥n, aprender√°s:

- C√≥mo preparar tus datos para construir modelos.
- C√≥mo usar Matplotlib para la visualizaci√≥n de datos.

## Hacer la pregunta correcta sobre tus datos

La pregunta que necesitas responder determinar√° qu√© tipo de algoritmos de ML utilizar√°s. Y la calidad de la respuesta que obtengas depender√° en gran medida de la naturaleza de tus datos.

Echa un vistazo a los [datos](https://github.com/microsoft/ML-For-Beginners/blob/main/2-Regression/data/US-pumpkins.csv) proporcionados para esta lecci√≥n. Puedes abrir este archivo .csv en VS Code. Una revisi√≥n r√°pida muestra que hay espacios en blanco y una mezcla de datos de tipo cadena y num√©ricos. Tambi√©n hay una columna extra√±a llamada 'Package' donde los datos son una mezcla entre 'sacks', 'bins' y otros valores. De hecho, los datos est√°n un poco desordenados.

[![ML para principiantes - C√≥mo analizar y limpiar un conjunto de datos](https://img.youtube.com/vi/5qGjczWTrDQ/0.jpg)](https://youtu.be/5qGjczWTrDQ "ML para principiantes - C√≥mo analizar y limpiar un conjunto de datos")

> üé• Haz clic en la imagen de arriba para ver un breve video sobre c√≥mo preparar los datos para esta lecci√≥n.

De hecho, no es muy com√∫n recibir un conjunto de datos completamente listo para usar y crear un modelo de ML directamente. En esta lecci√≥n, aprender√°s c√≥mo preparar un conjunto de datos sin procesar utilizando bibliotecas est√°ndar de Python. Tambi√©n aprender√°s varias t√©cnicas para visualizar los datos.

## Caso de estudio: 'el mercado de calabazas'

En esta carpeta encontrar√°s un archivo .csv en la carpeta ra√≠z `data` llamado [US-pumpkins.csv](https://github.com/microsoft/ML-For-Beginners/blob/main/2-Regression/data/US-pumpkins.csv), que incluye 1757 l√≠neas de datos sobre el mercado de calabazas, agrupados por ciudad. Estos son datos sin procesar extra√≠dos de los [Informes est√°ndar de mercados terminales de cultivos especiales](https://www.marketnews.usda.gov/mnp/fv-report-config-step1?type=termPrice) distribuidos por el Departamento de Agricultura de los Estados Unidos.

### Preparar los datos

Estos datos son de dominio p√∫blico. Se pueden descargar en muchos archivos separados, por ciudad, desde el sitio web del USDA. Para evitar demasiados archivos separados, hemos concatenado todos los datos de las ciudades en una sola hoja de c√°lculo, por lo que ya hemos _preparado_ un poco los datos. Ahora, echemos un vistazo m√°s de cerca a los datos.

### Los datos de calabazas - primeras conclusiones

¬øQu√© notas sobre estos datos? Ya viste que hay una mezcla de cadenas, n√∫meros, espacios en blanco y valores extra√±os que necesitas interpretar.

¬øQu√© pregunta puedes hacer sobre estos datos utilizando una t√©cnica de regresi√≥n? ¬øQu√© tal "Predecir el precio de una calabaza en venta durante un mes determinado"? Mirando nuevamente los datos, hay algunos cambios que necesitas hacer para crear la estructura de datos necesaria para esta tarea.

## Ejercicio - analizar los datos de calabazas

Usemos [Pandas](https://pandas.pydata.org/) (el nombre significa `Python Data Analysis`), una herramienta muy √∫til para dar forma a los datos, para analizar y preparar estos datos de calabazas.

### Primero, verifica si faltan fechas

Primero necesitar√°s tomar medidas para verificar si faltan fechas:

1. Convierte las fechas al formato de mes (estas son fechas de EE. UU., por lo que el formato es `MM/DD/YYYY`).
2. Extrae el mes a una nueva columna.

Abre el archivo _notebook.ipynb_ en Visual Studio Code e importa la hoja de c√°lculo en un nuevo dataframe de Pandas.

1. Usa la funci√≥n `head()` para ver las primeras cinco filas.

    ```python
    import pandas as pd
    pumpkins = pd.read_csv('../data/US-pumpkins.csv')
    pumpkins.head()
    ```

    ‚úÖ ¬øQu√© funci√≥n usar√≠as para ver las √∫ltimas cinco filas?

1. Verifica si hay datos faltantes en el dataframe actual:

    ```python
    pumpkins.isnull().sum()
    ```

    Hay datos faltantes, pero tal vez no importen para la tarea en cuesti√≥n.

1. Para que tu dataframe sea m√°s f√°cil de trabajar, selecciona solo las columnas que necesitas, usando la funci√≥n `loc`, que extrae del dataframe original un grupo de filas (pasadas como primer par√°metro) y columnas (pasadas como segundo par√°metro). La expresi√≥n `:` en el caso siguiente significa "todas las filas".

    ```python
    columns_to_select = ['Package', 'Low Price', 'High Price', 'Date']
    pumpkins = pumpkins.loc[:, columns_to_select]
    ```

### Segundo, determina el precio promedio de las calabazas

Piensa en c√≥mo determinar el precio promedio de una calabaza en un mes determinado. ¬øQu√© columnas elegir√≠as para esta tarea? Pista: necesitar√°s 3 columnas.

Soluci√≥n: toma el promedio de las columnas `Low Price` y `High Price` para llenar la nueva columna Price, y convierte la columna Date para que solo muestre el mes. Afortunadamente, seg√∫n la verificaci√≥n anterior, no hay datos faltantes para fechas o precios.

1. Para calcular el promedio, agrega el siguiente c√≥digo:

    ```python
    price = (pumpkins['Low Price'] + pumpkins['High Price']) / 2

    month = pd.DatetimeIndex(pumpkins['Date']).month

    ```

   ‚úÖ Si√©ntete libre de imprimir cualquier dato que desees verificar usando `print(month)`.

2. Ahora, copia tus datos convertidos en un nuevo dataframe de Pandas:

    ```python
    new_pumpkins = pd.DataFrame({'Month': month, 'Package': pumpkins['Package'], 'Low Price': pumpkins['Low Price'],'High Price': pumpkins['High Price'], 'Price': price})
    ```

    Al imprimir tu dataframe, ver√°s un conjunto de datos limpio y ordenado sobre el cual puedes construir tu nuevo modelo de regresi√≥n.

### Pero espera, ¬°hay algo extra√±o aqu√≠!

Si miras la columna `Package`, las calabazas se venden en muchas configuraciones diferentes. Algunas se venden en medidas de '1 1/9 bushel', otras en '1/2 bushel', algunas por calabaza, otras por libra, y algunas en grandes cajas con anchos variables.

> Parece que las calabazas son muy dif√≠ciles de pesar de manera consistente.

Al profundizar en los datos originales, es interesante notar que cualquier cosa con `Unit of Sale` igual a 'EACH' o 'PER BIN' tambi√©n tiene el tipo `Package` por pulgada, por bin, o 'each'. Parece que las calabazas son muy dif√≠ciles de pesar de manera consistente, as√≠ que filtremos seleccionando solo las calabazas con la cadena 'bushel' en su columna `Package`.

1. Agrega un filtro en la parte superior del archivo, debajo de la importaci√≥n inicial del .csv:

    ```python
    pumpkins = pumpkins[pumpkins['Package'].str.contains('bushel', case=True, regex=True)]
    ```

    Si imprimes los datos ahora, puedes ver que solo est√°s obteniendo las aproximadamente 415 filas de datos que contienen calabazas por bushel.

### Pero espera, ¬°hay una cosa m√°s por hacer!

¬øNotaste que la cantidad de bushel var√≠a por fila? Necesitas normalizar los precios para mostrar el precio por bushel, as√≠ que haz algunos c√°lculos para estandarizarlo.

1. Agrega estas l√≠neas despu√©s del bloque que crea el dataframe new_pumpkins:

    ```python
    new_pumpkins.loc[new_pumpkins['Package'].str.contains('1 1/9'), 'Price'] = price/(1 + 1/9)

    new_pumpkins.loc[new_pumpkins['Package'].str.contains('1/2'), 'Price'] = price/(1/2)
    ```

‚úÖ Seg√∫n [The Spruce Eats](https://www.thespruceeats.com/how-much-is-a-bushel-1389308), el peso de un bushel depende del tipo de producto, ya que es una medida de volumen. "Un bushel de tomates, por ejemplo, se supone que pesa 56 libras... Las hojas y los vegetales ocupan m√°s espacio con menos peso, por lo que un bushel de espinacas pesa solo 20 libras". ¬°Es todo bastante complicado! No nos molestemos en hacer una conversi√≥n de bushel a libra, y en su lugar fijemos el precio por bushel. Todo este estudio sobre bushels de calabazas, sin embargo, demuestra lo importante que es entender la naturaleza de tus datos.

Ahora puedes analizar el precio por unidad basado en su medida de bushel. Si imprimes los datos una vez m√°s, puedes ver c√≥mo se han estandarizado.

‚úÖ ¬øNotaste que las calabazas vendidas por medio bushel son muy caras? ¬øPuedes averiguar por qu√©? Pista: las calabazas peque√±as son mucho m√°s caras que las grandes, probablemente porque hay muchas m√°s por bushel, dado el espacio no utilizado que ocupa una calabaza grande y hueca para pastel.

## Estrategias de visualizaci√≥n

Parte del rol del cient√≠fico de datos es demostrar la calidad y naturaleza de los datos con los que est√°n trabajando. Para hacerlo, a menudo crean visualizaciones interesantes, como gr√°ficos, diagramas y tablas, que muestran diferentes aspectos de los datos. De esta manera, pueden mostrar visualmente relaciones y brechas que de otro modo ser√≠an dif√≠ciles de descubrir.

[![ML para principiantes - C√≥mo visualizar datos con Matplotlib](https://img.youtube.com/vi/SbUkxH6IJo0/0.jpg)](https://youtu.be/SbUkxH6IJo0 "ML para principiantes - C√≥mo visualizar datos con Matplotlib")

> üé• Haz clic en la imagen de arriba para ver un breve video sobre c√≥mo visualizar los datos para esta lecci√≥n.

Las visualizaciones tambi√©n pueden ayudar a determinar la t√©cnica de aprendizaje autom√°tico m√°s adecuada para los datos. Un gr√°fico de dispersi√≥n que parece seguir una l√≠nea, por ejemplo, indica que los datos son buenos candidatos para un ejercicio de regresi√≥n lineal.

Una biblioteca de visualizaci√≥n de datos que funciona bien en Jupyter notebooks es [Matplotlib](https://matplotlib.org/) (que tambi√©n viste en la lecci√≥n anterior).

> Obt√©n m√°s experiencia con la visualizaci√≥n de datos en [estos tutoriales](https://docs.microsoft.com/learn/modules/explore-analyze-data-with-python?WT.mc_id=academic-77952-leestott).

## Ejercicio - experimentar con Matplotlib

Intenta crear algunos gr√°ficos b√°sicos para mostrar el nuevo dataframe que acabas de crear. ¬øQu√© mostrar√≠a un gr√°fico de l√≠neas b√°sico?

1. Importa Matplotlib en la parte superior del archivo, debajo de la importaci√≥n de Pandas:

    ```python
    import matplotlib.pyplot as plt
    ```

1. Vuelve a ejecutar todo el notebook para actualizar.
1. En la parte inferior del notebook, agrega una celda para graficar los datos como un cuadro:

    ```python
    price = new_pumpkins.Price
    month = new_pumpkins.Month
    plt.scatter(price, month)
    plt.show()
    ```

    ![Un gr√°fico de dispersi√≥n que muestra la relaci√≥n entre precio y mes](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/2-Data/images/scatterplot.png)

    ¬øEs este un gr√°fico √∫til? ¬øHay algo que te sorprenda?

    No es particularmente √∫til, ya que solo muestra tus datos como una dispersi√≥n de puntos en un mes determinado.

### Hazlo √∫til

Para que los gr√°ficos muestren datos √∫tiles, generalmente necesitas agrupar los datos de alguna manera. Intentemos crear un gr√°fico donde el eje y muestre los meses y los datos demuestren la distribuci√≥n de los mismos.

1. Agrega una celda para crear un gr√°fico de barras agrupado:

    ```python
    new_pumpkins.groupby(['Month'])['Price'].mean().plot(kind='bar')
    plt.ylabel("Pumpkin Price")
    ```

    ![Un gr√°fico de barras que muestra la relaci√≥n entre precio y mes](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/2-Data/images/barchart.png)

    ¬°Este es un gr√°fico de datos m√°s √∫til! Parece indicar que el precio m√°s alto de las calabazas ocurre en septiembre y octubre. ¬øCumple con tus expectativas? ¬øPor qu√© o por qu√© no?

---

## üöÄDesaf√≠o

Explora los diferentes tipos de visualizaci√≥n que ofrece Matplotlib. ¬øQu√© tipos son m√°s apropiados para problemas de regresi√≥n?

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y autoestudio

Echa un vistazo a las muchas formas de visualizar datos. Haz una lista de las diversas bibliotecas disponibles y anota cu√°les son mejores para ciertos tipos de tareas, por ejemplo, visualizaciones en 2D frente a visualizaciones en 3D. ¬øQu√© descubres?

## Tarea

[Explorar visualizaci√≥n](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "40e64f004f3cb50aa1d8661672d3cd92",
  "translation_date": "2025-09-04T22:11:11+00:00",
  "source_file": "2-Regression/3-Linear/README.md",
  "language_code": "es"
}
-->
# Construir un modelo de regresi√≥n usando Scikit-learn: cuatro formas de regresi√≥n

![Infograf√≠a de regresi√≥n lineal vs polin√≥mica](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/3-Linear/images/linear-polynomial.png)
> Infograf√≠a por [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

> ### [¬°Esta lecci√≥n est√° disponible en R!](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### Introducci√≥n 

Hasta ahora has explorado qu√© es la regresi√≥n con datos de muestra obtenidos del conjunto de datos de precios de calabazas que utilizaremos a lo largo de esta lecci√≥n. Tambi√©n lo has visualizado utilizando Matplotlib.

Ahora est√°s listo para profundizar m√°s en la regresi√≥n para ML. Mientras que la visualizaci√≥n te permite comprender los datos, el verdadero poder del aprendizaje autom√°tico proviene del _entrenamiento de modelos_. Los modelos se entrenan con datos hist√≥ricos para capturar autom√°ticamente las dependencias de los datos, y te permiten predecir resultados para nuevos datos que el modelo no ha visto antes.

En esta lecci√≥n, aprender√°s m√°s sobre dos tipos de regresi√≥n: _regresi√≥n lineal b√°sica_ y _regresi√≥n polin√≥mica_, junto con algunas de las matem√°ticas subyacentes a estas t√©cnicas. Estos modelos nos permitir√°n predecir los precios de las calabazas dependiendo de diferentes datos de entrada.

[![ML para principiantes - Entendiendo la regresi√≥n lineal](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "ML para principiantes - Entendiendo la regresi√≥n lineal")

> üé• Haz clic en la imagen de arriba para un breve video sobre la regresi√≥n lineal.

> A lo largo de este plan de estudios, asumimos un conocimiento m√≠nimo de matem√°ticas y buscamos hacerlo accesible para estudiantes provenientes de otros campos, as√≠ que presta atenci√≥n a las notas, üßÆ llamados, diagramas y otras herramientas de aprendizaje para facilitar la comprensi√≥n.

### Prerrequisitos

A estas alturas deber√≠as estar familiarizado con la estructura de los datos de calabazas que estamos examinando. Puedes encontrarlos precargados y preprocesados en el archivo _notebook.ipynb_ de esta lecci√≥n. En el archivo, el precio de las calabazas se muestra por bushel en un nuevo marco de datos. Aseg√∫rate de poder ejecutar estos notebooks en kernels en Visual Studio Code.

### Preparaci√≥n

Como recordatorio, est√°s cargando estos datos para hacer preguntas sobre ellos.

- ¬øCu√°ndo es el mejor momento para comprar calabazas? 
- ¬øQu√© precio puedo esperar por un paquete de calabazas miniatura?
- ¬øDeber√≠a comprarlas en cestas de medio bushel o en cajas de 1 1/9 bushel?
Sigamos investigando estos datos.

En la lecci√≥n anterior, creaste un marco de datos de Pandas y lo llenaste con parte del conjunto de datos original, estandarizando los precios por bushel. Sin embargo, al hacer eso, solo pudiste recopilar alrededor de 400 puntos de datos y solo para los meses de oto√±o.

Echa un vistazo a los datos que precargamos en el notebook que acompa√±a esta lecci√≥n. Los datos est√°n precargados y se ha trazado un gr√°fico de dispersi√≥n inicial para mostrar los datos por mes. Tal vez podamos obtener un poco m√°s de detalle sobre la naturaleza de los datos limpi√°ndolos m√°s.

## Una l√≠nea de regresi√≥n lineal

Como aprendiste en la Lecci√≥n 1, el objetivo de un ejercicio de regresi√≥n lineal es poder trazar una l√≠nea para:

- **Mostrar relaciones entre variables**. Mostrar la relaci√≥n entre las variables.
- **Hacer predicciones**. Hacer predicciones precisas sobre d√≥nde caer√≠a un nuevo punto de datos en relaci√≥n con esa l√≠nea.

Es t√≠pico de la **Regresi√≥n de M√≠nimos Cuadrados** trazar este tipo de l√≠nea. El t√©rmino 'm√≠nimos cuadrados' significa que todos los puntos de datos que rodean la l√≠nea de regresi√≥n se elevan al cuadrado y luego se suman. Idealmente, esa suma final es lo m√°s peque√±a posible, porque queremos un n√∫mero bajo de errores, o `m√≠nimos cuadrados`.

Hacemos esto porque queremos modelar una l√≠nea que tenga la menor distancia acumulada de todos nuestros puntos de datos. Tambi√©n elevamos los t√©rminos al cuadrado antes de sumarlos porque nos interesa su magnitud m√°s que su direcci√≥n.

> **üßÆ Mu√©strame las matem√°ticas** 
> 
> Esta l√≠nea, llamada _l√≠nea de mejor ajuste_, puede expresarse mediante [una ecuaci√≥n](https://en.wikipedia.org/wiki/Simple_linear_regression): 
> 
> ```
> Y = a + bX
> ```
>
> `X` es la 'variable explicativa'. `Y` es la 'variable dependiente'. La pendiente de la l√≠nea es `b` y `a` es la intersecci√≥n con el eje Y, que se refiere al valor de `Y` cuando `X = 0`. 
>
>![calcular la pendiente](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/3-Linear/images/slope.png)
>
> Primero, calcula la pendiente `b`. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)
>
> En otras palabras, y refiri√©ndonos a la pregunta original de los datos de calabazas: "predecir el precio de una calabaza por bushel seg√∫n el mes", `X` se referir√≠a al precio y `Y` se referir√≠a al mes de venta. 
>
>![completar la ecuaci√≥n](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/3-Linear/images/calculation.png)
>
> Calcula el valor de Y. Si est√°s pagando alrededor de $4, ¬°debe ser abril! Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)
>
> Las matem√°ticas que calculan la l√≠nea deben demostrar la pendiente de la l√≠nea, que tambi√©n depende de la intersecci√≥n, o d√≥nde se sit√∫a `Y` cuando `X = 0`.
>
> Puedes observar el m√©todo de c√°lculo para estos valores en el sitio web [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html). Tambi√©n visita [este calculador de m√≠nimos cuadrados](https://www.mathsisfun.com/data/least-squares-calculator.html) para ver c√≥mo los valores de los n√∫meros afectan la l√≠nea.

## Correlaci√≥n

Otro t√©rmino que debes entender es el **Coeficiente de Correlaci√≥n** entre las variables X e Y dadas. Usando un gr√°fico de dispersi√≥n, puedes visualizar r√°pidamente este coeficiente. Un gr√°fico con puntos de datos dispersos en una l√≠nea ordenada tiene alta correlaci√≥n, pero un gr√°fico con puntos de datos dispersos por todas partes entre X e Y tiene baja correlaci√≥n.

Un buen modelo de regresi√≥n lineal ser√° aquel que tenga un Coeficiente de Correlaci√≥n alto (m√°s cercano a 1 que a 0) utilizando el m√©todo de Regresi√≥n de M√≠nimos Cuadrados con una l√≠nea de regresi√≥n.

‚úÖ Ejecuta el notebook que acompa√±a esta lecci√≥n y observa el gr√°fico de dispersi√≥n de Mes a Precio. Seg√∫n tu interpretaci√≥n visual del gr√°fico de dispersi√≥n, ¬øparece que los datos que asocian Mes con Precio para las ventas de calabazas tienen alta o baja correlaci√≥n? ¬øCambia eso si usas una medida m√°s detallada en lugar de `Mes`, por ejemplo, *d√≠a del a√±o* (es decir, el n√∫mero de d√≠as desde el inicio del a√±o)?

En el c√≥digo a continuaci√≥n, asumiremos que hemos limpiado los datos y obtenido un marco de datos llamado `new_pumpkins`, similar al siguiente:

ID | Mes | D√≠aDelA√±o | Variedad | Ciudad | Paquete | Precio Bajo | Precio Alto | Precio
---|-----|-----------|----------|--------|---------|-------------|-------------|-------
70 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364

> El c√≥digo para limpiar los datos est√° disponible en [`notebook.ipynb`](../../../../2-Regression/3-Linear/notebook.ipynb). Hemos realizado los mismos pasos de limpieza que en la lecci√≥n anterior y hemos calculado la columna `D√≠aDelA√±o` utilizando la siguiente expresi√≥n: 

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

Ahora que tienes una comprensi√≥n de las matem√°ticas detr√°s de la regresi√≥n lineal, vamos a crear un modelo de Regresi√≥n para ver si podemos predecir qu√© paquete de calabazas tendr√° los mejores precios. Alguien que compre calabazas para un huerto de calabazas festivo podr√≠a querer esta informaci√≥n para optimizar sus compras de paquetes de calabazas para el huerto.

## Buscando correlaci√≥n

[![ML para principiantes - Buscando correlaci√≥n: La clave para la regresi√≥n lineal](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "ML para principiantes - Buscando correlaci√≥n: La clave para la regresi√≥n lineal")

> üé• Haz clic en la imagen de arriba para un breve video sobre la correlaci√≥n.

De la lecci√≥n anterior probablemente hayas visto que el precio promedio para diferentes meses se ve as√≠:

<img alt="Precio promedio por mes" src="../2-Data/images/barchart.png" width="50%"/>

Esto sugiere que deber√≠a haber alguna correlaci√≥n, y podemos intentar entrenar un modelo de regresi√≥n lineal para predecir la relaci√≥n entre `Mes` y `Precio`, o entre `D√≠aDelA√±o` y `Precio`. Aqu√≠ est√° el gr√°fico de dispersi√≥n que muestra esta √∫ltima relaci√≥n:

<img alt="Gr√°fico de dispersi√≥n de Precio vs. D√≠a del A√±o" src="images/scatter-dayofyear.png" width="50%" /> 

Veamos si hay una correlaci√≥n usando la funci√≥n `corr`:

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

Parece que la correlaci√≥n es bastante peque√±a, -0.15 por `Mes` y -0.17 por `D√≠aDelA√±o`, pero podr√≠a haber otra relaci√≥n importante. Parece que hay diferentes grupos de precios que corresponden a diferentes variedades de calabazas. Para confirmar esta hip√≥tesis, tracemos cada categor√≠a de calabaza usando un color diferente. Al pasar un par√°metro `ax` a la funci√≥n de trazado de dispersi√≥n podemos trazar todos los puntos en el mismo gr√°fico:

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Gr√°fico de dispersi√≥n de Precio vs. D√≠a del A√±o" src="images/scatter-dayofyear-color.png" width="50%" /> 

Nuestra investigaci√≥n sugiere que la variedad tiene m√°s efecto en el precio general que la fecha de venta real. Podemos ver esto con un gr√°fico de barras:

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Gr√°fico de barras de precio vs variedad" src="images/price-by-variety.png" width="50%" /> 

Centr√©monos por el momento solo en una variedad de calabaza, el 'tipo pie', y veamos qu√© efecto tiene la fecha en el precio:

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Gr√°fico de dispersi√≥n de Precio vs. D√≠a del A√±o" src="images/pie-pumpkins-scatter.png" width="50%" /> 

Si ahora calculamos la correlaci√≥n entre `Precio` y `D√≠aDelA√±o` usando la funci√≥n `corr`, obtendremos algo como `-0.27`, lo que significa que tiene sentido entrenar un modelo predictivo.

> Antes de entrenar un modelo de regresi√≥n lineal, es importante asegurarse de que nuestros datos est√©n limpios. La regresi√≥n lineal no funciona bien con valores faltantes, por lo que tiene sentido deshacerse de todas las celdas vac√≠as:

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

Otra opci√≥n ser√≠a llenar esos valores vac√≠os con valores promedio de la columna correspondiente.

## Regresi√≥n Lineal Simple

[![ML para principiantes - Regresi√≥n Lineal y Polin√≥mica usando Scikit-learn](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "ML para principiantes - Regresi√≥n Lineal y Polin√≥mica usando Scikit-learn")

> üé• Haz clic en la imagen de arriba para un breve video sobre regresi√≥n lineal y polin√≥mica.

Para entrenar nuestro modelo de Regresi√≥n Lineal, utilizaremos la biblioteca **Scikit-learn**.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

Comenzamos separando los valores de entrada (caracter√≠sticas) y la salida esperada (etiqueta) en matrices numpy separadas:

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> Nota que tuvimos que realizar un `reshape` en los datos de entrada para que el paquete de Regresi√≥n Lineal los entienda correctamente. La Regresi√≥n Lineal espera una matriz 2D como entrada, donde cada fila de la matriz corresponde a un vector de caracter√≠sticas de entrada. En nuestro caso, dado que solo tenemos una entrada, necesitamos una matriz con forma N√ó1, donde N es el tama√±o del conjunto de datos.

Luego, necesitamos dividir los datos en conjuntos de entrenamiento y prueba, para que podamos validar nuestro modelo despu√©s del entrenamiento:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Finalmente, entrenar el modelo de Regresi√≥n Lineal real toma solo dos l√≠neas de c√≥digo. Definimos el objeto `LinearRegression` y lo ajustamos a nuestros datos usando el m√©todo `fit`:

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

El objeto `LinearRegression` despu√©s de ajustarse contiene todos los coeficientes de la regresi√≥n, que se pueden acceder usando la propiedad `.coef_`. En nuestro caso, solo hay un coeficiente, que deber√≠a estar alrededor de `-0.017`. Esto significa que los precios parecen bajar un poco con el tiempo, pero no demasiado, alrededor de 2 centavos por d√≠a. Tambi√©n podemos acceder al punto de intersecci√≥n de la regresi√≥n con el eje Y usando `lin_reg.intercept_`, que estar√° alrededor de `21` en nuestro caso, indicando el precio al comienzo del a√±o.

Para ver qu√© tan preciso es nuestro modelo, podemos predecir precios en un conjunto de datos de prueba y luego medir qu√© tan cerca est√°n nuestras predicciones de los valores esperados. Esto se puede hacer usando la m√©trica de error cuadr√°tico medio (MSE), que es el promedio de todas las diferencias al cuadrado entre el valor esperado y el predicho.

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```
Nuestro error parece estar en torno a 2 puntos, lo que equivale a ~17%. No es muy bueno. Otro indicador de la calidad del modelo es el **coeficiente de determinaci√≥n**, que se puede obtener de la siguiente manera:

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```
Si el valor es 0, significa que el modelo no toma en cuenta los datos de entrada y act√∫a como el *peor predictor lineal*, que simplemente es el valor promedio del resultado. Un valor de 1 significa que podemos predecir perfectamente todos los resultados esperados. En nuestro caso, el coeficiente est√° alrededor de 0.06, lo cual es bastante bajo.

Tambi√©n podemos graficar los datos de prueba junto con la l√≠nea de regresi√≥n para ver mejor c√≥mo funciona la regresi√≥n en nuestro caso:

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```

<img alt="Regresi√≥n lineal" src="images/linear-results.png" width="50%" />

## Regresi√≥n Polin√≥mica

Otro tipo de Regresi√≥n Lineal es la Regresi√≥n Polin√≥mica. Aunque a veces existe una relaci√≥n lineal entre las variables - cuanto mayor es el volumen de la calabaza, mayor es el precio - en otras ocasiones estas relaciones no pueden representarse como un plano o una l√≠nea recta.

‚úÖ Aqu√≠ hay [algunos ejemplos](https://online.stat.psu.edu/stat501/lesson/9/9.8) de datos que podr√≠an usar Regresi√≥n Polin√≥mica.

Observa nuevamente la relaci√≥n entre Fecha y Precio. ¬øEste diagrama de dispersi√≥n parece que deber√≠a analizarse necesariamente con una l√≠nea recta? ¬øNo pueden fluctuar los precios? En este caso, puedes intentar con regresi√≥n polin√≥mica.

‚úÖ Los polinomios son expresiones matem√°ticas que pueden consistir en una o m√°s variables y coeficientes.

La regresi√≥n polin√≥mica crea una l√≠nea curva para ajustar mejor los datos no lineales. En nuestro caso, si incluimos una variable `DayOfYear` al cuadrado en los datos de entrada, deber√≠amos poder ajustar nuestros datos con una curva parab√≥lica, que tendr√° un m√≠nimo en cierto punto del a√±o.

Scikit-learn incluye una √∫til [API de pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) para combinar diferentes pasos de procesamiento de datos. Un **pipeline** es una cadena de **estimadores**. En nuestro caso, crearemos un pipeline que primero agrega caracter√≠sticas polin√≥micas a nuestro modelo y luego entrena la regresi√≥n:

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```

Usar `PolynomialFeatures(2)` significa que incluiremos todos los polinomios de segundo grado de los datos de entrada. En nuestro caso, esto simplemente significar√° `DayOfYear`<sup>2</sup>, pero dado dos variables de entrada X e Y, esto agregar√° X<sup>2</sup>, XY y Y<sup>2</sup>. Tambi√©n podemos usar polinomios de mayor grado si lo deseamos.

Los pipelines pueden usarse de la misma manera que el objeto original `LinearRegression`, es decir, podemos usar `fit` en el pipeline y luego usar `predict` para obtener los resultados de predicci√≥n. Aqu√≠ est√° el gr√°fico que muestra los datos de prueba y la curva de aproximaci√≥n:

<img alt="Regresi√≥n polin√≥mica" src="images/poly-results.png" width="50%" />

Usando Regresi√≥n Polin√≥mica, podemos obtener un MSE ligeramente m√°s bajo y un coeficiente de determinaci√≥n m√°s alto, pero no significativamente. ¬°Necesitamos tomar en cuenta otras caracter√≠sticas!

> Puedes observar que los precios m√≠nimos de las calabazas se registran en alg√∫n momento cerca de Halloween. ¬øC√≥mo puedes explicar esto?

üéÉ ¬°Felicidades! Acabas de crear un modelo que puede ayudar a predecir el precio de las calabazas para pastel. Probablemente podr√≠as repetir el mismo procedimiento para todos los tipos de calabazas, pero eso ser√≠a tedioso. ¬°Ahora aprendamos c√≥mo tomar en cuenta la variedad de calabazas en nuestro modelo!

## Caracter√≠sticas Categ√≥ricas

En un mundo ideal, queremos poder predecir precios para diferentes variedades de calabazas usando el mismo modelo. Sin embargo, la columna `Variety` es algo diferente de columnas como `Month`, porque contiene valores no num√©ricos. Estas columnas se llaman **categ√≥ricas**.

[![ML para principiantes - Predicciones con caracter√≠sticas categ√≥ricas usando Regresi√≥n Lineal](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML para principiantes - Predicciones con caracter√≠sticas categ√≥ricas usando Regresi√≥n Lineal")

> üé• Haz clic en la imagen de arriba para ver un breve video sobre el uso de caracter√≠sticas categ√≥ricas.

Aqu√≠ puedes ver c√≥mo el precio promedio depende de la variedad:

<img alt="Precio promedio por variedad" src="images/price-by-variety.png" width="50%" />

Para tomar en cuenta la variedad, primero necesitamos convertirla a forma num√©rica, o **codificarla**. Hay varias maneras de hacerlo:

* La **codificaci√≥n num√©rica simple** construir√° una tabla de diferentes variedades y luego reemplazar√° el nombre de la variedad por un √≠ndice en esa tabla. Esta no es la mejor idea para la regresi√≥n lineal, porque la regresi√≥n lineal toma el valor num√©rico real del √≠ndice y lo agrega al resultado, multiplic√°ndolo por alg√∫n coeficiente. En nuestro caso, la relaci√≥n entre el n√∫mero de √≠ndice y el precio claramente no es lineal, incluso si nos aseguramos de que los √≠ndices est√©n ordenados de alguna manera espec√≠fica.
* La **codificaci√≥n one-hot** reemplazar√° la columna `Variety` por 4 columnas diferentes, una para cada variedad. Cada columna contendr√° `1` si la fila correspondiente es de una variedad dada, y `0` en caso contrario. Esto significa que habr√° cuatro coeficientes en la regresi√≥n lineal, uno para cada variedad de calabaza, responsables del "precio inicial" (o m√°s bien "precio adicional") para esa variedad en particular.

El siguiente c√≥digo muestra c√≥mo podemos codificar una variedad usando one-hot:

```python
pd.get_dummies(new_pumpkins['Variety'])
```

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE
----|-----------|-----------|--------------------------|----------
70 | 0 | 0 | 0 | 1
71 | 0 | 0 | 0 | 1
... | ... | ... | ... | ...
1738 | 0 | 1 | 0 | 0
1739 | 0 | 1 | 0 | 0
1740 | 0 | 1 | 0 | 0
1741 | 0 | 1 | 0 | 0
1742 | 0 | 1 | 0 | 0

Para entrenar la regresi√≥n lineal usando la variedad codificada como one-hot en los datos de entrada, solo necesitamos inicializar correctamente los datos `X` y `y`:

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```

El resto del c√≥digo es el mismo que usamos anteriormente para entrenar la Regresi√≥n Lineal. Si lo pruebas, ver√°s que el error cuadr√°tico medio es aproximadamente el mismo, pero obtenemos un coeficiente de determinaci√≥n mucho m√°s alto (~77%). Para obtener predicciones a√∫n m√°s precisas, podemos tomar en cuenta m√°s caracter√≠sticas categ√≥ricas, as√≠ como caracter√≠sticas num√©ricas, como `Month` o `DayOfYear`. Para obtener un gran conjunto de caracter√≠sticas, podemos usar `join`:

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```

Aqu√≠ tambi√©n tomamos en cuenta `City` y el tipo de `Package`, lo que nos da un MSE de 2.84 (10%) y un coeficiente de determinaci√≥n de 0.94.

## Junt√°ndolo todo

Para crear el mejor modelo, podemos usar datos combinados (categ√≥ricos codificados como one-hot + num√©ricos) del ejemplo anterior junto con Regresi√≥n Polin√≥mica. Aqu√≠ est√° el c√≥digo completo para tu conveniencia:

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```

Esto deber√≠a darnos el mejor coeficiente de determinaci√≥n de casi 97% y un MSE=2.23 (~8% de error de predicci√≥n).

| Modelo | MSE | Determinaci√≥n |
|--------|-----|---------------|
| `DayOfYear` Lineal | 2.77 (17.2%) | 0.07 |
| `DayOfYear` Polin√≥mico | 2.73 (17.0%) | 0.08 |
| `Variety` Lineal | 5.24 (19.7%) | 0.77 |
| Todas las caracter√≠sticas Lineal | 2.84 (10.5%) | 0.94 |
| Todas las caracter√≠sticas Polin√≥mico | 2.23 (8.25%) | 0.97 |

üèÜ ¬°Bien hecho! Creaste cuatro modelos de Regresi√≥n en una sola lecci√≥n y mejoraste la calidad del modelo al 97%. En la secci√≥n final sobre Regresi√≥n, aprender√°s sobre Regresi√≥n Log√≠stica para determinar categor√≠as.

---
## üöÄDesaf√≠o

Prueba varias variables diferentes en este notebook para ver c√≥mo la correlaci√≥n corresponde a la precisi√≥n del modelo.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y Autoestudio

En esta lecci√≥n aprendimos sobre Regresi√≥n Lineal. Hay otros tipos importantes de Regresi√≥n. Lee sobre las t√©cnicas Stepwise, Ridge, Lasso y Elasticnet. Un buen curso para estudiar y aprender m√°s es el [curso de Stanford sobre Aprendizaje Estad√≠stico](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning).

## Tarea

[Construye un Modelo](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---

<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abf86d845c84330bce205a46b382ec88",
  "translation_date": "2025-09-04T22:12:57+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "es"
}
-->
# Regresi√≥n log√≠stica para predecir categor√≠as

![Infograf√≠a de regresi√≥n log√≠stica vs. regresi√≥n lineal](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/linear-vs-logistic.png)

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

> ### [¬°Esta lecci√≥n est√° disponible en R!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introducci√≥n

En esta √∫ltima lecci√≥n sobre Regresi√≥n, una de las t√©cnicas b√°sicas _cl√°sicas_ de ML, exploraremos la Regresi√≥n Log√≠stica. Utilizar√≠as esta t√©cnica para descubrir patrones y predecir categor√≠as binarias. ¬øEs este dulce de chocolate o no? ¬øEs esta enfermedad contagiosa o no? ¬øElegir√° este cliente este producto o no?

En esta lecci√≥n, aprender√°s:

- Una nueva biblioteca para la visualizaci√≥n de datos
- T√©cnicas para la regresi√≥n log√≠stica

‚úÖ Profundiza tu comprensi√≥n sobre c√≥mo trabajar con este tipo de regresi√≥n en este [m√≥dulo de aprendizaje](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Prerrequisitos

Despu√©s de trabajar con los datos de calabazas, ya estamos lo suficientemente familiarizados con ellos como para darnos cuenta de que hay una categor√≠a binaria con la que podemos trabajar: `Color`.

Construyamos un modelo de regresi√≥n log√≠stica para predecir, dado algunas variables, _de qu√© color es probable que sea una calabaza_ (naranja üéÉ o blanca üëª).

> ¬øPor qu√© estamos hablando de clasificaci√≥n binaria en una lecci√≥n sobre regresi√≥n? Solo por conveniencia ling√º√≠stica, ya que la regresi√≥n log√≠stica es [realmente un m√©todo de clasificaci√≥n](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), aunque basado en un enfoque lineal. Aprende sobre otras formas de clasificar datos en el pr√≥ximo grupo de lecciones.

## Define la pregunta

Para nuestros prop√≥sitos, expresaremos esto como un binario: 'Blanca' o 'No Blanca'. Tambi√©n hay una categor√≠a 'rayada' en nuestro conjunto de datos, pero hay pocos casos de ella, por lo que no la usaremos. De todos modos, desaparece una vez que eliminamos los valores nulos del conjunto de datos.

> üéÉ Dato curioso: a veces llamamos a las calabazas blancas 'calabazas fantasma'. No son muy f√°ciles de tallar, por lo que no son tan populares como las naranjas, ¬°pero tienen un aspecto genial! As√≠ que tambi√©n podr√≠amos reformular nuestra pregunta como: 'Fantasma' o 'No Fantasma'. üëª

## Sobre la regresi√≥n log√≠stica

La regresi√≥n log√≠stica difiere de la regresi√≥n lineal, que aprendiste anteriormente, en algunos aspectos importantes.

[![ML para principiantes - Comprendiendo la Regresi√≥n Log√≠stica para la Clasificaci√≥n en Machine Learning](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML para principiantes - Comprendiendo la Regresi√≥n Log√≠stica para la Clasificaci√≥n en Machine Learning")

> üé• Haz clic en la imagen de arriba para un breve video sobre la regresi√≥n log√≠stica.

### Clasificaci√≥n binaria

La regresi√≥n log√≠stica no ofrece las mismas caracter√≠sticas que la regresi√≥n lineal. La primera ofrece una predicci√≥n sobre una categor√≠a binaria ("blanca o no blanca"), mientras que la segunda es capaz de predecir valores continuos, por ejemplo, dado el origen de una calabaza y el momento de la cosecha, _cu√°nto subir√° su precio_.

![Modelo de clasificaci√≥n de calabazas](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/pumpkin-classifier.png)
> Infograf√≠a por [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Otras clasificaciones

Existen otros tipos de regresi√≥n log√≠stica, incluyendo multinomial y ordinal:

- **Multinomial**, que implica tener m√°s de una categor√≠a - "Naranja, Blanca y Rayada".
- **Ordinal**, que implica categor√≠as ordenadas, √∫til si quisi√©ramos ordenar nuestros resultados l√≥gicamente, como nuestras calabazas que est√°n ordenadas por un n√∫mero finito de tama√±os (mini, peque√±a, mediana, grande, XL, XXL).

![Regresi√≥n multinomial vs ordinal](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/multinomial-vs-ordinal.png)

### Las variables NO tienen que correlacionarse

¬øRecuerdas c√≥mo la regresi√≥n lineal funcionaba mejor con variables m√°s correlacionadas? La regresi√≥n log√≠stica es lo opuesto: las variables no tienen que estar alineadas. Esto funciona para estos datos, que tienen correlaciones algo d√©biles.

### Necesitas muchos datos limpios

La regresi√≥n log√≠stica dar√° resultados m√°s precisos si utilizas m√°s datos; nuestro peque√±o conjunto de datos no es √≥ptimo para esta tarea, as√≠ que tenlo en cuenta.

[![ML para principiantes - An√°lisis y Preparaci√≥n de Datos para la Regresi√≥n Log√≠stica](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML para principiantes - An√°lisis y Preparaci√≥n de Datos para la Regresi√≥n Log√≠stica")

> üé• Haz clic en la imagen de arriba para un breve video sobre la preparaci√≥n de datos para la regresi√≥n lineal.

‚úÖ Piensa en los tipos de datos que se prestar√≠an bien a la regresi√≥n log√≠stica.

## Ejercicio - organiza los datos

Primero, limpia un poco los datos, eliminando valores nulos y seleccionando solo algunas de las columnas:

1. Agrega el siguiente c√≥digo:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Siempre puedes echar un vistazo a tu nuevo dataframe:

    ```python
    pumpkins.info
    ```

### Visualizaci√≥n - gr√°fico categ√≥rico

Hasta ahora has cargado el [notebook inicial](../../../../2-Regression/4-Logistic/notebook.ipynb) con datos de calabazas una vez m√°s y lo has limpiado para preservar un conjunto de datos que contiene algunas variables, incluyendo `Color`. Visualicemos el dataframe en el notebook usando una biblioteca diferente: [Seaborn](https://seaborn.pydata.org/index.html), que est√° construida sobre Matplotlib, que usamos anteriormente.

Seaborn ofrece formas interesantes de visualizar tus datos. Por ejemplo, puedes comparar distribuciones de los datos para cada `Variety` y `Color` en un gr√°fico categ√≥rico.

1. Crea dicho gr√°fico usando la funci√≥n `catplot`, con nuestros datos de calabazas `pumpkins`, y especificando un mapeo de colores para cada categor√≠a de calabaza (naranja o blanca):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Una cuadr√≠cula de datos visualizados](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/pumpkins_catplot_1.png)

    Al observar los datos, puedes ver c√≥mo los datos de Color se relacionan con Variety.

    ‚úÖ Dado este gr√°fico categ√≥rico, ¬øqu√© exploraciones interesantes puedes imaginar?

### Preprocesamiento de datos: codificaci√≥n de caracter√≠sticas y etiquetas

Nuestro conjunto de datos de calabazas contiene valores de cadena para todas sus columnas. Trabajar con datos categ√≥ricos es intuitivo para los humanos, pero no para las m√°quinas. Los algoritmos de aprendizaje autom√°tico funcionan bien con n√∫meros. Por eso, la codificaci√≥n es un paso muy importante en la fase de preprocesamiento de datos, ya que nos permite convertir datos categ√≥ricos en datos num√©ricos, sin perder informaci√≥n. Una buena codificaci√≥n conduce a la construcci√≥n de un buen modelo.

Para la codificaci√≥n de caracter√≠sticas, hay dos tipos principales de codificadores:

1. Codificador ordinal: es adecuado para variables ordinales, que son variables categ√≥ricas donde sus datos siguen un orden l√≥gico, como la columna `Item Size` en nuestro conjunto de datos. Crea un mapeo de modo que cada categor√≠a est√© representada por un n√∫mero, que es el orden de la categor√≠a en la columna.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Codificador categ√≥rico: es adecuado para variables nominales, que son variables categ√≥ricas donde sus datos no siguen un orden l√≥gico, como todas las caracter√≠sticas diferentes de `Item Size` en nuestro conjunto de datos. Es una codificaci√≥n one-hot, lo que significa que cada categor√≠a est√° representada por una columna binaria: la variable codificada es igual a 1 si la calabaza pertenece a esa Variety y 0 en caso contrario.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

Luego, `ColumnTransformer` se utiliza para combinar m√∫ltiples codificadores en un solo paso y aplicarlos a las columnas apropiadas.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

Por otro lado, para codificar la etiqueta, usamos la clase `LabelEncoder` de scikit-learn, que es una clase de utilidad para ayudar a normalizar etiquetas de modo que contengan solo valores entre 0 y n_classes-1 (aqu√≠, 0 y 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

Una vez que hemos codificado las caracter√≠sticas y la etiqueta, podemos fusionarlas en un nuevo dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

‚úÖ ¬øCu√°les son las ventajas de usar un codificador ordinal para la columna `Item Size`?

### Analiza las relaciones entre variables

Ahora que hemos preprocesado nuestros datos, podemos analizar las relaciones entre las caracter√≠sticas y la etiqueta para hacernos una idea de qu√© tan bien el modelo podr√° predecir la etiqueta dadas las caracter√≠sticas. La mejor manera de realizar este tipo de an√°lisis es graficando los datos. Usaremos nuevamente la funci√≥n `catplot` de Seaborn para visualizar las relaciones entre `Item Size`, `Variety` y `Color` en un gr√°fico categ√≥rico. Para graficar mejor los datos, usaremos la columna codificada `Item Size` y la columna sin codificar `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![Un gr√°fico categ√≥rico de datos visualizados](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/pumpkins_catplot_2.png)

### Usa un gr√°fico de enjambre

Dado que Color es una categor√≠a binaria (Blanca o No), necesita '[un enfoque especializado](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) para la visualizaci√≥n'. Hay otras formas de visualizar la relaci√≥n de esta categor√≠a con otras variables.

Puedes visualizar variables lado a lado con gr√°ficos de Seaborn.

1. Prueba un gr√°fico de 'enjambre' para mostrar la distribuci√≥n de valores:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Un enjambre de datos visualizados](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/swarm_2.png)

**Cuidado**: el c√≥digo anterior podr√≠a generar una advertencia, ya que Seaborn falla al representar tal cantidad de puntos de datos en un gr√°fico de enjambre. Una posible soluci√≥n es disminuir el tama√±o del marcador, utilizando el par√°metro 'size'. Sin embargo, ten en cuenta que esto afecta la legibilidad del gr√°fico.

> **üßÆ Mu√©strame las matem√°ticas**
>
> La regresi√≥n log√≠stica se basa en el concepto de 'm√°xima verosimilitud' utilizando [funciones sigmoides](https://wikipedia.org/wiki/Sigmoid_function). Una 'Funci√≥n Sigmoide' en un gr√°fico tiene forma de 'S'. Toma un valor y lo mapea a un rango entre 0 y 1. Su curva tambi√©n se llama 'curva log√≠stica'. Su f√≥rmula es la siguiente:
>
> ![funci√≥n log√≠stica](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/sigmoid.png)
>
> donde el punto medio de la sigmoide se encuentra en el punto 0 de x, L es el valor m√°ximo de la curva, y k es la pendiente de la curva. Si el resultado de la funci√≥n es mayor a 0.5, la etiqueta en cuesti√≥n se clasificar√° como '1' de la elecci√≥n binaria. Si no, se clasificar√° como '0'.

## Construye tu modelo

Construir un modelo para encontrar estas clasificaciones binarias es sorprendentemente sencillo en Scikit-learn.

[![ML para principiantes - Regresi√≥n Log√≠stica para la clasificaci√≥n de datos](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML para principiantes - Regresi√≥n Log√≠stica para la clasificaci√≥n de datos")

> üé• Haz clic en la imagen de arriba para un breve video sobre c√≥mo construir un modelo de regresi√≥n lineal.

1. Selecciona las variables que deseas usar en tu modelo de clasificaci√≥n y divide los conjuntos de entrenamiento y prueba llamando a `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Ahora puedes entrenar tu modelo llamando a `fit()` con tus datos de entrenamiento y mostrar su resultado:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    Observa el puntaje de tu modelo. No est√° mal, considerando que solo tienes alrededor de 1000 filas de datos:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Mejor comprensi√≥n mediante una matriz de confusi√≥n

Aunque puedes obtener un informe de puntaje [t√©rminos](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) imprimiendo los elementos anteriores, podr√≠as entender mejor tu modelo utilizando una [matriz de confusi√≥n](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) para ayudarnos a comprender c√≥mo est√° funcionando el modelo.

> üéì Una '[matriz de confusi√≥n](https://wikipedia.org/wiki/Confusion_matrix)' (o 'matriz de error') es una tabla que expresa los verdaderos vs. falsos positivos y negativos de tu modelo, evaluando as√≠ la precisi√≥n de las predicciones.

1. Para usar una matriz de confusi√≥n, llama a `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Observa la matriz de confusi√≥n de tu modelo:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

En Scikit-learn, las filas (eje 0) son etiquetas reales y las columnas (eje 1) son etiquetas predichas.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

¬øQu√© est√° pasando aqu√≠? Supongamos que nuestro modelo debe clasificar calabazas entre dos categor√≠as binarias, categor√≠a 'blanca' y categor√≠a 'no blanca'.

- Si tu modelo predice una calabaza como no blanca y en realidad pertenece a la categor√≠a 'no blanca', lo llamamos un verdadero negativo, mostrado por el n√∫mero en la esquina superior izquierda.
- Si tu modelo predice una calabaza como blanca y en realidad pertenece a la categor√≠a 'no blanca', lo llamamos un falso negativo, mostrado por el n√∫mero en la esquina inferior izquierda.
- Si tu modelo predice una calabaza como no blanca y en realidad pertenece a la categor√≠a 'blanca', lo llamamos un falso positivo, mostrado por el n√∫mero en la esquina superior derecha.
- Si tu modelo predice una calabaza como blanca y en realidad pertenece a la categor√≠a 'blanca', lo llamamos un verdadero positivo, mostrado por el n√∫mero en la esquina inferior derecha.

Como habr√°s adivinado, es preferible tener un mayor n√∫mero de verdaderos positivos y verdaderos negativos y un menor n√∫mero de falsos positivos y falsos negativos, lo que implica que el modelo funciona mejor.
¬øC√≥mo se relaciona la matriz de confusi√≥n con la precisi√≥n y el recall? Recuerda, el informe de clasificaci√≥n mostrado anteriormente indic√≥ una precisi√≥n (0.85) y un recall (0.67).

Precisi√≥n = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

Recall = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

‚úÖ P: Seg√∫n la matriz de confusi√≥n, ¬øc√≥mo le fue al modelo? R: No est√° mal; hay un buen n√∫mero de verdaderos negativos, pero tambi√©n algunos falsos negativos.

Volvamos a revisar los t√©rminos que vimos antes con la ayuda del mapeo de TP/TN y FP/FN en la matriz de confusi√≥n:

üéì Precisi√≥n: TP/(TP + FP) La fracci√≥n de instancias relevantes entre las instancias recuperadas (por ejemplo, qu√© etiquetas fueron bien etiquetadas).

üéì Recall: TP/(TP + FN) La fracci√≥n de instancias relevantes que fueron recuperadas, ya sea bien etiquetadas o no.

üéì f1-score: (2 * precisi√≥n * recall)/(precisi√≥n + recall) Un promedio ponderado de la precisi√≥n y el recall, donde el mejor valor es 1 y el peor es 0.

üéì Soporte: El n√∫mero de ocurrencias de cada etiqueta recuperada.

üéì Exactitud: (TP + TN)/(TP + TN + FP + FN) El porcentaje de etiquetas predichas correctamente para una muestra.

üéì Promedio Macro: El c√°lculo de las m√©tricas medias no ponderadas para cada etiqueta, sin tener en cuenta el desequilibrio de etiquetas.

üéì Promedio Ponderado: El c√°lculo de las m√©tricas medias para cada etiqueta, teniendo en cuenta el desequilibrio de etiquetas al ponderarlas seg√∫n su soporte (el n√∫mero de instancias verdaderas para cada etiqueta).

‚úÖ ¬øPuedes pensar en qu√© m√©trica deber√≠as enfocarte si quieres que tu modelo reduzca el n√∫mero de falsos negativos?

## Visualizar la curva ROC de este modelo

[![ML para principiantes - Analizando el rendimiento de la regresi√≥n log√≠stica con curvas ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML para principiantes - Analizando el rendimiento de la regresi√≥n log√≠stica con curvas ROC")

> üé• Haz clic en la imagen de arriba para un breve video sobre las curvas ROC.

Hagamos una visualizaci√≥n m√°s para observar la llamada curva 'ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Usando Matplotlib, grafica la [Curva Caracter√≠stica Operativa del Receptor](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) o ROC del modelo. Las curvas ROC se usan a menudo para obtener una vista del rendimiento de un clasificador en t√©rminos de sus verdaderos positivos frente a los falsos positivos. "Las curvas ROC t√≠picamente muestran la tasa de verdaderos positivos en el eje Y y la tasa de falsos positivos en el eje X." Por lo tanto, la inclinaci√≥n de la curva y el espacio entre la l√≠nea del punto medio y la curva son importantes: quieres una curva que suba r√°pidamente y se aleje de la l√≠nea. En nuestro caso, hay falsos positivos al principio, y luego la l√≠nea sube y se aleja correctamente:

![ROC](https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/4-Logistic/images/ROC_2.png)

Finalmente, usa la API [`roc_auc_score` de Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) para calcular el '√Årea Bajo la Curva' (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
El resultado es `0.9749908725812341`. Dado que el AUC var√≠a de 0 a 1, quieres un puntaje alto, ya que un modelo que sea 100% correcto en sus predicciones tendr√° un AUC de 1; en este caso, el modelo es _bastante bueno_.

En futuras lecciones sobre clasificaciones, aprender√°s c√≥mo iterar para mejorar los puntajes de tu modelo. Pero por ahora, ¬°felicitaciones! ¬°Has completado estas lecciones sobre regresi√≥n!

---
## üöÄDesaf√≠o

¬°Hay mucho m√°s que explorar sobre la regresi√≥n log√≠stica! Pero la mejor manera de aprender es experimentando. Encuentra un conjunto de datos que se preste a este tipo de an√°lisis y construye un modelo con √©l. ¬øQu√© aprendes? Consejo: prueba [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) para encontrar conjuntos de datos interesantes.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y Autoestudio

Lee las primeras p√°ginas de [este art√≠culo de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sobre algunos usos pr√°cticos de la regresi√≥n log√≠stica. Piensa en tareas que se adapten mejor a uno u otro tipo de tareas de regresi√≥n que hemos estudiado hasta ahora. ¬øQu√© funcionar√≠a mejor?

## Tarea

[Reintentando esta regresi√≥n](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.

---
